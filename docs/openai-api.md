*Note: This is llmstxt.txt is not complete, please enter a Firecrawl API key to get the entire llmstxt.txt at llmstxt.firecrawl.dev or you can access llms.txt via API with curl -X GET 'http://llmstxt.firecrawl.dev/https://platform.openai.com/docs/api-reference/introduction?FIRECRAWL_API_KEY=YOUR_API_KEY' or llms-full.txt via API with curl -X GET 'http://llmstxt.firecrawl.dev/https://platform.openai.com/docs/api-reference/introduction/full?FIRECRAWL_API_KEY=YOUR_API_KEY'

# https://platform.openai.com/docs/api-reference/introduction llms.txt

- [API Example Codes](https://platform.openai.com/docs/examples): OpenAI API example code and usage guides for various programming languages.
- [OpenAI Subprocessor List](https://platform.openai.com/subprocessors): List of Subprocessors engaged by OpenAI to process customer data, including contact information for inquiries.
- [OpenAI Data Quality](https://platform.openai.com/docs/data-quality): OpenAI's data quality documentation; find answers to your questions.
- [OpenAI Sign Up](https://platform.openai.com/signup.Complete): Sign up or log in to access OpenAI platform.
- [OpenAI Chat Playground](https://platform.openai.com/playground/chat): OpenAI Chat playground: requires login to access interactive AI chat.
- [OpenAI API Concepts](https://platform.openai.com/docs/concepts): Key concepts for using OpenAI API: text generation models, assistants, embeddings, and tokens.
- [OpenAI Platform Login](https://platform.openai.com/overviewGamifying): Access OpenAI platform; requires login for authentication and authorization.
- [OpenAI API Login](https://platform.openai.com/overviewOpenAIAPIAnAPIfor): Access OpenAI API; authentication required. Please log in to continue.
- [OpenAI 404 Error](https://platform.openai.com/docs/overvieOpenAi): OpenAI's documentation page not found error; unexpected URL.
- [OpenAI Data Retrieval](https://platform.openai.com/docs/actions/data-retrieval): Retrieve data using OpenAI's powerful API actions; seamlessly integrate data into your workflows.
- [GPT Actions File I/O](https://platform.openai.com/docs/actions/sending-files): Send and receive files using GPT Actions.  Supports various file types and sizes with options for inline or URL-based responses.
- [OpenAI Apps & API](https://platform.openai.com/apps): Interact with OpenAI language models via conversational interface or API.
- [Page Not Found](https://platform.openai.com/docs/deprecations%E3%80%82): OpenAI Platform documentation page not found error.
- [API Deprecations](https://platform.openai.com/docs/deprecations): OpenAI API deprecation announcements and timelines for impacted features.
- [OpenAI Platform Login](https://platform.openai.com/overviewThe): OpenAI platform overview; requires login to access.
- [OpenAI Sign Up](https://platform.openai.com/signupNote): Sign up or log in to access OpenAI platform.
- [Page Not Found](https://platform.openai.com/docs/assistan-): OpenAI platform documentation page not found error.
- [OpenAI Login Required](https://platform.openai.com/overviewTwo): OpenAI platform login required.  Access requires authentication.
- [Page Not Found](https://platform.openai.com/docs/models579): OpenAI page not found error; unexpected URL.
- [OpenAI Pro Access](https://platform.openai.com/docs/guides/pro): Access OpenAI's advanced features and capabilities with a Pro account.
- [404: Page Not Found](https://platform.openai.com/docs/hackathons/faq): OpenAI Hackathons FAQ page not found; please check URL.
- [OpenAI API Quickstart](https://platform.openai.com/docs/quickstart): Quickstart guide for OpenAI API: generate API key, make first API request using various methods and explore next steps.
- [Authentication Error](https://platform.openai.com/auth/callback): OpenAI authentication error; contact help center if problem persists.
- [OpenAI Supported Countries](https://platform.openai.com/docs/supported-countries): List of countries and territories supported by OpenAI API services; accessing services from unsupported regions may lead to account suspension.
- [Page Not Found](https://platform.openai.com/docs/model): OpenAI API page not found error; check URL.
- [OpenAI Model Overview](https://platform.openai.com/docs/models/overview): Overview of OpenAI's models: capabilities, limitations, and use cases.
- [Page Not Found](https://platform.openai.com/docs/chatgpt-education.): OpenAI ChatGPT Education page not found; check URL.
- [OpenAI Platform Login](https://platform.openai.com/overview.Using): OpenAI Platform overview; login required to access.
- [OpenAI FAQ Error](https://platform.openai.com/docs/faqs): OpenAI's frequently asked questions page not found error.
- [OpenAI Model Selection](https://platform.openai.com/docs/guides/model-selection): Choose the best OpenAI model for your needs by balancing accuracy, cost, and latency.  This guide offers principles and a practical example for model selection.
- [OpenAI Developer Platform](https://platform.openai.com/docs/overview): OpenAI's developer platform: APIs, models, guides, and resources for building with AI.
- [OpenAI Text Generation](https://platform.openai.com/docs/guides/text-generation): Generate text using OpenAI's API with various models and prompts; explore prompt engineering, manage conversation context, and optimize outputs for accuracy, cost, and latency.
- [OpenAI API Libraries](https://platform.openai.com/docs/libraries/go): OpenAI API client libraries for Python, Node.js, .NET, and more, with links to community-maintained libraries.
- [Page Not Found](https://platform.openai.com/docs/guides/375): OpenAI Platform documentation page not found error.  Check URL for accuracy.
- [Predicted Outputs Guide](https://platform.openai.com/docs/guides/predicted-outputs): Speed up OpenAI API responses using predicted outputs for faster text and code regeneration with gpt-4o models.
- [GPT Actions Production Notes](https://platform.openai.com/docs/actions/production): Deploy GPT Actions to production following best practices; includes rate limits, timeouts, TLS/HTTPS, IP ranges, authentication, OpenAPI specification limits, and additional limitations.
- [OpenAI Developer Platform](https://platform.openai.com/docs/overview): OpenAI's platform provides various models (GPT-4, others),  guides for building applications, and helpful resources.
- [Page Not Found](https://platform.openai.com/docs/quickstartdeep): OpenAI platform page not found error; check URL.
- [Page Not Found](https://platform.openai.com/docs/guides/function-): OpenAI page not found error; check URL for accuracy.
- [OpenAI Crawlers](https://platform.openai.com/docs/bots): OpenAI crawler overview; robots.txt tags for managing how sites interact with OpenAI's crawlers (OAI-SearchBot, ChatGPT-User, GPTBot).
- [GPT Actions: Getting Started](https://platform.openai.com/docs/actions/getting-started): Build a custom GPT Action by setting up, testing, and debugging an Open API schema; integrating authentication and handling errors.
- [Prompt Caching Guide](https://platform.openai.com/docs/guides/prompt-caching): Reduce API latency and cost with OpenAI's automatic prompt caching; learn how it works, best practices, and FAQs.
- [GPT Actions](https://platform.openai.com/docs/actions/introduction): Customize ChatGPT with GPT Actions and API integrations; connect to external applications via RESTful APIs using natural language.
- [Assistants API Updates](https://platform.openai.com/docs/assistants/whats-new): New Assistants API features: improved file search, vector stores, token control, tool choice, custom conversation histories, model config, fine-tuned models, and streaming support.
- [Audio Generation Quickstart](https://platform.openai.com/docs/guides/audio/quickstart): Generate audio from text or audio prompts using OpenAI's API; includes code examples and FAQs.
- [OpenAI API Libraries](https://platform.openai.com/docs/libraries): Explore OpenAI's official and community-supported libraries for Python, Node.js, .NET, and more.
- [Automated Meeting Minutes](https://platform.openai.com/docs/tutorials/meeting-minutes): Automate meeting minutes generation using OpenAI's Whisper and GPT-4: transcribe audio, summarize discussions, extract key points and action items, and perform sentiment analysis.
- [OpenAI API Changelog](https://platform.openai.com/docs/changelog): OpenAI API updates and new features: models, tools, and improvements across various APIs.
- [OpenAI Text Generation](https://platform.openai.com/docs/guides/text-generation): Generate text using OpenAI's API with various models; learn prompt engineering, manage context, and optimize outputs for accuracy, cost, and latency.
- [OpenAI API Error Codes](https://platform.openai.com/docs/guides/error-codes): Troubleshoot OpenAI API and Python library errors; find solutions and detailed guidance for various error codes.
- [Prompt Generation Guide](https://platform.openai.com/docs/guides/prompt-generation): Generate prompts and schemas using OpenAI's Playground; this guide details the process using meta-prompts and meta-schemas.
- [OpenAI Language Models](https://platform.openai.com/docs/models/gp): OpenAI's flagship GPT models: GPT-4o, GPT-4o mini, and others; details on pricing, capabilities, and API usage.
- [OpenAI API Prompts](https://platform.openai.com/docs/examples/default-keywords): OpenAI API examples for various tasks like text summarization, translation, code generation, and keyword extraction.
- [API Rate Limits](https://platform.openai.com/docs/guides/rate-limits): Understand OpenAI API rate limits, restrictions, and how to mitigate exceeding them using various methods and libraries.
- [OpenAI 404 Error](https://platform.openai.com/docs/deprecations%E3%80%91): OpenAI page not found error; check URL or sign up/log in.
- [GPT Release Notes](https://platform.openai.com/docs/gpts/release-notes): OpenAI GPT updates and new features release notes, including file handling, user feedback, and GPT Store launch.
- [OpenAI Advanced Usage](https://platform.openai.com/docs/advanced-usage): Advanced usage of OpenAI's models, including reproducibility, managing tokens, and parameter details for fine-tuning.
- [GPT Actions Introduction](https://platform.openai.com/docs/actions/introduction): Customize ChatGPT with GPT Actions and API integrations; connect to external applications via RESTful APIs using natural language.
- [OpenAI Assistants API Deep Dive](https://platform.openai.com/docs/assistants/deep-dive): In-depth guide for creating and managing OpenAI Assistants, including creating Assistants, managing threads and messages, understanding runs and run steps, and data access guidance.  Covers tools, models, and more.
- [OpenAI Model Overview](https://platform.openai.com/docs/models/overviewof): Overview of OpenAI's language and image models, including GPT-4, DALL-E, and embeddings, pricing details, and model versioning.
- [LLM Latency Optimization](https://platform.openai.com/docs/guides/latency-optimization): Optimize latency in LLM applications using seven key principles: faster token processing, fewer tokens, efficient requests, parallelization, improved user experience, and avoiding unnecessary LLM use.
- [OpenAI Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs): Generate reliable, type-safe JSON outputs using OpenAI's structured outputs feature.  Learn to define schemas, handle refusals, and leverage SDK helpers for seamless integration.
- [Function Calling Guide](https://platform.openai.com/docs/guides/function-calling): Extend OpenAI models with function calling; connect to external data and systems.
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer): Tokenize text using OpenAI's language models; see token counts and examples.
- [OpenAI Prompt Examples](https://platform.openai.com/docs/examples/default-summarize): Explore various OpenAI prompt examples for tasks like grammar correction, text summarization, code explanation, and more.
- [Page Not Found](https://platform.openai.com/docs/deprecatio...): OpenAI Platform documentation page not found error.
- [Explain Code Example](https://platform.openai.com/docs/examples/default-explain-code): OpenAI API example: Explains how to use the API to explain a complicated piece of code.
- [OpenAI API Examples](https://platform.openai.com/docs/examples/default-parse-data): OpenAI API examples for various tasks including text parsing, code generation, and more.
- [Emoji Chatbot Example](https://platform.openai.com/docs/examples/default-emoji-chatbot): Learn to build an emoji chatbot with OpenAI's API; explore example prompts and code implementation.
- [Default Grammar Settings](https://platform.openai.com/docs/examples/default-grammar): Fine-tune the grammar of your prompts with OpenAI's default grammar settings for improved model performance.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): OpenAI API reference introduction: authentication, making requests, streaming responses, debugging, and backward compatibility.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): OpenAI API reference introduction: authentication, making requests, streaming, debugging, backward compatibility, and API key management.
- [OpenAI Account Dashboard](https://platform.openai.com/auth/dashboard): Manage your OpenAI account, API keys, and organization settings.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): OpenAI API reference introduction: authentication, making requests, streaming, debugging, and backward compatibility.
- [OpenAI API Keys](https://platform.openai.com/docs/api_key): Manage and securely use your OpenAI API keys for seamless access to our models.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): Access OpenAI API using HTTP requests, Python, Node.js, or community libraries.  Authenticate with API keys, scoped to projects or users.  Make requests, stream responses, and debug issues.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): OpenAI API reference introduction: authentication, making requests, streaming, debugging, and backward compatibility.
- [OpenAI Account Signup](https://platform.openai.com/signup_ext): Create OpenAI account; sign up and access AI models and tools.
- [OpenAI API Tutorials](https://platform.openai.com/docs/tutorials): Learn to use the OpenAI API with our comprehensive tutorials and examples.
- [Fine-tuning Guide](https://platform.openai.com/docs/guides/fine-): Fine-tune pre-trained models for improved accuracy and performance on specific tasks, using your own data.
- [OpenAI Login](https://platform.openai.com/auth/login): Sign in to your OpenAI account to access API keys, billing, and more.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): OpenAI API reference introduction: authentication methods, making requests, streaming, debugging, and backward compatibility.
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction): OpenAI API reference introduction: authentication, making requests, streaming, debugging, and backward compatibility.
- [OpenAI Terms of Service](https://platform.openai.com/termsGenerative): OpenAI terms of service; login required to view.
- [OpenAI Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering): Learn to write effective prompts for OpenAI models, improving your results and workflows.
- [AI Assistant Overview](https://platform.openai.com/docs/assistants/overview): Build and manage AI assistants with custom skills and knowledge for improved user experiences.
- [OpenAI Terms & Policies](https://openai.com/policies/): OpenAI's terms of use, privacy policy, service terms, and other policies regarding data, patents, plugins, and business.
- [OpenAI's o1 Model](https://platform.openai.com/docs/models/o1): OpenAI's o1 model: a powerful, adaptable language model for various tasks, offering efficient performance and cost-effectiveness.
- [Assistant Tools Integration](https://platform.openai.com/docs/assistants/tools): Extend your assistant's capabilities by integrating various tools, such as code interpreters, web browsers, and file retrieval systems.
- [Structured Data Guide](https://platform.openai.com/docs/guides/structured-): Learn how to use OpenAI's API to process structured data like tables and lists effectively.
- [OpenAI Platform FAQ](https://platform.openai.com/docs/faq/faq): Frequently Asked Questions about OpenAI's platform, services, and capabilities.
- [OpenAI Actions Library](https://platform.openai.com/docs/actions/actions-library): Explore and integrate pre-built actions to enhance your OpenAI applications.  Streamline development with readily available tools.
- [OpenAI API Tutorial](https://platform.openai.com/docs/tutorials/Please): Learn how to use the OpenAI API to build applications.  This tutorial provides a comprehensive guide and examples.


*Note: This is llms-full.txt is not complete, please enter a Firecrawl API key to get the entire llms-full.txt at llmstxt.firecrawl.dev or you can access llms.txt via API with curl -X GET 'http://llmstxt.firecrawl.dev/https://platform.openai.com/docs/api-reference/introduction?FIRECRAWL_API_KEY=YOUR_API_KEY' or llms-full.txt via API with curl -X GET 'http://llmstxt.firecrawl.dev/https://platform.openai.com/docs/api-reference/introduction/full?FIRECRAWL_API_KEY=YOUR_API_KEY'

# https://platform.openai.com/docs/api-reference/introduction llms-full.txt

Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

# OpenAI Subprocessor List

Copy page

This page provides information about the Subprocessors OpenAI has engaged to provide processing activities on Customer Data as defined in the OpenAI Data Processing Agreement.

### Subscribe to new Subprocessor notifications

Customers may sign up to receive notification of new Subprocessors by filling out [this form](https://share.hsforms.com/12eQCIydyQYSBVsV-pan8yQ4sk30).

* * *

| Subprocessor Name | Purpose | Location |
| --- | --- | --- |
| Cloudflare | Content delivery | Worldwide |
| Microsoft | Cloud infrastructure | Worldwide |
| OpenAI affiliates | Services and support | United States |
| Snowflake | Data warehousing | United States |
| TaskUS | User support, safety and monitoring | Worldwide |

Please contact [privacy@openai.com](mailto:privacy@openai.com) with any questions or concerns.Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

# Key concepts

Copy page

Key concepts to understand when working with the OpenAI API.

At OpenAI, protecting user data is fundamental to our mission. We do not train our
models on inputs and outputs through our API. Learn more on our
[API data privacy page](https://openai.com/api-data-privacy).

### Text generation models

OpenAI's text generation models (often referred to as generative pre-trained transformers or "GPT" models for short), like GPT-4 and GPT-3.5, have been trained to understand natural and formal language. Models like GPT-4 allows text outputs in response to their inputs. The inputs to these models are also referred to as "prompts". Designing a prompt is essentially how you "program" a model like GPT-4, usually by providing instructions or some examples of how to successfully complete a task. Models like GPT-4 can be used across a great variety of tasks including content or code generation, summarization, conversation, creative writing, and more. Read more in our introductory [text generation guide](/docs/guides/text-generation) and in our [prompt engineering guide](/docs/guides/prompt-engineering).

### Assistants

Assistants refer to entities, which in the case of the OpenAI API are powered by large language models like GPT-4, that are capable of performing tasks for users. These assistants operate based on the instructions embedded within the context window of the model. They also usually have access to tools which allows the assistants to perform more complex tasks like running code or retrieving information from a file. Read more about assistants in our [Assistants API Overview](/docs/assistants).

### Embeddings

An embedding is a vector representation of a piece of data (e.g. some text) that is meant to preserve aspects of its content and/or its meaning. Chunks of data that are similar in some way will tend to have embeddings that are closer together than unrelated data. OpenAI offers text embedding models that take as input a text string and produce as output an embedding vector. Embeddings are useful for search, clustering, recommendations, anomaly detection, classification, and more. Read more about embeddings in our [embeddings guide](/docs/guides/embeddings).

### Tokens

Text generation and embeddings models process text in chunks called tokens. Tokens represent commonly occurring sequences of characters. For example, the string " tokenization" is decomposed as " token" and "ization", while a short and common word like " the" is represented as a single token. Note that in a sentence, the first token of each word typically starts with a space character. Check out our [tokenizer tool](/tokenizer) to test specific strings and see how they are translated into tokens. As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text.

One limitation to keep in mind is that for a text generation model the prompt and the generated output combined must be no more than the model's maximum context length. For embeddings models (which do not output tokens), the input must be shorter than the model's maximum context length. The maximum context lengths for each text generation and embeddings model can be found in the [model index](/docs/models).Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)Log in [Sign up](/signup)

# Sending and returning files with GPT Actions

Copy page

## Sending files

POST requests can include up to ten files (including DALL-E generated images) from the conversation. They will be sent as URLs which are valid for five minutes.

For files to be part of your POST request, the parameter must be named `openaiFileIdRefs` and the description should explain to the model the type and quantity of the files which your API is expecting.

The `openaiFileIdRefs` parameter will be populated with an array of JSON objects. Each object contains:

- `name` The name of the file. This will be an auto generated name when created by DALL-E.
- `id` A stable identifier for the file.
- `mime_type` The mime type of the file. For user uploaded files this is based on file extension.
- `download_link` The URL to fetch the file which is valid for five minutes.

Here’s an example of an `openaiFileIdRefs` array with two elements:

```text
1
2
3
4
5
6
7
8
9
10
11
12
13
14
[\
  {\
    "name": "dalle-Lh2tg7WuosbyR9hk",\
    "id": "file-XFlOqJYTPBPwMZE3IopCBv1Z",\
    "mime_type": "image/webp",\
    "download_link": "https://files.oaiusercontent.com/file-XFlOqJYTPBPwMZE3IopCBv1Z?se=2024-03-11T20%3A29%3A52Z&sp=r&sv=2021-08-06&sr=b&rscc=max-age%3D31536000%2C%20immutable&rscd=attachment%3B%20filename%3Da580bae6-ea30-478e-a3e2-1f6c06c3e02f.webp&sig=ZPWol5eXACxU1O9azLwRNgKVidCe%2BwgMOc/TdrPGYII%3D"\
  },\
  {\
    "name": "2023 Benefits Booklet.pdf",\
    "id": "file-s5nX7o4junn2ig0J84r8Q0Ew",\
    "mime_type": "application/pdf",\
    "download_link": "https://files.oaiusercontent.com/file-s5nX7o4junn2ig0J84r8Q0Ew?se=2024-03-11T20%3A29%3A52Z&sp=r&sv=2021-08-06&sr=b&rscc=max-age%3D299%2C%20immutable&rscd=attachment%3B%20filename%3D2023%2520Benefits%2520Booklet.pdf&sig=Ivhviy%2BrgoyUjxZ%2BingpwtUwsA4%2BWaRfXy8ru9AfcII%3D"\
  }\
]
```

Actions can include files uploaded by the user, images generated by DALL-E, and files created by Code Interpreter.

### OpenAPI Example

```text
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
/createWidget:
    post:
      operationId: createWidget
      summary: Creates a widget based on an image.
      description: Uploads a file reference using its file id. This file should be an image created by DALL·E or uploaded by the user. JPG, WEBP, and PNG are supported for widget creation.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                openaiFileIdRefs:
                  type: array
                  items:
                    type: string
```

While this schema shows `openaiFileIdRefs` as being an array of type `string`, at runtime this will be populated with an array of JSON objects as previously shown.

## Returning files

Requests may return up to 10 files. Each file may be up to 10 MB and cannot be an image or video.

These files will become part of the conversation similarly to if a user uploaded them, meaning they may be made available to code interpreter, file search, and sent as part of subsequent action invocations. In the web app users will see that the files have been returned and can download them.

To return files, the body of the response must contain an `openaiFileResponse` parameter. This parameter must always be an array and must be populated in one of two ways.

### Inline option

Each element of the array is a JSON object which contains:

- `name` The name of the file. This will be visible to the user.
- `mime_type` The MIME type of the file. This is used to determine eligibility and which features have access to the file.
- `content` The base64 encoded contents of the file.

Here’s an example of an openaiFileResponse array with two elements:

```text
1
2
3
4
5
6
7
8
9
10
11
12
[\
  {\
    "name": "example_document.pdf",\
    "mime_type": "application/pdf",\
    "content": "JVBERi0xLjQKJcfsj6IKNSAwIG9iago8PC9MZW5ndGggNiAwIFIvRmlsdGVyIC9GbGF0ZURlY29kZT4+CnN0cmVhbQpHhD93PQplbmRzdHJlYW0KZW5kb2JqCg=="\
  },\
  {\
    "name": "sample_spreadsheet.csv",\
    "mime_type": "text/csv",\
    "content": "iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg=="\
  }\
]
```

OpenAPI example

```text
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
/papers:
  get:
    operationId: findPapers
    summary: Retrieve PDFs of relevant academic papers.
    description: Provided an academic topic, up to five relevant papers will be returned as PDFs.
    parameters:
      - in: query
        name: topic
        required: true
        schema:
          type: string
        description: The topic the papers should be about.
    responses:
      '200':
        description: Zero to five academic paper PDFs
        content:
            application/json:
              schema:
                type: object
                properties:
                  openaiFileResponse:
                    type: array
                    items:
                      type: object
                      properties:
                        name:
                          type: string
                          description: The name of the file.
                        mime_type:
                          type: string
                          description: The MIME type of the file.
                        content:
                          type: string
                          format: byte
                          description: The content of the file in base64 encoding.
```

### URL option

Each element of the array is a URL referencing a file to be downloaded. The headers `Content-Disposition` and `Content-Type` must be set such that a file name and MIME type can be determined. The name of the file will be visible to the user. The MIME type of the file determines eligibility and which features have access to the file.

There is a 10 second timeout for fetching each file.

Here’s an example of an `openaiFileResponse` array with two elements:

```text
1
2
3
4
[\
  "https://example.com/f/dca89f18-16d4-4a65-8ea2-ededced01646",\
  "https://example.com/f/01fad6b0-635b-4803-a583-0f678b2e6153"\
]
```

Here’s an example of the required headers for each URL:

```text
Content-Type: application/pdf
Content-Disposition: attachment; filename="example_document.pdf"
```

OpenAPI example

```/papers:
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
get:
    operationId: findPapers
    summary: Retrieve PDFs of relevant academic papers.
    description: Provided an academic topic, up to five relevant papers will be returned as PDFs.
    parameters:
      - in: query
        name: topic
        required: true
        schema:
          type: string
        description: The topic the papers should be about.
    responses:
      '200':
        description: Zero to five academic paper PDFs
        content:
            application/json:
              schema:
                type: object
                properties:
                  openaiFileResponse:
                    type: array
                    items:
                    type: string
                    format: uri
                    description: URLs to fetch the files.
```OpenAI

[**ChatGPT**\\
\\
Interact with our flagship language models in a conversational interface](https://chatgpt.com/auth/login) [**API**\\
\\
Integrate OpenAI models into your application or business](/)Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

# Developer quickstart

Copy page

Learn how to make your first API request.

The OpenAI API provides a simple interface to state-of-the-art AI [models](/docs/models) for natural language processing, image generation, semantic search, and speech recognition. Follow this guide to learn how to generate human-like responses to [natural language prompts](/docs/guides/text-generation), [create vector embeddings](/docs/guides/embeddings) for semantic search, and [generate images](/docs/guides/images) from textual descriptions.

## Create and export an API key

[Create an API key in the dashboard here](/api-keys), which you’ll use to securely [access the API](/docs/api-reference/authentication). Store the key in a safe location, like a [`.zshrc` file](https://www.freecodecamp.org/news/how-do-zsh-configuration-files-work/) or another text file on your computer. Once you’ve generated an API key, export it as an [environment variable](https://en.wikipedia.org/wiki/Environment_variable) in your terminal.

macOS / LinuxWindows

Export an environment variable on macOS or Linux systems

```bash
1
export OPENAI_API_KEY="your_api_key_here"
```

## Make your first API request

With your OpenAI API key exported as an environment variable, you're ready to make your first API request. You can either use the [REST API](/docs/api-reference) directly with the HTTP client of your choice, or use one of our [official SDKs](/docs/libraries) as shown below.

JavaScriptPythoncurl

To use the OpenAI API in server-side JavaScript environments like Node.js, Deno, or Bun, you can use the official [OpenAI SDK for TypeScript and JavaScript](https://github.com/openai/openai-node). Get started by installing the SDK using [npm](https://www.npmjs.com/) or your preferred package manager:

Install the OpenAI SDK with npm

```bash
1
npm install openai
```

With the OpenAI SDK installed, create a file called `example.mjs` and copy one of the following examples into it:

Generate textGenerate an imageCreate vector embeddings

Create a human-like response to a prompt

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import OpenAI from "openai";
const openai = new OpenAI();

const completion = await openai.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [\
        { role: "system", content: "You are a helpful assistant." },\
        {\
            role: "user",\
            content: "Write a haiku about recursion in programming.",\
        },\
    ],
});

console.log(completion.choices[0].message);
```

Execute the code with `node example.mjs` (or the equivalent command for Deno or Bun). In a few moments, you should see the output of your API request!

## Next steps

Now that you've made your first OpenAI API request, you can explore the following resources:

[Chat Completions\\
\\
Learn more about generating text responses to natural language prompts](/docs/guides/text-generation) [Image Generation\\
\\
Generate images using our DALL·E model](/docs/guides/images) [Embeddings\\
\\
Create vector representations of text, used for similarity search](/docs/guides/embeddings) [Text-to-speech\\
\\
Generate human-like voice recordings with our text-to-speech model](/docs/guides/text-to-speech) [Speech-to-text\\
\\
Create transcriptions of voice recordings with our Whisper model](/docs/guides/speech-to-text) [Moderation\\
\\
Analyze and filter user-created content with our moderation model](/docs/guides/moderation) [Fine-tuning\\
\\
Fine-tune our models with your own data](/docs/guides/fine-tuning) [Batch\\
\\
Batch requests for async jobs](/docs/guides/batch) [Full API Reference\\
\\
View the full REST API reference for OpenAI](/docs/api-reference)# Oops!

We ran into an issue while authenticating you. If this issue persists, please contact us through our help center at https://help.openai.com.

Return to homepageLog in [Sign up](/signup)

# Supported countries and territories

Copy page

Countries and territories that currently support access to our API services.

Accessing or offering access to our services outside of the countries and territories listed below may result in your account being blocked or suspended.

- Albania
- Algeria
- Afghanistan
- Andorra
- Angola
- Antigua and Barbuda
- Argentina
- Armenia
- Australia
- Austria
- Azerbaijan
- Bahamas
- Bahrain
- Bangladesh
- Barbados
- Belgium
- Belize
- Benin
- Bhutan
- Bolivia
- Bosnia and Herzegovina
- Botswana
- Brazil
- Brunei
- Bulgaria
- Burkina Faso
- Burundi
- Cabo Verde
- Cambodia
- Cameroon
- Canada
- Central African Republic
- Chad
- Chile
- Colombia
- Comoros
- Congo (Brazzaville)
- Congo (DRC)
- Costa Rica
- Côte d'Ivoire
- Croatia
- Cyprus
- Czechia (Czech Republic)
- Denmark
- Djibouti
- Dominica
- Dominican Republic
- Ecuador
- Egypt
- El Salvador
- Equatorial Guinea
- Eritrea
- Estonia
- Eswatini (Swaziland)
- Ethiopia
- Fiji
- Finland
- France
- Gabon
- Gambia
- Georgia
- Germany
- Ghana
- Greece
- Grenada
- Guatemala
- Guinea
- Guinea-Bissau
- Guyana
- Haiti
- Holy See (Vatican City)
- Honduras
- Hungary
- Iceland
- India
- Indonesia
- Iraq
- Ireland
- Israel
- Italy
- Jamaica
- Japan
- Jordan
- Kazakhstan
- Kenya
- Kiribati
- Kuwait
- Kyrgyzstan
- Laos
- Latvia
- Lebanon
- Lesotho
- Liberia
- Libya
- Liechtenstein
- Lithuania
- Luxembourg
- Madagascar
- Malawi
- Malaysia
- Maldives
- Mali
- Malta
- Marshall Islands
- Mauritania
- Mauritius
- Mexico
- Micronesia
- Moldova
- Monaco
- Mongolia
- Montenegro
- Morocco
- Mozambique
- Myanmar
- Namibia
- Nauru
- Nepal
- Netherlands
- New Zealand
- Nicaragua
- Niger
- Nigeria
- North Macedonia
- Norway
- Oman
- Pakistan
- Palau
- Palestine
- Panama
- Papua New Guinea
- Paraguay
- Peru
- Philippines
- Poland
- Portugal
- Qatar
- Romania
- Rwanda
- Saint Kitts and Nevis
- Saint Lucia
- Saint Vincent and the Grenadines
- Samoa
- San Marino
- Sao Tome and Principe
- Saudi Arabia
- Senegal
- Serbia
- Seychelles
- Sierra Leone
- Singapore
- Slovakia
- Slovenia
- Solomon Islands
- Somalia
- South Africa
- South Korea
- South Sudan
- Spain
- Sri Lanka
- Suriname
- Sweden
- Switzerland
- Sudan
- Taiwan
- Tajikistan
- Tanzania
- Thailand
- Timor-Leste (East Timor)
- Togo
- Tonga
- Trinidad and Tobago
- Tunisia
- Turkey
- Turkmenistan
- Tuvalu
- Uganda
- Ukraine (with certain exceptions)
- United Arab Emirates
- United Kingdom
- United States of America
- Uruguay
- Uzbekistan
- Vanuatu
- Vietnam
- Yemen
- Zambia
- ZimbabweLog in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign upLog in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

# Model selection

Copy page

Choose the best model for performance and cost.

Choosing the right model, whether GPT-4o or a smaller option like GPT-4o-mini, requires balancing **accuracy**, **latency**, and **cost**. This guide explains key principles to help you make informed decisions, along with a practical example.

## Core Principles

The principles for model selection are simple:

- **Optimize for accuracy first:** Optimize for accuracy until you hit your accuracy target.
- **Optimize for cost and latency second:** Then aim to maintain accuracy with the cheapest, fastest model possible.

### 1\. Focus on Accuracy First

Begin by setting a clear accuracy goal for your use case, where you're clear on the accuracy that would be "good enough" for this use case to go to production. You can accomplish this through:

- **Setting a clear accuracy target:** Identify what your target accuracy statistic is going to be.

  - For example, 90% of customer service calls need to be triaged correctly at the first interaction.
- **Developing an evaluation dataset:** Create a dataset that allows you to measure the model's performance against these goals.

  - To extend the example above, capture 100 interaction examples where we have what the user asked for, what the LLM triaged them to, what the correct triage should be, and whether this was correct or not.
- **Using the most powerful model to optimize:** Start with the most capable model available to achieve your accuracy targets. Log all responses so we can use them for distillation of a smaller model.

  - Use retrieval-augmented generation to optimize for accuracy
  - Use fine-tuning to optimize for consistency and behavior

During this process, collect prompt and completion pairs for use in evaluations, few-shot learning, or fine-tuning. This practice, known as **prompt baking**, helps you produce high-quality examples for future use.

For more methods and tools here, see our [Accuracy Optimization Guide](https://platform.openai.com/docs/guides/optimizing-llm-accuracy).

#### Setting a realistic accuracy target

Calculate a realistic accuracy target by evaluating the financial impact of model decisions. For example, in a fake news classification scenario:

- **Correctly classified news:** If the model classifies it correctly, it saves you the cost of a human reviewing it - let's assume **$50**.
- **Incorrectly classified news:** If it falsely classifies a safe article or misses a fake news article, it may trigger a review process and possible complaint, which might cost us **$300**.

Our news classification example would need **85.8%** accuracy to cover costs, so targeting 90% or more ensures an overall return on investment. Use these calculations to set an effective accuracy target based on your specific cost structures.

### 2\. Optimize cost and latency

Cost and latency are considered secondary because if the model can’t hit your accuracy target then these concerns are moot. However, once you’ve got a model that works for your use case, you can take one of two approaches:

- **Compare with a smaller model zero- or few-shot:** Swap out the model for a smaller, cheaper one and test whether it maintains accuracy at the lower cost and latency point.
- **Model distillation:** Fine-tune a smaller model using the data gathered during accuracy optimization.

Cost and latency are typically interconnected; reducing tokens and requests generally leads to faster processing.

The main strategies to consider here are:

- **Reduce requests:** Limit the number of necessary requests to complete tasks.
- **Minimize tokens:** Lower the number of input tokens and optimize for shorter model outputs.
- **Select a smaller model:** Use models that balance reduced costs and latency with maintained accuracy.

To dive deeper into these, please refer to our guide on [latency optimization](https://platform.openai.com/docs/guides/latency-optimization).

#### Exceptions to the rule

Clear exceptions exist for these principles. If your use case is extremely cost or latency sensitive, establish thresholds for these metrics before beginning your testing, then remove the models that exceed those from consideration. Once benchmarks are set, these guidelines will help you refine model accuracy within your constraints.

## Practical example

To demonstrate these principles, we'll develop a fake news classifier with the following target metrics:

- **Accuracy:** Achieve 90% correct classification
- **Cost:** Spend less than $5 per 1,000 articles
- **Latency:** Maintain processing time under 2 seconds per article

### Experiments

We ran three experiments to reach our goal:

1. **Zero-shot:** Used `GPT-4o` with a basic prompt for 1,000 records, but missed the accuracy target.
2. **Few-shot learning:** Included 5 few-shot examples, meeting the accuracy target but exceeding cost due to more prompt tokens.
3. **Fine-tuned model:** Fine-tuned `GPT-4o-mini` with 1,000 labeled examples, meeting all targets with similar latency and accuracy but significantly lower costs.

| ID | Method | Accuracy | Accuracy target | Cost | Cost target | Avg. latency | Latency target |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | gpt-4o zero-shot | 84.5% |  | $1.72 |  | < 1s |  |
| 2 | gpt-4o few-shot (n=5) | 91.5% | ✓ | $11.92 |  | < 1s | ✓ |
| 3 | gpt-4o-mini fine-tuned w/ 1000 examples | 91.5% | ✓ | $0.21 | ✓ | < 1s | ✓ |

## Conclusion

By switching from `gpt-4o` to `gpt-4o-mini` with fine-tuning, we achieved **equivalent performance for less than 2%** of the cost, using only 1,000 labeled examples.

This process is important - you often can’t jump right to fine-tuning because you don’t know whether fine-tuning is the right tool for the optimization you need, or you don’t have enough labeled examples. Use `gpt-4o` to achieve your accuracy targets, and curate a good training set - then go for a smaller, more efficient model with fine-tuning.Log in [Sign up](/signup)

# OpenAI developer platform

[Developer quickstart\\
\\
Set up your environment and make your first API request in minutes\\
\\
5 min](/docs/quickstart)

node.js

```javascript
1
2
3
4
5
6
7
8
import OpenAI from "openai";
const openai = new OpenAI();
const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [\
        {"role": "user", "content": "write a haiku about ai"}\
    ]
});
```

## Meet the models

[Pricing](https://openai.com/api/pricing)

[GPT-4o\\
\\
Our high-intelligence flagship model for complex, multi‑step tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Smarter model, higher price per token](/docs/models#gpt-4o)

[GPT-4o mini\\
\\
Our affordable and intelligent small model for fast, lightweight tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Faster model, lower price per token](/docs/models#gpt-4o-mini)

[o1-preview & o1-mini\\
\\
Beta\\
\\
A new series of reasoning models for solving hard problems\\
\\
Text input, text output\\
\\
128k context length\\
\\
Higher latency, uses tokens to think](/docs/models#o1)

[Explore all](/docs/models)

## Start building

[Structured Outputs\\
\\
Ensure model responses adhere to your supplied JSON schema](/docs/guides/structured-outputs) [Realtime API\\
\\
Build low-latency multimodal experiences](/docs/guides/realtime) [Assistants API\\
\\
Build conversational assistants with tools and File Search](/docs/assistants) [Async use cases\\
\\
Batch requests for async, large-scale processing](/docs/guides/batch) [Fine-tuning\\
\\
Adapt a model to your specific use case with your data](/docs/guides/fine-tuning) [Distillation\\
\\
Evaluate and fine-tune models using production logs](/docs/guides/distillation)

## Explore our guides

[Prompt engineering\\
\\
Get better results from LLMs](/docs/guides/prompt-engineering) [Production best practices\\
\\
Transition from prototype to production](/docs/guides/production-best-practices) [Safety best practices\\
\\
Make sure your application is safe](/docs/guides/safety-best-practices) [Latency optimization\\
\\
Improve latency across multiple use cases](/docs/guides/latency-optimization) [Optimizing LLM accuracy\\
\\
Maximize correctness and consistent behavior of LLMs](/docs/guides/optimizing-llm-accuracy)

[Help center\\
\\
Frequently asked account and billing questions](https://help.openai.com/) [Developer forum\\
\\
Discuss topics with other developers](https://community.openai.com/) [Cookbook\\
\\
Open-source collection of examples and guides](https://cookbook.openai.com/) [Status\\
\\
Check the status of OpenAI services](https://status.openai.com)Log in [Sign up](/signup)

# Text generation

Copy page

Learn how to generate text from a prompt.

OpenAI provides simple APIs to use a [large language model](/docs/models) to generate text from a prompt, as you might using [ChatGPT](https://chatgpt.com). These models have been trained on vast quantities of data to understand multimedia inputs and natural language instructions. From these [prompts](/docs/guides/prompt-engineering), models can generate almost any kind of text response, like code, mathematical equations, structured JSON data, or human-like prose.

## Quickstart

To generate text, you can use the [chat completions endpoint](/docs/api-reference/chat/) in the REST API, as seen in the examples below. You can either use the [REST API](/docs/api-reference) from the HTTP client of your choice, or use one of OpenAI's [official SDKs](/docs/libraries) for your preferred programming language.

Generate proseAnalyze an imageGenerate JSON data

Create a human-like response to a prompt

javascript

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import OpenAI from "openai";
const openai = new OpenAI();

const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [\
        { role: "system", content: "You are a helpful assistant." },\
        {\
            role: "user",\
            content: "Write a haiku about recursion in programming.",\
        },\
    ],
});

console.log(completion.choices[0].message);
```

## Choosing a model

When making a text generation request, the first option to configure is which [model](/docs/models) you want to generate the response. The model you choose can greatly influence the output, and impact how much each generation request [costs](https://openai.com/api/pricing/).

- A **large model** like [`gpt-4o`](/docs/models#gpt-4o) will offer a very high level of intelligence and strong performance, while having a higher cost per token.
- A **small model** like [`gpt-4o-mini`](/docs/models#gpt-4o-mini) offers intelligence not quite on the level of the larger model, but is faster and less expensive per token.
- A **reasoning model** like [the `o1` family of models](/docs/models#o1) is slower to return a result, and uses more tokens to "think", but is capable of advanced reasoning, coding, and multi-step planning.

Experiment with different models [in the Playground](/playground) to see which one works best for your prompts! More information on choosing a model can [also be found here](/docs/guides/model-selection).

## Building prompts

The process of crafting prompts to get the right output from a model is called **prompt engineering**. By giving the model precise instructions, examples, and necessary context information (like private or specialized information that wasn't included in the model's training data), you can improve the quality and accuracy of the model's output. Here, we'll get into some high-level guidance on building prompts, but you might also find the [prompt engineering guide](/docs/guides/prompt-engineering) helpful.

In the [chat completions](/docs/api-reference/chat/) API, you create prompts by providing an array of `messages` that contain instructions for the model. Each message can have a different `role`, which influences how the model might interpret the input.

### User messages

User messages contain instructions that request a particular type of output from the model. You can think of `user` messages as the messages you might type in to [ChatGPT](https://chaptgpt.com) as an end user.

Here's an example of a user message prompt that asks the `gpt-4o` model to generate a haiku poem based on a prompt.

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": "Write a haiku about programming."\
        }\
      ]\
    }\
  ]
});
```

### System messages

Messages with the `system` role act as top-level instructions to the model, and typically describe what the model is supposed to do and how it should generally behave and respond.

Here's an example of a system message that modifies the behavior of the model when generating a response to a `user` message:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "system",\
      "content": [\
        {\
          "type": "text",\
          "text": `\
            You are a helpful assistant that answers programming questions\
            in the style of a southern belle from the southeast United States.\
          `\
        }\
      ]\
    },\
    {\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": "Are semicolons optional in JavaScript?"\
        }\
      ]\
    }\
  ]
});
```

This prompt returns a text output in the rhetorical style requested:

```text
1
2
3
4
5
6
7
8
Well, sugar, that's a fine question you've got there! Now, in the world of
JavaScript, semicolons are indeed a bit like the pearls on a necklace – you
might slip by without 'em, but you sure do look more polished with 'em in place.

Technically, JavaScript has this little thing called "automatic semicolon
insertion" where it kindly adds semicolons for you where it thinks they
oughta go. However, it's not always perfect, bless its heart. Sometimes, it
might get a tad confused and cause all sorts of unexpected behavior.
```

### Assistant messages

Messages with the `assistant` role are presumed to have been generated by the model, perhaps in a previous generation request (see the "Conversations" section below). They can also be used to provide examples to the model for how it should respond to the current request - a technique known as **few-shot learning**.

Here's an example of using an assistant message to capture the results of a previous text generation result, and making a new request based on that.

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "knock knock." }]\
    },\
    {\
      "role": "assistant",\
      "content": [{ "type": "text", "text": "Who's there?" }]\
    },\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "Orange." }]\
    }\
  ]
});
```

### Giving the model additional data to use for generation

The message types above can also be used to provide additional information to the model which may be outside its training data. You might want to include the results of a database query, a text document, or other resources to help the model generate a relevant response. This technique is often referred to as **retrieval augmented generation**, or RAG. [Learn more about RAG techniques here](https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts).

## Conversations and context

While each text generation request is independent and stateless (unless you are using [assistants](/docs/assistants/overview)), you can still implement **multi-turn conversations** by providing additional messages as parameters to your text generation request. Consider the "knock knock" joke example shown above:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "knock knock." }]\
    },\
    {\
      "role": "assistant",\
      "content": [{ "type": "text", "text": "Who's there?" }]\
    },\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "Orange." }]\
    }\
  ]
});
```

By using alternating `user` and `assistant` messages, you can capture the previous state of a conversation in one request to the model.

### Managing context for text generation

As your inputs become more complex, or you include more and more turns in a conversation, you will need to consider both **output token** and **context window** limits. Model inputs and outputs are metered in [**tokens**](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them), which are parsed from inputs to analyze their content and intent, and assembled to render logical outputs. Models have limits on how many tokens can be used during the lifecycle of a text generation request.

- **Output tokens** are the tokens that are generated by a model in response to a prompt. Each model supports different limits for output tokens, [documented here](/docs/models). For example, `gpt-4o-2024-08-06` can generate a maximum of 16,384 output tokens.
- A **context window** describes the total tokens that can be used for both input tokens and output tokens (and for some models, [reasoning tokens](/docs/guides/reasoning)), [documented here](/docs/models). For example, `gpt-4o-2024-08-06` has a total context window of 128k tokens.

If you create a very large prompt (usually by including a lot of conversation context or additional data/examples for the model), you run the risk of exceeding the allocated context window for a model, which might result in truncated outputs.

You can use the [tokenizer tool](/tokenizer) (which uses the [tiktoken library](https://github.com/openai/tiktoken)) to see how many tokens are present in a string of text.

## Optimizing model outputs

As you iterate on your prompts, you will be continually trying to improve **accuracy**, **cost**, and **latency**.

|  | Goal | Available techniques |
| --- | --- | --- |
| **Accuracy** | Ensure the model produces accurate and useful responses to your prompts. | Accurate responses require that the model has all the information it needs<br>to generate a response, and knows how to go about creating a response<br>(from interpreting input to formatting and styling). Often, this will<br>require a mix of [prompt engineering](/docs/guides/prompt-engineering),<br>[RAG](https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts),<br>and [model fine-tuning](/docs/guides/fine-tuning).<br>[Learn about optimizing for accuracy here](/docs/guides/optimizing-llm-accuracy). |
| **Cost** | Drive down the total cost of model usage by reducing token usage and using cheaper models when possible. | To control costs, you can try to use fewer tokens or smaller, cheaper models.<br>[Learn more about optimizing for cost here](/docs/guides/model-selection). |
| **Latency** | Decrease the time it takes to generate responses to your prompts. | Optimizing latency is a multi-faceted process including prompt engineering,<br>parallelism in your own code, and more.<br>[Learn more here](/docs/guides/latency-optimization). |

## Next steps

There's much more to explore in text generation - here's a few resources to go even deeper.

[Prompt examples\\
\\
Get inspired by example prompts for a variety of use cases.](/docs/examples) [Build a prompt in the Playground\\
\\
Use the Playground to develop and iterate on prompts.](/playground) [Browse the Cookbook\\
\\
The Cookbook has complex examples covering a variety of use cases.](/docs/guides/https://cookbook.openai.com) [Generate JSON data with Structured Outputs\\
\\
Ensure JSON data emitted from a model conforms to a JSON schema.](/docs/guides/structured-outputs) [Full API reference\\
\\
Check out all the options for text generation in the API reference.](/docs/api-reference/chat)Log in [Sign up](/signup)

# Libraries

Copy page

Explore libraries for Python, Node.js, .NET, and more.

## Python library

We provide a [Python library](https://github.com/openai/openai-python), which you can install by running:

```bash
pip install openai
```

Once installed, you can use the library and your secret key to run the following:

```python
1
2
3
4
5
6
7
8
9
from openai import OpenAI
client = OpenAI(
    # Defaults to os.environ.get("OPENAI_API_KEY")
)

chat_completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello world"}]
)
```

The bindings also will install a command-line utility you can use as follows:

```bash
$ openai api chat_completions.create -m gpt-4o-mini -g user "Hello world"
```

* * *

## TypeScript / JavaScript library

We provide a [TypeScript / JavaScript library](https://github.com/openai/openai-node) with support for Node.js and various [other runtimes](https://deno.land/x/openai). Install it by running:

```bash
1
2
3
npm install --save openai
# or
yarn add openai
```

Once installed, you can use the library and your secret key to run the following:

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from "openai";

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

const chatCompletion = await openai.chat.completions.create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-4o-mini",
});
```

* * *

## .NET library

We provide a [.NET library](https://github.com/openai/openai-dotnet), which you can install by running:

```text
dotnet add package OpenAI
```

Once installed, you can use the library and your secret key to run the following:

```csharp
1
2
3
4
5
using OpenAI.Chat;

ChatClient client = new(model: "gpt-4o-mini",  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY"));

ChatCompletion chatCompletion = client.CompleteChat("Say 'this is a test.'");
```

* * *

## Azure OpenAI libraries

Microsoft's Azure team maintains libraries that are compatible with both the OpenAI API and Azure OpenAI services. Read the library documentation below to learn how you can use them with the OpenAI API.

- [Azure OpenAI client library for .NET](https://github.com/Azure/azure-sdk-for-net/tree/main/sdk/openai/Azure.AI.OpenAI)
- [Azure OpenAI client library for JavaScript](https://github.com/Azure/azure-sdk-for-js/tree/main/sdk/openai/openai)
- [Azure OpenAI client library for Java](https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/openai/azure-ai-openai)
- [Azure OpenAI client library for Go](https://github.com/Azure/azure-sdk-for-go/tree/main/sdk/ai/azopenai)

* * *

## Community libraries

The libraries below are built and maintained by the broader developer community. If you'd like to add a new library here, please follow the instructions in our [help center article](https://help.openai.com/en/articles/6684216-adding-your-api-client-to-the-community-libraries-page) on adding community libraries. You can also [watch our OpenAPI specification](https://github.com/openai/openai-openapi) repository on GitHub to get timely updates on when we make changes to our API.

Please note that OpenAI does not verify the correctness or security of these projects. **Use them at your own risk!**

### C\# / .NET

- [Betalgo.OpenAI](https://github.com/betalgo/openai) by [Betalgo](https://github.com/betalgo)
- [OpenAI-API-dotnet](https://github.com/OkGoDoIt/OpenAI-API-dotnet) by [OkGoDoIt](https://github.com/OkGoDoIt)
- [OpenAI-DotNet](https://github.com/RageAgainstThePixel/OpenAI-DotNet) by [RageAgainstThePixel](https://github.com/RageAgainstThePixel)

### C++

- [liboai](https://github.com/D7EAD/liboai) by [D7EAD](https://github.com/D7EAD)

### Clojure

- [openai-clojure](https://github.com/wkok/openai-clojure) by [wkok](https://github.com/wkok)

### Crystal

- [openai-crystal](https://github.com/sferik/openai-crystal) by [sferik](https://github.com/sferik)

### Dart/Flutter

- [openai](https://github.com/anasfik/openai) by [anasfik](https://github.com/anasfik)

### Delphi

- [DelphiOpenAI](https://github.com/HemulGM/DelphiOpenAI) by [HemulGM](https://github.com/HemulGM)

### Elixir

- [openai.ex](https://github.com/mgallo/openai.ex) by [mgallo](https://github.com/mgallo)

### Go

- [go-gpt3](https://github.com/sashabaranov/go-gpt3) by [sashabaranov](https://github.com/sashabaranov)

### Java

- [openai-java](https://github.com/TheoKanning/openai-java) by [Theo Kanning](https://github.com/TheoKanning)

### Julia

- [OpenAI.jl](https://github.com/rory-linehan/OpenAI.jl) by [rory-linehan](https://github.com/rory-linehan)

### Kotlin

- [openai-kotlin](https://github.com/Aallam/openai-kotlin) by [Mouaad Aallam](https://github.com/Aallam)

### Node.js

- [openai-api](https://www.npmjs.com/package/openai-api) by [Njerschow](https://github.com/Njerschow)
- [openai-api-node](https://www.npmjs.com/package/openai-api-node) by [erlapso](https://github.com/erlapso)
- [gpt-x](https://www.npmjs.com/package/gpt-x) by [ceifa](https://github.com/ceifa)
- [gpt3](https://www.npmjs.com/package/gpt3) by [poteat](https://github.com/poteat)
- [gpts](https://www.npmjs.com/package/gpts) by [thencc](https://github.com/thencc)
- [@dalenguyen/openai](https://www.npmjs.com/package/@dalenguyen/openai) by [dalenguyen](https://github.com/dalenguyen)
- [tectalic/openai](https://github.com/tectalichq/public-openai-client-js) by [tectalic](https://tectalic.com/)

### PHP

- [orhanerday/open-ai](https://packagist.org/packages/orhanerday/open-ai) by [orhanerday](https://github.com/orhanerday)
- [tectalic/openai](https://github.com/tectalichq/public-openai-client-php) by [tectalic](https://tectalic.com/)
- [openai-php client](https://github.com/openai-php/client) by [openai-php](https://github.com/openai-php)

### Python

- [chronology](https://github.com/OthersideAI/chronology) by [OthersideAI](https://www.othersideai.com/)

### R

- [rgpt3](https://github.com/ben-aaron188/rgpt3) by [ben-aaron188](https://github.com/ben-aaron188)

### Ruby

- [openai](https://github.com/nileshtrivedi/openai/) by [nileshtrivedi](https://github.com/nileshtrivedi)
- [ruby-openai](https://github.com/alexrudall/ruby-openai) by [alexrudall](https://github.com/alexrudall)

### Rust

- [async-openai](https://github.com/64bit/async-openai) by [64bit](https://github.com/64bit)
- [fieri](https://github.com/lbkolev/fieri) by [lbkolev](https://github.com/lbkolev)

### Scala

- [openai-scala-client](https://github.com/cequence-io/openai-scala-client) by [cequence-io](https://github.com/cequence-io)

### Swift

- [OpenAIKit](https://github.com/dylanshine/openai-kit) by [dylanshine](https://github.com/dylanshine)
- [OpenAI](https://github.com/MacPaw/OpenAI/) by [MacPaw](https://github.com/MacPaw)

### Unity

- [OpenAi-Api-Unity](https://github.com/hexthedev/OpenAi-Api-Unity) by [hexthedev](https://github.com/hexthedev)
- [com.openai.unity](https://github.com/RageAgainstThePixel/com.openai.unity) by [RageAgainstThePixel](https://github.com/RageAgainstThePixel)

### Unreal Engine

- [OpenAI-Api-Unreal](https://github.com/KellanM/OpenAI-Api-Unreal) by [KellanM](https://github.com/KellanM)

## Other OpenAI repositories

- [tiktoken](https://github.com/openai/tiktoken) \- counting tokens
- [simple-evals](https://github.com/openai/simple-evals) \- simple evaluation library
- [mle-bench](https://github.com/openai/mle-bench) \- library to evaluate machine learning engineer agents
- [gym](https://github.com/openai/gym) \- reinforcement learning library
- [swarm](https://github.com/openai/swarm) \- educational orchestration repositoryLog in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

# Predicted Outputs

Copy page

Reduce latency for model responses where much of the response is known ahead of time.

**Predicted Outputs** enable you to speed up API responses from [Chat Completions](/docs/api-reference/chat/create) when many of the output tokens are known ahead of time. This is most common when you are regenerating a text or code file with minor modifications. You can provide your prediction using the [`prediction` request parameter in Chat Completions](/docs/api-reference/chat/create#chat-create-prediction).

Predicted Outputs are available today using the latest `gpt-4o` and `gpt-4o-mini` models. Read on to learn how to use Predicted Outputs to reduce latency in your applicatons.

## Code refactoring example

Predicted Outputs are particularly useful for regenerating text documents and code files with small modifications. Let's say you want the [GPT-4o model](/docs/models#gpt-4o) to refactor a piece of TypeScript code, and convert the `username` property of the `User` class to be `email` instead:

```typescript
1
2
3
4
5
6
7
class User {
  firstName: string = "";
  lastName: string = "";
  username: string = "";
}

export default User;
```

Most of the file will be unchanged, except for line 4 above. If you use the current text of the code file as your prediction, you can regenerate the entire file with lower latency. These time savings add up quickly for larger files.

Below is an example of using the `prediction` parameter in our SDKs to predict that the final output of the model will be very similar to our original code file, which we use as the prediction text.

Refactor a TypeScript class with a Predicted Output

javascript

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
import OpenAI from "openai";

const code = `
class User {
  firstName: string = "";
  lastName: string = "";
  username: string = "";
}

export default User;
`.trim();

const openai = new OpenAI();

const refactorPrompt = `
Replace the "username" property with an "email" property. Respond only
with code, and with no markdown formatting.
`;

const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      role: "user",\
      content: refactorPrompt\
    },\
    {\
      role: "user",\
      content: code\
    }\
  ],
  prediction: {
    type: "content",
    content: code
  }
});

// Inspect returned data
console.log(completion);
console.log(completion.choices[0].message.content);
```

In addition to the refactored code, the model response will contain data that looks something like this:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  id: 'chatcmpl-xxx',
  object: 'chat.completion',
  created: 1730918466,
  model: 'gpt-4o-2024-08-06',
  choices: [ /* ...actual text response here... */],
  usage: {
    prompt_tokens: 81,
    completion_tokens: 39,
    total_tokens: 120,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 18,
      rejected_prediction_tokens: 10
    }
  },
  system_fingerprint: 'fp_159d8341cc'
}
```

Note both the `accepted_prediction_tokens` and `rejected_prediction_tokens` in the `usage` object. In this example, 18 tokens from the prediction were used to speed up the response, while 10 were rejected.

Note that any rejected tokens are still billed like other completion tokens generated by the API, so Predicted Outputs can introduce higher costs for your requests.

## Streaming example

The latency gains of Predicted Outputs are even greater when you use streaming for API responses. Here is an example of the same code refactoring use case, but using streaming in the OpenAI SDKs instead.

Predicted Outputs with streaming

javascript

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
import OpenAI from "openai";

const code = `
class User {
  firstName: string = "";
  lastName: string = "";
  username: string = "";
}

export default User;
`.trim();

const openai = new OpenAI();

const refactorPrompt = `
Replace the "username" property with an "email" property. Respond only
with code, and with no markdown formatting.
`;

const completion = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      role: "user",\
      content: refactorPrompt\
    },\
    {\
      role: "user",\
      content: code\
    }\
  ],
  prediction: {
    type: "content",
    content: code
  },
  stream: true
});

// Inspect returned data
for await (const chunk of stream) {
  process.stdout.write(chunk.choices[0]?.delta?.content || "");
}
```

## Position of predicted text in response

When providing prediction text, your prediction can appear anywhere within the generated response, and still provide latency reduction for the response. Let's say your predicted text is the simple [Hono](https://hono.dev/) server shown below:

```typescript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
import { serveStatic } from "@hono/node-server/serve-static";
import { serve } from "@hono/node-server";
import { Hono } from "hono";

const app = new Hono();

app.get("/api", (c) => {
  return c.text("Hello Hono!");
});

// You will need to build the client code first `pnpm run ui:build`
app.use(
  "/*",
  serveStatic({
    rewriteRequestPath: (path) => `./dist${path}`,
  })
);

const port = 3000;
console.log(`Server is running on port ${port}`);

serve({
  fetch: app.fetch,
  port,
});
```

You could prompt the model to regenerate the file with a prompt like:

```text
1
2
3
4
Add a get route to this application that responds with
the text "hello world". Generate the entire application
file again with this route added, and with no other
markdown formatting.
```

The response to the prompt might look something like this:

```typescript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
import { serveStatic } from "@hono/node-server/serve-static";
import { serve } from "@hono/node-server";
import { Hono } from "hono";

const app = new Hono();

app.get("/api", (c) => {
  return c.text("Hello Hono!");
});

app.get("/hello", (c) => {
  return c.text("hello world");
});

// You will need to build the client code first `pnpm run ui:build`
app.use(
  "/*",
  serveStatic({
    rewriteRequestPath: (path) => `./dist${path}`,
  })
);

const port = 3000;
console.log(`Server is running on port ${port}`);

serve({
  fetch: app.fetch,
  port,
});
```

You would still see accepted prediction tokens in the response, even though the prediction text appeared both before and after the new content added to the response:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  id: 'chatcmpl-xxx',
  object: 'chat.completion',
  created: 1731014771,
  model: 'gpt-4o-2024-08-06',
  choices: [ /* completion here... */],
  usage: {
    prompt_tokens: 203,
    completion_tokens: 159,
    total_tokens: 362,
    prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
    completion_tokens_details: {
      reasoning_tokens: 0,
      audio_tokens: 0,
      accepted_prediction_tokens: 60,
      rejected_prediction_tokens: 0
    }
  },
  system_fingerprint: 'fp_9ee9e968ea'
}
```

This time, there were no rejected prediction tokens, because the entire content of the file we predicted was used in the final response. Nice! 🔥

## Limitations

When using Predicted Outputs, you should consider the following factors and limitations.

- Predicted Outputs are only supported with the GPT-4o and GPT-4o-mini series of models.
- When providing a prediction, any tokens provided that are not part of the final completion are still charged at completion token rates. See the [`rejected_prediction_tokens` property of the `usage` object](/docs/api-reference/chat/object#chat/object-usage) to see how many tokens are not used in the final response.
- The following [API parameters](/docs/api-reference/chat/create) are not supported when using Predicted Outputs:

  - `n`: values higher than 1 are not supported
  - `logprobs`: not supported
  - `presence_penalty`: values greater than 0 are not supported
  - `frequency_penalty`: values greater than 0 are not supported
  - `audio`: Predicted Outputs are not compatible with [audio inputs and outputs](/docs/guides/audio)
  - `modalities`: Only `text` modalities are supported
  - `max_completion_tokens`: not supported
  - `tools`: Function calling is not currently supported with Predicted OutputsLog in [Sign up](/signup)

# Production notes on GPT Actions

Copy page

Deploy GPT Actions in production with best practices.

## Rate limits

Consider implementing rate limiting on the API endpoints you expose. ChatGPT will respect 429 response codes and dynamically back off from sending requests to your action after receiving a certain number of 429's or 500's in a short period of time.

## Timeouts

When making API calls during the actions experience, timeouts take place if the following thresholds are exceeded:

- 45 seconds round trip for API calls

## Use TLS and HTTPS

All traffic to your action must use TLS 1.2 or later on port 443 with a valid public certificate.

## IP egress ranges

ChatGPT will call your action from an IP address from one of these [CIDR blocks](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing):

- `23.102.140.112/28`
- `13.66.11.96/28`
- `104.210.133.240/28`
- `70.37.60.192/28`
- `20.97.188.144/28`
- `20.161.76.48/28`
- `52.234.32.208/28`
- `52.156.132.32/28`
- `40.84.220.192/28`
- `23.98.178.64/28`
- `51.8.155.32/28`
- `20.246.77.240/28`
- `172.178.141.0/28`
- `172.178.141.192/28`
- `40.84.180.128/28`

You may wish to explicitly allowlist these IP addresses.

## Multiple authentication schemas

When defining an action, you can mix a single authentication type (OAuth or API key) along with endpoints that do not require authentication.

You can learn more about action authentication on our [actions authentication page](/docs/actions/authentication).

## Open API specification limits

Keep in mind the following limits in your OpenAPI specification, which are subject to change:

- 300 characters max for each API endpoint description/summary field in API specification
- 700 characters max for each API parameter description field in API specification

## Additional limitations

There are a few limitations to be aware of when building with actions:

- Custom headers are not supported
- With the exception of Google, Microsoft and Adobe OAuth domains, all domains used in an OAuth flow must be the same as the domain used for the primary endpoints
- Request and response payloads must be less than 100,000 characters each
- Requests timeout after 45 seconds
- Requests and responses can only contain text (no images or video)

## Consequential flag

In the OpenAPI specification, you can now set certain endpoints as "consequential" as shown below:

```text
1
2
3
4
5
6
7
8
9
10
paths:
  /todo:
    get:
      operationId: getTODOs
      description: Fetches items in a TODO list from the API.
      security: []
    post:
      operationId: updateTODOs
      description: Mutates the TODO list.
      x-openai-isConsequential: true
```

A good example of a consequential action is booking a hotel room and paying for it on behalf of a user.

- If the `x-openai-isConsequential` field is `true`, ChatGPT treats the operation as "must always prompt the user for confirmation before running" and don't show an "always allow" button (both are features of GPTs designed to give builders and users more control over actions).
- If the `x-openai-isConsequential` field is `false`, ChatGPT shows the "always allow button".
- If the field isn't present, ChatGPT defaults all GET operations to `false` and all other operations to `true`

## Best practices on feeding examples

Here are some best practices to follow when writing your GPT instructions and descriptions in your schema, as well as when designing your API responses:

1. Your descriptions should not encourage the GPT to use the action when the user hasn't asked for your action's particular category of service.

_Bad example_:


> Whenever the user mentions any type of task, ask if they would like to use the TODO action to add something to their todo list.


_Good example_:


> The TODO list can add, remove and view the user's TODOs.

2. Your descriptions should not prescribe specific triggers for the GPT to use the action. ChatGPT is designed to use your action automatically when appropriate.

_Bad example_:


> When the user mentions a task, respond with "Would you like me to add this to your TODO list? Say 'yes' to continue."


_Good example_:


> \[no instructions needed for this\]

3. Action responses from an API should return raw data instead of natural language responses unless it's necessary. The GPT will provide its own natural language response using the returned data.

_Bad example_:


> I was able to find your todo list! You have 2 todos: get groceries and walk the dog. I can add more todos if you'd like!


_Good example_:


> { "todos": \[ "get groceries", "walk the dog" \] }


## How GPT Action data is used

GPT Actions connect ChatGPT to external apps. If a user interacts with a GPT’s custom action, ChatGPT may send parts of their conversation to the action’s endpoint.

If you have questions or run into additional limitations, you can join the discussion on the [OpenAI developer forum](https://community.openai.com).Log in [Sign up](/signup)

# OpenAI developer platform

[Developer quickstart\\
\\
Set up your environment and make your first API request in minutes\\
\\
5 min](/docs/quickstart)

node.js

```javascript
1
2
3
4
5
6
7
8
import OpenAI from "openai";
const openai = new OpenAI();
const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [\
        {"role": "user", "content": "write a haiku about ai"}\
    ]
});
```

## Meet the models

[Pricing](https://openai.com/api/pricing)

[GPT-4o\\
\\
Our high-intelligence flagship model for complex, multi‑step tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Smarter model, higher price per token](/docs/models#gpt-4o)

[GPT-4o mini\\
\\
Our affordable and intelligent small model for fast, lightweight tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Faster model, lower price per token](/docs/models#gpt-4o-mini)

[o1-preview & o1-mini\\
\\
Beta\\
\\
A new series of reasoning models for solving hard problems\\
\\
Text input, text output\\
\\
128k context length\\
\\
Higher latency, uses tokens to think](/docs/models#o1)

[Explore all](/docs/models)

## Start building

[Structured Outputs\\
\\
Ensure model responses adhere to your supplied JSON schema](/docs/guides/structured-outputs) [Realtime API\\
\\
Build low-latency multimodal experiences](/docs/guides/realtime) [Assistants API\\
\\
Build conversational assistants with tools and File Search](/docs/assistants) [Async use cases\\
\\
Batch requests for async, large-scale processing](/docs/guides/batch) [Fine-tuning\\
\\
Adapt a model to your specific use case with your data](/docs/guides/fine-tuning) [Distillation\\
\\
Evaluate and fine-tune models using production logs](/docs/guides/distillation)

## Explore our guides

[Prompt engineering\\
\\
Get better results from LLMs](/docs/guides/prompt-engineering) [Production best practices\\
\\
Transition from prototype to production](/docs/guides/production-best-practices) [Safety best practices\\
\\
Make sure your application is safe](/docs/guides/safety-best-practices) [Latency optimization\\
\\
Improve latency across multiple use cases](/docs/guides/latency-optimization) [Optimizing LLM accuracy\\
\\
Maximize correctness and consistent behavior of LLMs](/docs/guides/optimizing-llm-accuracy)

[Help center\\
\\
Frequently asked account and billing questions](https://help.openai.com/) [Developer forum\\
\\
Discuss topics with other developers](https://community.openai.com/) [Cookbook\\
\\
Open-source collection of examples and guides](https://cookbook.openai.com/) [Status\\
\\
Check the status of OpenAI services](https://status.openai.com)Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

# Overview of OpenAI Crawlers

Copy page

OpenAI uses web crawlers (“robots”) and user agents to perform actions for its products, either automatically or triggered by user request. OpenAI uses the following robots.txt tags to enable webmasters to manage how their sites and content work with AI. Each setting is independent of the others – for example, a webmaster can allow OAI-SearchBot to appear in search results while disallowing GPTbot to indicate that crawled content should not be used for training OpenAI’s generative AI foundation models. For search results, please note it can take ~24 hours from a site’s robots.txt update for our systems to adjust.

| User agent | Description & details |
| --- | --- |
| OAI-SearchBot | OAI-SearchBot is for search. OAI-SearchBot is used to link to and surface websites in search results in ChatGPT's search features. It is not used to crawl content to train OpenAI’s generative AI foundation models. To help ensure your site appears in search results, we recommend allowing OAI-SearchBot in your site’s robots.txt file and allowing requests from our published IP ranges below. <br>Full user-agent string: `Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko); compatible; OAI-SearchBot/1.0; +https://openai.com/searchbot`<br>Published IP addresses: [https://openai.com/searchbot.json](https://openai.com/searchbot.json) |
| ChatGPT-User | ChatGPT-User is for user actions in ChatGPT and [Custom GPTs](https://openai.com/index/introducing-gpts/). When users ask ChatGPT or a CustomGPT a question, it may visit a web page to help answer and include a link to the source in its response. ChatGPT users may also interact with external applications via [GPT Actions](/docs/actions/introduction). ChatGPT-User governs which sites these user requests can be made to. It is not used for crawling the web in any automatic fashion, nor to crawl content for generative AI training. <br>Full user-agent string: `Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko); compatible; ChatGPT-User/1.0; +https://openai.com/bot`<br>Published IP addresses: [https://openai.com/chatgpt-user.json](https://openai.com/chatgpt-user.json) |
| GPTBot | GPTBot is used to make our generative AI foundation models more useful and safe. It is used to crawl content that may be used in training our generative AI foundation models. Disallowing GPTBot indicates a site’s content should not be used in training generative AI foundation models. <br>Full user-agent string: `Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko); compatible; GPTBot/1.1; +https://openai.com/gptbot`<br>Published IP addresses: [https://openai.com/gptbot.json](https://openai.com/gptbot.json) |Log in [Sign up](/signup)

# Getting started with GPT Actions

Copy page

Set up and test GPT Actions from scratch.

## Weather.gov example

The NSW (National Weather Service) maintains a [public API](https://www.weather.gov/documentation/services-web-api) that users can query to receive a weather forecast for any lat-long point. To retrieve a forecast, there’s 2 steps:

1. A user provides a lat-long to the api.weather.gov/points API and receives back a WFO (weather forecast office), grid-X, and grid-Y coordinates
2. Those 3 elements feed into the api.weather.gov/forecast API to retrieve a forecast for that coordinate

For the purpose of this exercise, let’s build a Custom GPT where a user writes a city, landmark, or lat-long coordinates, and the Custom GPT answers questions about a weather forecast in that location.

## Step 1: Write and test Open API schema (using Actions GPT)

A GPT Action requires an [Open API schema](https://swagger.io/specification/) to describe the parameters of the API call, which is a standard for describing APIs.

OpenAI released a public [Actions GPT](https://chatgpt.com/g/g-TYEliDU6A-actionsgpt) to help developers write this schema. For example, go to the Actions GPT and ask: _“Go to [https://www.weather.gov/documentation/services-web-api](https://www.weather.gov/documentation/services-web-api) and read the documentation on that page. Build an Open API Schema for the /points/{latitude},{longitude} and /gridpoints/{office}/{gridX},{gridY}/forecast” API calls”_

![](https://cdn.openai.com/API/images/guides/actions_action_gpt.png)

Deep dive

See Full Open API Schema

ChatGPT uses the **info** at the top (including the description in particular) to determine if this action is relevant for the user query.

```text
1
2
3
4
info:
  title: NWS Weather API
  description: Access to weather data including forecasts, alerts, and observations.
  version: 1.0.0
```

Then the **parameters** below further define each part of the schema. For example, we're informing ChatGPT that the _office_ parameter refers to the Weather Forecast Office (WFO).

```text
1
2
3
4
5
6
7
8
9
10
11
/gridpoints/{office}/{gridX},{gridY}/forecast:
  get:
    operationId: getGridpointForecast
    summary: Get forecast for a given grid point
    parameters:
      - name: office
        in: path
        required: true
        schema:
          type: string
        description: Weather Forecast Office ID
```

**Key:** Pay special attention to the **schema names** and **descriptions** that you use in this Open API schema. ChatGPT uses those names and descriptions to understand (a) which API action should be called and (b) which parameter should be used. If a field is restricted to only certain values, you can also provide an "enum" with descriptive category names.

While you can just try the Open API schema directly in a GPT Action, debugging directly in ChatGPT can be a challenge. We recommend using a 3rd party service, like [Postman](https://www.postman.com/), to test that your API call is working properly. Postman is free to sign up, verbose in its error-handling, and comprehensive in its authentication options. It even gives you the option of importing Open API schemas directly (see below).

![](https://cdn.openai.com/API/images/guides/actions_import.png)

## Step 2: Identify authentication requirements

This Weather 3rd party service does not require authentication, so you can skip that step for this Custom GPT. For other GPT Actions that do require authentication, there are 2 options: API Key or OAuth. Asking ChatGPT can help you get started for most common applications. For example, if I needed to use OAuth to authenticate to Google Cloud, I can provide a screenshot and ask for details: _“I’m building a connection to Google Cloud via OAuth. Please provide instructions for how to fill out each of these boxes.”_

![](https://cdn.openai.com/API/images/guides/actions_oauth_panel.png)

Often, ChatGPT provides the correct directions on all 5 elements. Once you have those basics ready, try testing and debugging the authentication in Postman or another similar service. If you encounter an error, provide the error to ChatGPT, and it can usually help you debug from there.

## Step 3: Create the GPT Action and test

Now is the time to create your Custom GPT. If you've never created a Custom GPT before, start at our [Creating a GPT guide](https://help.openai.com/en/articles/8554397-creating-a-gpt).

1. Provide a name, description, and image to describe your Custom GPT
2. Go to the Action section and paste in your Open API schema. Take a note of the Action names and json parameters when writing your instructions.
3. Add in your authentication settings
4. Go back to the main page and add in instructions

Deep dive

Guidance on Writing Instructions

### Test the GPT Action

Next to each action, you'll see a **Test** button. Click on that for each action. In the test, you can see the detailed input and output of each API call.

![](https://cdn.openai.com/API/images/guides/actions_available_action.png)

If your API call is working in a 3rd party tool like Postman and not in ChatGPT, there are a few possible culprits:

- The parameters in ChatGPT are wrong or missing
- An authentication issue in ChatGPT
- Your instructions are incomplete or unclear
- The descriptions in the Open API schema are unclear

![](https://cdn.openai.com/API/images/guides/actions_test_action.png)

## Step 4: Set up callback URL in the 3rd party app

If your GPT Action uses OAuth Authentication, you’ll need to set up the callback URL in your 3rd party application. Once you set up a GPT Action with OAuth, ChatGPT provides you with a callback URL (this will update any time you update one of the OAuth parameters). Copy that callback URL and add it to the appropriate place in your application.

![](https://cdn.openai.com/API/images/guides/actions_bq_callback.png)

## Step 5: Evaluate the Custom GPT

Even though you tested the GPT Action in the step above, you still need to evaluate if the Instructions and GPT Action function in the way users expect. Try to come up with at least 5-10 representative questions (the more, the better) of an **“evaluation set”** of questions to ask your Custom GPT.

**Key:** Test that the Custom GPT handles each one of your questions as you expect.

An example question: _“What should I pack for a trip to the White House this weekend?”_ tests the Custom GPT’s ability to: (1) convert a landmark to a lat-long, (2) run both GPT Actions, and (3) answer the user’s question.

![](https://cdn.openai.com/API/images/guides/actions_prompt_2_actions.png)![](https://cdn.openai.com/API/images/guides/actions_output.png)

## Common Debugging Steps

_Challenge:_ The GPT Action is calling the wrong API call (or not calling it at all)

- _Solution:_ Make sure the descriptions of the Actions are clear - and refer to the Action names in your Custom GPT Instructions

_Challenge:_ The GPT Action is calling the right API call but not using the parameters correctly

- _Solution:_ Add or modify the descriptions of the parameters in the GPT Action

_Challenge:_ The Custom GPT is not working but I am not getting a clear error

- _Solution:_ Make sure to test the Action - there are more robust logs in the test window. If that is still unclear, use Postman or another 3rd party service to better diagnose.

_Challenge:_ The Custom GPT is giving an authentication error

- _Solution:_ Make sure your callback URL is set up correctly. Try testing the exact same authentication settings in Postman or another 3rd party service

_Challenge:_ The Custom GPT cannot handle more difficult / ambiguous questions

- _Solution:_ Try to prompt engineer your instructions in the Custom GPT. See examples in our [prompt engineering guide](https://platform.openai.com/docs/guides/prompt-engineering)

This concludes the guide to building a Custom GPT. Good luck building and leveraging the [OpenAI developer forum](https://community.openai.com/) if you have additional questions.Log in [Sign up](/signup)

# Prompt caching

Copy page

Reduce latency and cost with prompt caching.

Model prompts often contain repetitive content, like system prompts and common instructions. OpenAI routes API requests to servers that recently processed the same prompt, making it cheaper and faster than processing a prompt from scratch. This can reduce latency by up to 80% and cost by 50% for long prompts. Prompt Caching works automatically on all your API requests (no code changes required) and has no additional fees associated with it.

Prompt Caching is enabled for the following [models](/docs/models):

| Model | Text Input Cost | Audio Input Cost |
| --- | --- | --- |
| gpt-4o (excludes gpt-4o-2024-05-13 and chatgpt-4o-latest) | 50% less | n/a |
| gpt-4o-mini | 50% less | n/a |
| gpt-4o-realtime-preview | 50% less | 80% less |
| o1-preview | 50% less | n/a |
| o1-mini | 50% less | n/a |

This guide describes how prompt caching works in detail, so that you can optimize your prompts for lower latency and cost.

## Structuring prompts

Cache hits are only possible for exact prefix matches within a prompt. To realize caching benefits, place static content like instructions and examples at the beginning of your prompt, and put variable content, such as user-specific information, at the end. This also applies to images and tools, which must be identical between requests.

![Prompt Caching visualization](https://openaidevs.retool.com/api/file/8593d9bb-4edb-4eb6-bed9-62bfb98db5ee)

## How it works

Caching is enabled automatically for prompts that are 1024 tokens or longer. When you make an API request, the following steps occur:

1. **Cache Lookup**: The system checks if the initial portion (prefix) of your prompt is stored in the cache.
2. **Cache Hit**: If a matching prefix is found, the system uses the cached result. This significantly decreases latency and reduces costs.
3. **Cache Miss**: If no matching prefix is found, the system processes your full prompt. After processing, the prefix of your prompt is cached for future requests.

Cached prefixes generally remain active for 5 to 10 minutes of inactivity. However, during off-peak periods, caches may persist for up to one hour.

## Requirements

Caching is available for prompts containing 1024 tokens or more, with cache hits occurring in increments of 128 tokens. Therefore, the number of cached tokens in a request will always fall within the following sequence: 1024, 1152, 1280, 1408, and so on, depending on the prompt's length.

All requests, including those with fewer than 1024 tokens, will display a `cached_tokens` field of the `usage.prompt_tokens_details` [chat completions object](/docs/api-reference/chat/object) indicating how many of the prompt tokens were a cache hit. For requests under 1024 tokens, `cached_tokens` will be zero.

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
"usage": {
  "prompt_tokens": 2006,
  "completion_tokens": 300,
  "total_tokens": 2306,
  "prompt_tokens_details": {
    "cached_tokens": 1920
  },
  "completion_tokens_details": {
    "reasoning_tokens": 0,
    "accepted_prediction_tokens": 0,
    "rejected_prediction_tokens": 0
  }
}
```

### What can be cached

- **Messages:** The complete messages array, encompassing system, user, and assistant interactions.
- **Images:** Images included in user messages, either as links or as base64-encoded data, as well as multiple images can be sent. Ensure the detail parameter is set identically, as it impacts image tokenization.
- **Tool use:** Both the messages array and the list of available `tools` can be cached, contributing to the minimum 1024 token requirement.
- **Structured outputs:** The structured output schema serves as a prefix to the system message and can be cached.

### Best practices

- Structure prompts with static or repeated content at the beginning and dynamic content at the end.
- Monitor metrics such as cache hit rates, latency, and the percentage of tokens cached to optimize your prompt and caching strategy.
- To increase cache hits, use longer prompts and make API requests during off-peak hours, as cache evictions are more frequent during peak times.
- Prompts that haven't been used recently are automatically removed from the cache. To minimize evictions, maintain a consistent stream of requests with the same prompt prefix.

### Frequently asked questions

1. **How is data privacy maintained for caches?**

Prompt caches are not shared between organizations. Only members of the same organization can access caches of identical prompts.

2. **Does Prompt Caching affect output token generation or the final response of the API?**

Prompt Caching does not influence the generation of output tokens or the final response provided by the API. Regardless of whether caching is used, the output generated will be identical. This is because only the prompt itself is cached, while the actual response is computed anew each time based on the cached prompt.

3. **Is there a way to manually clear the cache?**

Manual cache clearing is not currently available. Prompts that have not been encountered recently are automatically cleared from the cache. Typical cache evictions occur after 5-10 minutes of inactivity, though sometimes lasting up to a maximum of one hour during off-peak periods.

4. **Will I be expected to pay extra for writing to Prompt Caching?**

No. Caching happens automatically, with no explicit action needed or extra cost paid to use the caching feature.

5. **Do cached prompts contribute to TPM rate limits?**

Yes, as caching does not affect rate limits.

6. **Is discounting for Prompt Caching available on Scale Tier and the Batch API?**

Discounting for Prompt Caching is not available on the Batch API but is available on Scale Tier. With Scale Tier, any tokens that are spilled over to the shared API will also be eligible for caching.

7. **Does Prompt Caching work on Zero Data Retention requests?**

Yes, Prompt Caching is compliant with existing Zero Data Retention policies.Log in [Sign up](/signup)

# GPT Actions

Copy page

Customize ChatGPT with GPT Actions and API integrations.

GPT Actions are stored in [Custom GPTs](https://openai.com/blog/introducing-gpts), which enable users to customize ChatGPT for specific use cases by providing instructions, attaching documents as knowledge, and connecting to 3rd party services.

GPT Actions empower ChatGPT users to interact with external applications via RESTful APIs calls outside of ChatGPT simply by using natural language. They convert natural language text into the json schema required for an API call. GPT Actions are usually either used to do [data retrieval](https://platform.openai.com/docs/actions/data-retrieval) to ChatGPT (e.g. query a Data Warehouse) or take action in another application (e.g. file a JIRA ticket).

## How GPT Actions work

At their core, GPT Actions leverage [Function Calling](https://platform.openai.com/docs/guides/function-calling) to execute API calls.

Similar to ChatGPT's Data Analysis capability (which generates Python code and then executes it), they leverage Function Calling to (1) decide which API call is relevant to the user's question and (2) generate the json input necessary for the API call. Then finally, the GPT Action executes the API call using that json input.

Developers can even specify the authentication mechanism of an action, and the Custom GPT will execute the API call using the third party app’s authentication. GPT Actions obfuscates the complexity of the API call to the end user: they simply ask a question in natural language, and ChatGPT provides the output in natural language as well.

## The Power of GPT Actions

APIs allow for **interoperability** to enable your organization to access other applications. However, enabling users to access the right information from 3rd-party APIs can require significant overhead from developers.

GPT Actions provide a viable alternative: developers can now simply describe the schema of an API call, configure authentication, and add in some instructions to the GPT, and ChatGPT provides the bridge between the user's natural language questions and the API layer.

## Simplified example

The [getting started guide](https://platform.openai.com/docs/actions/getting-started) walks through an example using two API calls from [weather.gov](weather.gov) to generate a forecast:

- /points/{latitude},{longitude} inputs lat-long coordinates and outputs forecast office (wfo) and x-y coordinates
- /gridpoints/{office}/{gridX},{gridY}/forecast inputs wfo,x,y coordinates and outputs a forecast

Once a developer has encoded the json schema required to populate both of those API calls in a GPT Action, a user can simply ask "What I should pack on a trip to Washington DC this weekend?" The GPT Action will then figure out the lat-long of that location, execute both API calls in order, and respond with a packing list based on the weekend forecast it receives back.

In this example, GPT Actions will supply api.weather.gov with two API inputs:

/points API call:

```text
1
2
3
4
{
    "latitude": 38.9072,
    "longitude": -77.0369,
}
```

/forecast API call:

```text
1
2
3
4
5
{
    "wfo": "LWX",
    "x": 97,
    "y": 71,
}
```

## Get started on building

Check out the [getting started guide](https://platform.openai.com/docs/actions/getting-started) for a deeper dive on this weather example and our [actions library](https://platform.openai.com/docs/actions/actions-library) for pre-built example GPT Actions of the most common 3rd party apps.

## Additional information

- Familiarize yourself with our [GPT policies](https://openai.com/policies/usage-policies#:~:text=or%20educational%20purposes.-,Building%20with%20ChatGPT,-Shared%20GPTs%20allow)
- Explore the [differences between GPTs and Assistants](https://help.openai.com/en/articles/8673914-gpts-vs-assistants)
- Check out the [GPT data privacy FAQ's](https://help.openai.com/en/articles/8554402-gpts-data-privacy-faqs)
- Find answers to [common GPT questions](https://help.openai.com/en/articles/8554407-gpts-faq)Log in [Sign up](/signup)

# What's new in Assistants API  Beta

Copy page

Discover new features and improvements in Assistants API.

## April 2024

We are announcing a variety of new features and improvements to the Assistants API and moving our Beta to a new API version, `OpenAI-Beta: assistants=v2`. Here's what's new:

- We're launching an [improved retrieval tool called `file_search`](/docs/assistants/tools/file-search), which can ingest up to 10,000 files per assistant - 500x more than before. It is faster, supports parallel queries through multi-threaded searches, and features enhanced reranking and query rewriting.
- Alongside `file_search`, we're introducing [`vector_store` objects](/docs/assistants/tools/file-search#vector-stores) in the API. Once a file is added to a vector store, it's automatically parsed, chunked, and embedded, made ready to be searched. Vector stores can be used across assistants and threads, simplifying file management and billing.
- You can now [control the maximum number of tokens](/docs/assistants/overview) a run uses in the Assistants API, allowing you to manage token usage costs. You can also set limits on the number of previous / recent messages used in each run.
- We've added support for the [`tool_choice` parameter](/docs/api-reference/runs/object#runs/object-tool_choice) which can be used to force the use of a specific tool (like `file_search`, `code_interpreter`, or a `function`) in a particular run.
- You can now [create messages with the role `assistant`](/docs/api-reference/messages/createMessage#messages-createmessage-role) to create custom conversation histories in Threads.
- Assistant and Run objects now support popular model configuration parameters like [`temperature`](/docs/api-reference/assistants/createAssistant#assistants-createassistant-temperature), [`response_format` (JSON mode)](/docs/api-reference/assistants/createAssistant#assistants-createassistant-response_format), and [`top_p`](/docs/api-reference/assistants/createAssistant#assistants-createassistant-top_p).
- You can now use [fine-tuned models](/docs/guides/fine-tuning) in the Assistants API. At the moment, only fine-tuned versions of `gpt-3.5-turbo-0125` are supported.
- Assistants API now supports [streaming](/docs/assistants/overview#step-4-create-a-run?context=with-streaming).
- We've added several streaming and polling helpers to our [Node](https://github.com/openai/openai-node/blob/master/helpers.md) and [Python](https://github.com/openai/openai-python/blob/main/helpers.md) SDKs.

See our [migration guide](/docs/assistants/migration) to learn more about how to migrate your tool usage to the latest version of the Assistants API.Log in [Sign up](/signup)

# Audio generation

Copy page

Learn how to generate audio from a text or audio prompt.

In addition to generating [text](/docs/guides/text-generation) and [images](/docs/guides/images), some [models](/docs/models) enable you to generate a spoken audio response to a prompt, and to use audio inputs to prompt the model. Audio inputs can contain richer data than text alone, allowing the model to detect tone, inflection, and other nuances within the input.

You can use these audio capabilities to:

- Generate a spoken audio summary of a body of text (text in, audio out)
- Perform sentiment analysis on a recording (audio in, text out)
- Async speech to speech interactions with a model (audio in, audio out)

OpenAI provides other models for simple [speech to text](/docs/guides/speech-to-text) and [text to speech](/docs/guides/text-to-speech) \- when your task requires those conversions (and not dynamic content from a model), the TTS and STT models will be more performant and cost-efficient.

## Quickstart

To generate audio or use audio as an input, you can use the [chat completions endpoint](/docs/api-reference/chat/) in the REST API, as seen in the examples below. You can either use the [REST API](/docs/api-reference) from the HTTP client of your choice, or use one of OpenAI's [official SDKs](/docs/libraries) for your preferred programming language.

Audio output from modelAudio input to model

Create a human-like audio response to a prompt

javascript

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
import { writeFileSync } from "node:fs";
import OpenAI from "openai";

const openai = new OpenAI();

// Generate an audio response to the given prompt
const response = await openai.chat.completions.create({
  model: "gpt-4o-audio-preview",
  modalities: ["text", "audio"],
  audio: { voice: "alloy", format: "wav" },
  messages: [\
    {\
      role: "user",\
      content: "Is a golden retriever a good family dog?"\
    }\
  ]
});

// Inspect returned data
console.log(response.choices[0]);

// Write audio data to a file
writeFileSync(
  "dog.wav",
  Buffer.from(response.choices[0].message.audio.data, 'base64'),
  { encoding: "utf-8" }
);
```

## Multi-turn conversations

Using audio outputs from the model as inputs to multi-turn conversations requires a generated ID that appears in the response data for an audio generation. Below is an example JSON data structure for a [message you might receive](/docs/api-reference/chat/object#chat/object-choices) from `/chat/completions`:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "index": 0,
  "message": {
    "role": "assistant",
    "content": null,
    "refusal": null,
    "audio": {
      "id": "audio_abc123",
      "expires_at": 1729018505,
      "data": "<bytes omitted>",
      "transcript": "Yes, golden retrievers are known to be ..."
    }
  },
  "finish_reason": "stop"
}
```

The value of `message.audio.id` above provides an identifier you can use in an `assistant` message for a new `/chat/completions` request, as in the example below.

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
curl "https://api.openai.com/v1/chat/completions" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d '{
        "model": "gpt-4o-audio-preview",
        "modalities": ["text", "audio"],
        "audio": { "voice": "alloy", "format": "wav" },
        "messages": [\
            {\
                "role": "user",\
                "content": "Is a golden retriever a good family dog?"\
            },\
            {\
                "role": "assistant",\
                "audio": {\
                    "id": "audio_abc123"\
                }\
            },\
            {\
                "role": "user",\
                "content": "Why do you say they are loyal?"\
            }\
        ]
    }'
```

## FAQ

### What modalities are supported by gpt-4o-audio-preview

`gpt-4o-audio-preview` requires either audio output or audio input to be used at this time. Acceptable combinations of input and output are:

- text in → text + audio out
- audio in → text + audio out
- audio in → text out
- text + audio in → text + audio out
- text + audio in → text out

### How is audio in Chat Completions different from the Realtime API?

The underlying GPT-4o audio model is exactly the same. The Realtime API operates the same model at lower latency.

### How do I think about audio input to the model in terms of tokens?

We are working on better tooling to expose this, but roughly one hour of audio input is equal to 128k tokens, the max context window currently supported by this model.

### How do I control which output modalities I receive?

Currently the model only programmatically allows modalities = `[“text”, “audio”]`. In the future, this parameter will give more controls.

### How does tool/function calling work?

Tool (and function) calling works the same as it does for other models in Chat Completions - [learn more](/docs/guides/function-calling).

## Next steps

Now that you know how to generate audio outputs and send audio inputs, there are a few other techniques you might want to master.

[Text to speech\\
\\
Use a specialized model to turn text into speech.](/docs/guides/text-to-speech) [Speech to text\\
\\
Use a specialized model to turn audio files with speech into text.](/docs/guides/speech-to-text) [Realtime API\\
\\
Learn to use the Realtime API to prompt a model over a WebSocket.](/docs/guides/realtime) [Full API reference\\
\\
Check out all the options for audio generation in the API reference.](/docs/api-reference/chat)Log in [Sign up](/signup)

# Libraries

Copy page

Explore libraries for Python, Node.js, .NET, and more.

## Python library

We provide a [Python library](https://github.com/openai/openai-python), which you can install by running:

```bash
pip install openai
```

Once installed, you can use the library and your secret key to run the following:

```python
1
2
3
4
5
6
7
8
9
from openai import OpenAI
client = OpenAI(
    # Defaults to os.environ.get("OPENAI_API_KEY")
)

chat_completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hello world"}]
)
```

The bindings also will install a command-line utility you can use as follows:

```bash
$ openai api chat_completions.create -m gpt-4o-mini -g user "Hello world"
```

* * *

## TypeScript / JavaScript library

We provide a [TypeScript / JavaScript library](https://github.com/openai/openai-node) with support for Node.js and various [other runtimes](https://deno.land/x/openai). Install it by running:

```bash
1
2
3
npm install --save openai
# or
yarn add openai
```

Once installed, you can use the library and your secret key to run the following:

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from "openai";

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

const chatCompletion = await openai.chat.completions.create({
    messages: [{ role: "user", content: "Say this is a test" }],
    model: "gpt-4o-mini",
});
```

* * *

## .NET library

We provide a [.NET library](https://github.com/openai/openai-dotnet), which you can install by running:

```text
dotnet add package OpenAI
```

Once installed, you can use the library and your secret key to run the following:

```csharp
1
2
3
4
5
using OpenAI.Chat;

ChatClient client = new(model: "gpt-4o-mini",  apiKey: Environment.GetEnvironmentVariable("OPENAI_API_KEY"));

ChatCompletion chatCompletion = client.CompleteChat("Say 'this is a test.'");
```

* * *

## Azure OpenAI libraries

Microsoft's Azure team maintains libraries that are compatible with both the OpenAI API and Azure OpenAI services. Read the library documentation below to learn how you can use them with the OpenAI API.

- [Azure OpenAI client library for .NET](https://github.com/Azure/azure-sdk-for-net/tree/main/sdk/openai/Azure.AI.OpenAI)
- [Azure OpenAI client library for JavaScript](https://github.com/Azure/azure-sdk-for-js/tree/main/sdk/openai/openai)
- [Azure OpenAI client library for Java](https://github.com/Azure/azure-sdk-for-java/tree/main/sdk/openai/azure-ai-openai)
- [Azure OpenAI client library for Go](https://github.com/Azure/azure-sdk-for-go/tree/main/sdk/ai/azopenai)

* * *

## Community libraries

The libraries below are built and maintained by the broader developer community. If you'd like to add a new library here, please follow the instructions in our [help center article](https://help.openai.com/en/articles/6684216-adding-your-api-client-to-the-community-libraries-page) on adding community libraries. You can also [watch our OpenAPI specification](https://github.com/openai/openai-openapi) repository on GitHub to get timely updates on when we make changes to our API.

Please note that OpenAI does not verify the correctness or security of these projects. **Use them at your own risk!**

### C\# / .NET

- [Betalgo.OpenAI](https://github.com/betalgo/openai) by [Betalgo](https://github.com/betalgo)
- [OpenAI-API-dotnet](https://github.com/OkGoDoIt/OpenAI-API-dotnet) by [OkGoDoIt](https://github.com/OkGoDoIt)
- [OpenAI-DotNet](https://github.com/RageAgainstThePixel/OpenAI-DotNet) by [RageAgainstThePixel](https://github.com/RageAgainstThePixel)

### C++

- [liboai](https://github.com/D7EAD/liboai) by [D7EAD](https://github.com/D7EAD)

### Clojure

- [openai-clojure](https://github.com/wkok/openai-clojure) by [wkok](https://github.com/wkok)

### Crystal

- [openai-crystal](https://github.com/sferik/openai-crystal) by [sferik](https://github.com/sferik)

### Dart/Flutter

- [openai](https://github.com/anasfik/openai) by [anasfik](https://github.com/anasfik)

### Delphi

- [DelphiOpenAI](https://github.com/HemulGM/DelphiOpenAI) by [HemulGM](https://github.com/HemulGM)

### Elixir

- [openai.ex](https://github.com/mgallo/openai.ex) by [mgallo](https://github.com/mgallo)

### Go

- [go-gpt3](https://github.com/sashabaranov/go-gpt3) by [sashabaranov](https://github.com/sashabaranov)

### Java

- [openai-java](https://github.com/TheoKanning/openai-java) by [Theo Kanning](https://github.com/TheoKanning)

### Julia

- [OpenAI.jl](https://github.com/rory-linehan/OpenAI.jl) by [rory-linehan](https://github.com/rory-linehan)

### Kotlin

- [openai-kotlin](https://github.com/Aallam/openai-kotlin) by [Mouaad Aallam](https://github.com/Aallam)

### Node.js

- [openai-api](https://www.npmjs.com/package/openai-api) by [Njerschow](https://github.com/Njerschow)
- [openai-api-node](https://www.npmjs.com/package/openai-api-node) by [erlapso](https://github.com/erlapso)
- [gpt-x](https://www.npmjs.com/package/gpt-x) by [ceifa](https://github.com/ceifa)
- [gpt3](https://www.npmjs.com/package/gpt3) by [poteat](https://github.com/poteat)
- [gpts](https://www.npmjs.com/package/gpts) by [thencc](https://github.com/thencc)
- [@dalenguyen/openai](https://www.npmjs.com/package/@dalenguyen/openai) by [dalenguyen](https://github.com/dalenguyen)
- [tectalic/openai](https://github.com/tectalichq/public-openai-client-js) by [tectalic](https://tectalic.com/)

### PHP

- [orhanerday/open-ai](https://packagist.org/packages/orhanerday/open-ai) by [orhanerday](https://github.com/orhanerday)
- [tectalic/openai](https://github.com/tectalichq/public-openai-client-php) by [tectalic](https://tectalic.com/)
- [openai-php client](https://github.com/openai-php/client) by [openai-php](https://github.com/openai-php)

### Python

- [chronology](https://github.com/OthersideAI/chronology) by [OthersideAI](https://www.othersideai.com/)

### R

- [rgpt3](https://github.com/ben-aaron188/rgpt3) by [ben-aaron188](https://github.com/ben-aaron188)

### Ruby

- [openai](https://github.com/nileshtrivedi/openai/) by [nileshtrivedi](https://github.com/nileshtrivedi)
- [ruby-openai](https://github.com/alexrudall/ruby-openai) by [alexrudall](https://github.com/alexrudall)

### Rust

- [async-openai](https://github.com/64bit/async-openai) by [64bit](https://github.com/64bit)
- [fieri](https://github.com/lbkolev/fieri) by [lbkolev](https://github.com/lbkolev)

### Scala

- [openai-scala-client](https://github.com/cequence-io/openai-scala-client) by [cequence-io](https://github.com/cequence-io)

### Swift

- [OpenAIKit](https://github.com/dylanshine/openai-kit) by [dylanshine](https://github.com/dylanshine)
- [OpenAI](https://github.com/MacPaw/OpenAI/) by [MacPaw](https://github.com/MacPaw)

### Unity

- [OpenAi-Api-Unity](https://github.com/hexthedev/OpenAi-Api-Unity) by [hexthedev](https://github.com/hexthedev)
- [com.openai.unity](https://github.com/RageAgainstThePixel/com.openai.unity) by [RageAgainstThePixel](https://github.com/RageAgainstThePixel)

### Unreal Engine

- [OpenAI-Api-Unreal](https://github.com/KellanM/OpenAI-Api-Unreal) by [KellanM](https://github.com/KellanM)

## Other OpenAI repositories

- [tiktoken](https://github.com/openai/tiktoken) \- counting tokens
- [simple-evals](https://github.com/openai/simple-evals) \- simple evaluation library
- [mle-bench](https://github.com/openai/mle-bench) \- library to evaluate machine learning engineer agents
- [gym](https://github.com/openai/gym) \- reinforcement learning library
- [swarm](https://github.com/openai/swarm) \- educational orchestration repositoryLog in [Sign up](/signup)

# Meeting minutes

Copy page

Create an automated meeting minutes generator with Whisper and GPT-4.

In this tutorial, we'll harness the power of OpenAI's Whisper and GPT-4 models to develop an automated meeting minutes generator. The application transcribes audio from a meeting, provides a summary of the discussion, extracts key points and action items, and performs a sentiment analysis.

## Getting started

This tutorial assumes a basic understanding of Python and an [OpenAI API key](/settings/organization/api-keys). You can use the audio file provided with this tutorial or your own.

Additionally, you will need to install the [python-docx](https://python-docx.readthedocs.io/en/latest/) and [OpenAI](/docs/libraries) libraries. You can create a new Python environment and install the required packages with the following commands:

```bash
1
2
3
4
5
6
python -m venv env

source env/bin/activate

pip install openai
pip install python-docx
```

## Transcribing audio with Whisper

![Audio Waveform created by DALL·E](https://cdn.openai.com/API/docs/images/tutorials/meeting-minutes/waveform3.png)

The first step in transcribing the audio from a meeting is to pass the audio file of the meeting into our [/v1/audio API](/docs/api-reference/audio). Whisper, the model that powers the audio API, is capable of converting spoken language into written text. To start, we will avoid passing a [prompt](/docs/api-reference/audio/createTranscription#audio/createTranscription-prompt) or [temperature](/docs/api-reference/audio/createTranscription#audio/createTranscription-temperature-4) (optional parameters to control the model's output) and stick with the default values.

[Download sample audio](https://cdn.openai.com/API/docs/images/tutorials/meeting-minutes/EarningsCall.wav)

Next, we import the required packages and define a function that uses the Whisper model to take in the audio file and
transcribe it:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    # api_key="My API Key",
)
from docx import Document

def transcribe_audio(audio_file_path):
    with open(audio_file_path, 'rb') as audio_file:
        transcription = client.audio.transcriptions.create("whisper-1", audio_file)
    return transcription['text']
```

In this function, `audio_file_path` is the path to the audio file you want to transcribe. The function opens this file and passes it to the Whisper ASR model ( `whisper-1`) for transcription. The result is returned as raw text. It’s important to note that the `openai.Audio.transcribe` function requires the actual audio file to be passed in, not just the path to the file locally or on a remote server. This means that if you are running this code on a server where you might not also be storing your audio files, you will need to have a preprocessing step that first downloads the audio files onto that device.

## Summarizing and analyzing the transcript with GPT-4

Having obtained the transcript, we now pass it to GPT-4 via the [Chat Completions API](/docs/api-reference/chat/create). GPT-4 is OpenAI's state-of-the-art large language model which we'll use to generate a summary, extract key points, action items, and perform sentiment analysis.

This tutorial uses distinct functions for each task we want GPT-4 to perform. This is not the most efficient way to do this task - you can put these instructions into one function, however, splitting them up can lead to higher quality summarization.

To split the tasks up, we define the `meeting_minutes` function which will serve as the main function of this application:

```python
1
2
3
4
5
6
7
8
9
10
11
def meeting_minutes(transcription):
    abstract_summary = abstract_summary_extraction(transcription)
    key_points = key_points_extraction(transcription)
    action_items = action_item_extraction(transcription)
    sentiment = sentiment_analysis(transcription)
    return {
        'abstract_summary': abstract_summary,
        'key_points': key_points,
        'action_items': action_items,
        'sentiment': sentiment
    }
```

In this function, `transcription` is the text we obtained from Whisper. The transcription can be passed to the four other functions, each designed to perform a specific task: `abstract_summary_extraction` generates a summary of the meeting, `key_points_extraction` extracts the main points, `action_item_extraction` identifies the action items, and `sentiment_analysis performs` a sentiment analysis. If there are other capabilities you want, you can add those in as well using the same framework shown above.

Here is how each of these functions works:

### Summary extraction

The `abstract_summary_extraction` function takes the transcription and summarizes it into a concise abstract paragraph with the aim to retain the most important points while avoiding unnecessary details or tangential points. The main mechanism to enable this process is the system message as shown below. There are many different possible ways of achieving similar results through the process commonly referred to as prompt engineering. You can read our [prompt engineering guide](/docs/guides/prompt-engineering) which gives in depth advice on how to do this most effectively.

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
def abstract_summary_extraction(transcription):
    response = client.chat.completions.create(
        model="gpt-4",
        temperature=0,
        messages=[\
            {\
                "role": "system",\
                "content": "You are a highly skilled AI trained in language comprehension and summarization. I would like you to read the following text and summarize it into a concise abstract paragraph. Aim to retain the most important points, providing a coherent and readable summary that could help a person understand the main points of the discussion without needing to read the entire text. Please avoid unnecessary details or tangential points."\
            },\
            {\
                "role": "user",\
                "content": transcription\
            }\
        ]
    )
    return completion.choices[0].message.content
```

### Key points extraction

The `key_points_extraction` function identifies and lists the main points discussed in the meeting. These points should represent the most important ideas, findings, or topics crucial to the essence of the discussion. Again, the main mechanism for controlling the way these points are identified is the system message. You might want to give some additional context here around the way your project or company runs such as “We are a company that sells race cars to consumers. We do XYZ with the goal of XYZ”. This additional context could dramatically improve the models ability to extract information that is relevant.

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
def key_points_extraction(transcription):
    response = client.chat.completions.create(
        model="gpt-4",
        temperature=0,
        messages=[\
            {\
                "role": "system",\
                "content": "You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about."\
            },\
            {\
                "role": "user",\
                "content": transcription\
            }\
        ]
    )
    return completion.choices[0].message.content
```

### Action item extraction

The `action_item_extraction` function identifies tasks, assignments, or actions agreed upon or mentioned during the meeting. These could be tasks assigned to specific individuals or general actions the group decided to take. While not covered in this tutorial, the Chat Completions API provides a [function calling capability](/docs/guides/function-calling) which would allow you to build in the ability to automatically create tasks in your task management software and assign it to the relevant person.

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
def action_item_extraction(transcription):
    response = client.chat.completions.create(
        model="gpt-4",
        temperature=0,
        messages=[\
            {\
                "role": "system",\
                "content": "You are an AI expert in analyzing conversations and extracting action items. Please review the text and identify any tasks, assignments, or actions that were agreed upon or mentioned as needing to be done. These could be tasks assigned to specific individuals, or general actions that the group has decided to take. Please list these action items clearly and concisely."\
            },\
            {\
                "role": "user",\
                "content": transcription\
            }\
        ]
    )
    return completion.choices[0].message.content
```

### Sentiment analysis

The `sentiment_analysis` function analyzes the overall sentiment of the discussion. It considers the tone, the emotions conveyed by the language used, and the context in which words and phrases are used. For tasks which are less complicated, it may also be worthwhile to try out `gpt-3.5-turbo` in addition to `gpt-4` to see if you can get a similar level of performance. It might also be useful to experiment with taking the results of the `sentiment_analysis` function and passing it to the other functions to see how having the sentiment of the conversation impacts the other attributes.

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
def sentiment_analysis(transcription):
    response = client.chat.completions.create(
        model="gpt-4",
        temperature=0,
        messages=[\
            {\
                "role": "system",\
                "content": "As an AI with expertise in language and emotion analysis, your task is to analyze the sentiment of the following text. Please consider the overall tone of the discussion, the emotion conveyed by the language used, and the context in which words and phrases are used. Indicate whether the sentiment is generally positive, negative, or neutral, and provide brief explanations for your analysis where possible."\
            },\
            {\
                "role": "user",\
                "content": transcription\
            }\
        ]
    )
    return completion.choices[0].message.content
```

## Exporting meeting minutes

![Audio Waveform created by DALL·E](https://cdn.openai.com/API/docs/images/tutorials/meeting-minutes/waveform4.png)

Once we've generated the meeting minutes, it's beneficial to save them into a
readable format that can be easily distributed. One common format for such
reports is Microsoft Word. The Python docx library is a popular open source
library for creating Word documents. If you wanted to build an end-to-end
meeting minute application, you might consider removing this export step in
favor of sending the summary inline as an email followup.

To handle the exporting process, define a function `save_as_docx` that converts the raw text to a Word document:

```python
1
2
3
4
5
6
7
8
9
10
def save_as_docx(minutes, filename):
    doc = Document()
    for key, value in minutes.items():
        # Replace underscores with spaces and capitalize each word for the heading
        heading = ' '.join(word.capitalize() for word in key.split('_'))
        doc.add_heading(heading, level=1)
        doc.add_paragraph(value)
        # Add a line break between sections
        doc.add_paragraph()
    doc.save(filename)
```

In this function, minutes is a dictionary containing the abstract summary, key points, action items, and sentiment analysis from the meeting. Filename is the name of the Word document file to be created. The function creates a new Word document, adds headings and content for each part of the minutes, and then saves the document to the current working directory.

Finally, you can put it all together and generate the meeting minutes from an audio file:

```python
1
2
3
4
5
6
audio_file_path = "Earningscall.wav"
transcription = transcribe_audio(audio_file_path)
minutes = meeting_minutes(transcription)
print(minutes)

save_as_docx(minutes, 'meeting_minutes.docx')
```

This code will transcribe the audio file `Earningscall.wav`, generates the meeting minutes, prints them, and then saves them into a Word document called `meeting_minutes.docx`.

Now that you have the basic meeting minutes processing setup, consider trying to optimize the performance with [prompt engineering](/docs/guides/prompt-engineering) or build an end-to-end system with native [function calling](/docs/guides/function-calling).Log in [Sign up](/signup)

# Changelog

December, 2024

Dec 4

Update

- Launched [Usage API](/docs/api-reference/usage),
enabling customers to programmatically query activities and spending across OpenAI APIs.

November, 2024

Nov 20

Updatev1/chat/completions

- Released [gpt-4o-2024-11-20](/docs/models#gpt-4o), our newest model in the
gpt-4o series.

Nov 4

Featurev1/chat/completions

- Released
[Predicted Outputs](/docs/guides/predicted-outputs),
which greatly reduces latency for model responses where much of the response
is known ahead of time. This is most common when regenerating the content of
documents and code files with only minor changes.

October, 2024

Oct 30

Featuregpt-4o-realtime-previewgpt-4o-audio-previewv1/chat/completions

- Added five new voice types in the [Realtime API](/docs/guides/realtime) and
[Chat Completions API](/docs/guides/audio).

Oct 17

Featuregpt-4o-audio-previewv1/chat/completions

- Released [new `gpt-4o-audio-preview` model](/docs/guides/audio) for chat
completions, which supports both audio inputs and outputs. Uses the same
underlying model as the [Realtime API](/docs/guides/realtime).

Oct 1

Featurev1/realtimev1/chat/completionsv1/fine-tunes

Released several new features at
[OpenAI DevDay in San Francisco](https://openai.com/devday/):

[Realtime API](/docs/guides/realtime): Build fast speech-to-speech
experiences into your applications using a WebSockets interface.

[Model distillation](/docs/guides/distillation): Platform for fine-tuning
cost-efficient models with your outputs from a large frontier model.

[Image fine-tuning](/docs/guides/fine-tuning#vision): Fine-tune GPT-4o
with images and text to improve vision capabilities.

[Evals](/docs/guides/evals): Create and run custom evaluations to measure
model performance on specific tasks.

[Prompt caching](/docs/guides/prompt-caching): Discounts and faster
processing times on recently seen input tokens.

[Generate in playground](/playground/chat): Easily generate prompts,
function definitions, and structured output schemas in the playground using
the Generate button.

September, 2024

Sep 26

Featureomni-moderation-latestv1/moderations

- Released
[new `omni-moderation-latest` moderation model](/docs/guides/moderation),
which supports both images and text (for some categories), supports two new
text-only harm categories, and has more accurate scores.

Sep 12

Featureo1-previewo1-miniv1/chat/completions

- Released [o1-preview and o1-mini](/docs/guides/reasoning), new large language
models trained with reinforcement learning to perform complex reasoning tasks.

August, 2024

Aug 29

Featurev1/assistants

- Assistants API now supports
[including file search results used by the file search tool, and customizing ranking behavior](/docs/assistants/tools/file-search#improve-file-search-result-relevance-with-chunk-ranking).

Aug 20

Featuregpt-4ov1/fine-tunes

- GA release for [`gpt-4o-2024-08-06` fine-tuning](/docs/guides/fine-tuning)—all
API users can now fine-tune the latest GPT-4o model.

Aug 15

Updategpt-4ov1/chat/completions

- Released [dynamic model for `chatgpt-4o-latest`](/docs/models#gpt-4o)—this
model will point to the latest GPT-4o model used by ChatGPT.

Aug 6

Update

- Launched [Structured Outputs](/docs/guides/structured-outputs)—model outputs
now reliabilty adhere to developer supplied JSON Schemas.
- Released [gpt-4o-2024-08-06](/docs/models#gpt-4o), our newest model in the
gpt-4o series.

Aug 1

Update

- Launched [Admin and Audit Log APIs](/docs/api-reference/administration),
allowing customers to programmatically administer their organization and
monitor changes using the audit logs. Audit logging must be enabled within
[settings](settings/organization/general).

July, 2024

Jul 24

Update

- Launched
[self-serve SSO configuration](https://help.openai.com/en/articles/9641482-api-platform-single-sign-on-sso-integration-for-existing-enterprise-customers),
allowing Enterprise customers on custom and unlimited billing to set up
authentication against their desired IDP.

Jul 23

Update

- Launched [fine-tuning for GPT-4o mini](/docs/guides/fine-tuning), enabling
even higher performance for specific use cases.

Jul 18

Update

- Released [GPT-4o mini](/docs/models#gpt-4o-mini), our affordable an
intelligent small model for fast, lightweight tasks.

Jul 17

Update

- Released [Uploads](/docs/api-reference/uploads) to upload large files in
multiple parts.

June, 2024

Jun 6

Update

- [Parallel function calling](/docs/guides/function-calling#configure-parallel-function-calling)
can be disabled in Chat Completions and the Assistants API by passing
`parallel_tool_calls=false`.
- [.NET SDK](/docs/libraries#dotnet-library) launched in Beta.

Jun 3

Update

- Added support for
[file search customizations](/docs/assistants/tools/file-search#customizing-file-search-settings)
.

May, 2024

May 15

Update

- Added support for [archiving projects](/projects) . Only organization owners
can access this functionality.
- Added support for [setting cost limits](/settings/organization/general) on a
per-project basis for pay as you go customers.

May 13

Update

- Released [GPT-4o](/docs/models#gpt-4o) in the API. GPT-4o is our fastest and
most affordable flagship model.

May 9

Update

- Added support for
[image inputs to the Assistants API.](/docs/assistants/overview)

May 7

Update

- Added support for
[fine-tuned models to the Batch API](/docs/guides/batch#model-availability) .

May 6

Update

- Added
[`stream_options: {"include_usage": true}`](/docs/api-reference/chat/create#chat-create-stream_options)
parameter to the Chat Completions and Completions APIs. Setting this gives
developers access to usage stats when using streaming.

May 2

Update

- Added [a new endpoint](/docs/api-reference/messages/deleteMessage) to delete a
message from a thread in the Assistants API.

April, 2024

Apr 29

Update

- Added a new
[function calling option `tool_choice: "required"`](/docs/guides/function-calling#function-calling-behavior)
to the Chat Completions and Assistants APIs.
- Added a [guide for the Batch API](/docs/guides/batch) and Batch API support
for [embeddings models](/docs/guides/batch#model-availability)

Apr 17

Update

- Introduced a
[series of updates to the Assistants API](/docs/assistants/whats-new) ,
including a new file search tool allowing up to 10,000 files per assistant,
new token controls, and support for tool choice.

Apr 16

Update

- Introduced [project based hierarchy](../settings/organization/general) for
organizing work by projects, including the ability to create
[API keys](/docs/api-reference/authentication) and manage rate and cost limits
on a per-project basis (cost limits available only for Enterprise customers).

Apr 15

Update

- Released [Batch API](/docs/guides/batch)

Apr 9

Update

- Released [GPT-4 Turbo with Vision](/docs/models#gpt-4-turbo-and-gpt-4) in
general availability in the API

Apr 4

Update

- Added support for [seed](/docs/api-reference/fine-tuning/create) in the
fine-tuning API
- Added support for
[checkpoints](/docs/api-reference/fine-tuning/list-checkpoints) in the
fine-tuning API
- Added support for
[adding Messages when creating a Run](/docs/api-reference/runs/createRun#runs-createrun-additional_messages)
in the Assistants API

Apr 1

Update

- Added support for
[filtering Messages by run\_id](/docs/api-reference/messages/listMessages#messages-listmessages-run_id)
in the Assistants API

March, 2024

Mar 29

Update

- Added support for
[temperature](/docs/api-reference/runs/createRun#runs-createrun-temperature)
and
[assistant message creation](/docs/api-reference/messages/createMessage#messages-createmessage-role)
in the Assistants API

Mar 14

Update

- Added support for [streaming](/docs/assistants/overview) in the Assistants API

February, 2024

Feb 9

Update

- Added [`timestamp_granularities` parameter](/docs/models#gpt-3-5-turbo) to the
Audio API

Feb 1

Update

- Released
[gpt-3.5-turbo-0125, an updated GPT-3.5 Turbo model](/docs/models#gpt-3-5-turbo)

January, 2024

Jan 25

Update

- Released
[embedding V3 models and an updated GPT-4 Turbo preview](/docs/models#overview)
- Added
[`dimensions` parameter](/docs/api-reference/embeddings/create#embeddings-create-dimensions)
to the Embeddings API

December, 2023

Dec 20

Update

- Added
[`additional_instructions` parameter](/docs/api-reference/runs/createRun#runs-createrun-additional_instructions)
to run creation in the Assistants API

Dec 15

Update

- Added
[`logprobs` and `top_logprobs` parameters](/docs/api-reference/chat/create#chat-create-logprobs)
to the Chat Completions API

Dec 14

Update

- Changed
[function parameters](/docs/api-reference/chat/create#chat-create-tools)
argument on a tool call to be optional

November, 2023

Nov 30

Update

- Released [OpenAI Deno SDK](https://deno.land/x/openai)

Nov 6

Update

- Released [GPT-4 Turbo Preview](/docs/models#gpt-4-turbo-and-gpt-4) ,
[updated GPT-3.5 Turbo](/docs/models#gpt-3-5-turbo),
[GPT-4 Turbo with Vision](/docs/guides/vision),
[Assistants API](/docs/assistants/overview),
[DALL·E 3 in the API](/docs/models#dall-e), and
[text-to-speech API](/docs/guides/text-to-speech)
- Deprecated the Chat Completions `functions` parameter
[in favor of `tools`](/docs/api-reference/chat/create#chat-create-tools)
- Released [OpenAI Python SDK V1.0](/docs/libraries#python-library)

October, 2023

Oct 16

Update

- Added
[`encoding_format` parameter](/docs/api-reference/embeddings/create#embeddings-create-encoding_format)
to the Embeddings API
- Added `max_tokens` to the [Moderation models](/docs/models#moderation)

Oct 6

Update

- Added
[function calling support](/docs/guides/fine-tuning#fine-tuning-examples) to
the Fine-tuning APILog in [Sign up](/signup)

# Text generation

Copy page

Learn how to generate text from a prompt.

OpenAI provides simple APIs to use a [large language model](/docs/models) to generate text from a prompt, as you might using [ChatGPT](https://chatgpt.com). These models have been trained on vast quantities of data to understand multimedia inputs and natural language instructions. From these [prompts](/docs/guides/prompt-engineering), models can generate almost any kind of text response, like code, mathematical equations, structured JSON data, or human-like prose.

## Quickstart

To generate text, you can use the [chat completions endpoint](/docs/api-reference/chat/) in the REST API, as seen in the examples below. You can either use the [REST API](/docs/api-reference) from the HTTP client of your choice, or use one of OpenAI's [official SDKs](/docs/libraries) for your preferred programming language.

Generate proseAnalyze an imageGenerate JSON data

Create a human-like response to a prompt

javascript

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import OpenAI from "openai";
const openai = new OpenAI();

const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [\
        { role: "system", content: "You are a helpful assistant." },\
        {\
            role: "user",\
            content: "Write a haiku about recursion in programming.",\
        },\
    ],
});

console.log(completion.choices[0].message);
```

## Choosing a model

When making a text generation request, the first option to configure is which [model](/docs/models) you want to generate the response. The model you choose can greatly influence the output, and impact how much each generation request [costs](https://openai.com/api/pricing/).

- A **large model** like [`gpt-4o`](/docs/models#gpt-4o) will offer a very high level of intelligence and strong performance, while having a higher cost per token.
- A **small model** like [`gpt-4o-mini`](/docs/models#gpt-4o-mini) offers intelligence not quite on the level of the larger model, but is faster and less expensive per token.
- A **reasoning model** like [the `o1` family of models](/docs/models#o1) is slower to return a result, and uses more tokens to "think", but is capable of advanced reasoning, coding, and multi-step planning.

Experiment with different models [in the Playground](/playground) to see which one works best for your prompts! More information on choosing a model can [also be found here](/docs/guides/model-selection).

## Building prompts

The process of crafting prompts to get the right output from a model is called **prompt engineering**. By giving the model precise instructions, examples, and necessary context information (like private or specialized information that wasn't included in the model's training data), you can improve the quality and accuracy of the model's output. Here, we'll get into some high-level guidance on building prompts, but you might also find the [prompt engineering guide](/docs/guides/prompt-engineering) helpful.

In the [chat completions](/docs/api-reference/chat/) API, you create prompts by providing an array of `messages` that contain instructions for the model. Each message can have a different `role`, which influences how the model might interpret the input.

### User messages

User messages contain instructions that request a particular type of output from the model. You can think of `user` messages as the messages you might type in to [ChatGPT](https://chaptgpt.com) as an end user.

Here's an example of a user message prompt that asks the `gpt-4o` model to generate a haiku poem based on a prompt.

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": "Write a haiku about programming."\
        }\
      ]\
    }\
  ]
});
```

### System messages

Messages with the `system` role act as top-level instructions to the model, and typically describe what the model is supposed to do and how it should generally behave and respond.

Here's an example of a system message that modifies the behavior of the model when generating a response to a `user` message:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "system",\
      "content": [\
        {\
          "type": "text",\
          "text": `\
            You are a helpful assistant that answers programming questions\
            in the style of a southern belle from the southeast United States.\
          `\
        }\
      ]\
    },\
    {\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": "Are semicolons optional in JavaScript?"\
        }\
      ]\
    }\
  ]
});
```

This prompt returns a text output in the rhetorical style requested:

```text
1
2
3
4
5
6
7
8
Well, sugar, that's a fine question you've got there! Now, in the world of
JavaScript, semicolons are indeed a bit like the pearls on a necklace – you
might slip by without 'em, but you sure do look more polished with 'em in place.

Technically, JavaScript has this little thing called "automatic semicolon
insertion" where it kindly adds semicolons for you where it thinks they
oughta go. However, it's not always perfect, bless its heart. Sometimes, it
might get a tad confused and cause all sorts of unexpected behavior.
```

### Assistant messages

Messages with the `assistant` role are presumed to have been generated by the model, perhaps in a previous generation request (see the "Conversations" section below). They can also be used to provide examples to the model for how it should respond to the current request - a technique known as **few-shot learning**.

Here's an example of using an assistant message to capture the results of a previous text generation result, and making a new request based on that.

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "knock knock." }]\
    },\
    {\
      "role": "assistant",\
      "content": [{ "type": "text", "text": "Who's there?" }]\
    },\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "Orange." }]\
    }\
  ]
});
```

### Giving the model additional data to use for generation

The message types above can also be used to provide additional information to the model which may be outside its training data. You might want to include the results of a database query, a text document, or other resources to help the model generate a relevant response. This technique is often referred to as **retrieval augmented generation**, or RAG. [Learn more about RAG techniques here](https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts).

## Conversations and context

While each text generation request is independent and stateless (unless you are using [assistants](/docs/assistants/overview)), you can still implement **multi-turn conversations** by providing additional messages as parameters to your text generation request. Consider the "knock knock" joke example shown above:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
const response = await openai.chat.completions.create({
  model: "gpt-4o",
  messages: [\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "knock knock." }]\
    },\
    {\
      "role": "assistant",\
      "content": [{ "type": "text", "text": "Who's there?" }]\
    },\
    {\
      "role": "user",\
      "content": [{ "type": "text", "text": "Orange." }]\
    }\
  ]
});
```

By using alternating `user` and `assistant` messages, you can capture the previous state of a conversation in one request to the model.

### Managing context for text generation

As your inputs become more complex, or you include more and more turns in a conversation, you will need to consider both **output token** and **context window** limits. Model inputs and outputs are metered in [**tokens**](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them), which are parsed from inputs to analyze their content and intent, and assembled to render logical outputs. Models have limits on how many tokens can be used during the lifecycle of a text generation request.

- **Output tokens** are the tokens that are generated by a model in response to a prompt. Each model supports different limits for output tokens, [documented here](/docs/models). For example, `gpt-4o-2024-08-06` can generate a maximum of 16,384 output tokens.
- A **context window** describes the total tokens that can be used for both input tokens and output tokens (and for some models, [reasoning tokens](/docs/guides/reasoning)), [documented here](/docs/models). For example, `gpt-4o-2024-08-06` has a total context window of 128k tokens.

If you create a very large prompt (usually by including a lot of conversation context or additional data/examples for the model), you run the risk of exceeding the allocated context window for a model, which might result in truncated outputs.

You can use the [tokenizer tool](/tokenizer) (which uses the [tiktoken library](https://github.com/openai/tiktoken)) to see how many tokens are present in a string of text.

## Optimizing model outputs

As you iterate on your prompts, you will be continually trying to improve **accuracy**, **cost**, and **latency**.

|  | Goal | Available techniques |
| --- | --- | --- |
| **Accuracy** | Ensure the model produces accurate and useful responses to your prompts. | Accurate responses require that the model has all the information it needs<br>to generate a response, and knows how to go about creating a response<br>(from interpreting input to formatting and styling). Often, this will<br>require a mix of [prompt engineering](/docs/guides/prompt-engineering),<br>[RAG](https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts),<br>and [model fine-tuning](/docs/guides/fine-tuning).<br>[Learn about optimizing for accuracy here](/docs/guides/optimizing-llm-accuracy). |
| **Cost** | Drive down the total cost of model usage by reducing token usage and using cheaper models when possible. | To control costs, you can try to use fewer tokens or smaller, cheaper models.<br>[Learn more about optimizing for cost here](/docs/guides/model-selection). |
| **Latency** | Decrease the time it takes to generate responses to your prompts. | Optimizing latency is a multi-faceted process including prompt engineering,<br>parallelism in your own code, and more.<br>[Learn more here](/docs/guides/latency-optimization). |

## Next steps

There's much more to explore in text generation - here's a few resources to go even deeper.

[Prompt examples\\
\\
Get inspired by example prompts for a variety of use cases.](/docs/examples) [Build a prompt in the Playground\\
\\
Use the Playground to develop and iterate on prompts.](/playground) [Browse the Cookbook\\
\\
The Cookbook has complex examples covering a variety of use cases.](/docs/guides/https://cookbook.openai.com) [Generate JSON data with Structured Outputs\\
\\
Ensure JSON data emitted from a model conforms to a JSON schema.](/docs/guides/structured-outputs) [Full API reference\\
\\
Check out all the options for text generation in the API reference.](/docs/api-reference/chat)Log in [Sign up](/signup)

# Error codes

Copy page

Explore API error codes and solutions.

This guide includes an overview on error codes you might see from both the [API](/docs/introduction) and our [official Python library](/docs/libraries#python-library). Each error code mentioned in the overview has a dedicated section with further guidance.

## API errors

| Code | Overview |
| --- | --- |
| 401 - Invalid Authentication | **Cause:** Invalid Authentication <br>**Solution:** Ensure the correct [API key](/settings/organization/api-keys) and requesting organization are being used. |
| 401 - Incorrect API key provided | **Cause:** The requesting API key is not correct. <br>**Solution:** Ensure the API key used is correct, clear your browser cache, or [generate a new one](/settings/organization/api-keys). |
| 401 - You must be a member of an organization to use the API | **Cause:** Your account is not part of an organization. <br>**Solution:** Contact us to get added to a new organization or ask your organization manager to [invite you to an organization](/settings/organization/members). |
| 403 - Country, region, or territory not supported | **Cause:** You are accessing the API from an unsupported country, region, or territory. <br>**Solution:** Please see [this page](/docs/supported-countries) for more information. |
| 429 - Rate limit reached for requests | **Cause:** You are sending requests too quickly. <br>**Solution:** Pace your requests. Read the [Rate limit guide](/docs/guides/rate-limits). |
| 429 - You exceeded your current quota, please check your plan and billing details | **Cause:** You have run out of credits or hit your maximum monthly spend. <br>**Solution:** [Buy more credits](/settings/organization/billing) or learn how to [increase your limits](/settings/organization/limits). |
| 500 - The server had an error while processing your request | **Cause:** Issue on our servers. <br>**Solution:** Retry your request after a brief wait and contact us if the issue persists. Check the [status page](https://status.openai.com/). |
| 503 - The engine is currently overloaded, please try again later | **Cause:** Our servers are experiencing high traffic. <br>**Solution:** Please retry your requests after a brief wait. |

401 - Invalid Authentication

This error message indicates that your authentication credentials are invalid. This could happen for several reasons, such as:

- You are using a revoked API key.
- You are using a different API key than the one assigned to the requesting organization or project.
- You are using an API key that does not have the required permissions for the endpoint you are calling.

To resolve this error, please follow these steps:

- Check that you are using the correct API key and organization ID in your request header. You can find your API key and organization ID in [your account settings](/settings/organization/api-keys) or your can find specific project related keys under [General settings](/settings/organization/general) by selecting the desired project.
- If you are unsure whether your API key is valid, you can [generate a new one](/settings/organization/api-keys). Make sure to replace your old API key with the new one in your requests and follow our [best practices guide](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety).

401 - Incorrect API key provided

This error message indicates that the API key you are using in your request is not correct. This could happen for several reasons, such as:

- There is a typo or an extra space in your API key.
- You are using an API key that belongs to a different organization or project.
- You are using an API key that has been deleted or deactivated.
- An old, revoked API key might be cached locally.

To resolve this error, please follow these steps:

- Try clearing your browser's cache and cookies, then try again.
- Check that you are using the correct API key in your request header.
- If you are unsure whether your API key is correct, you can [generate a new one](/settings/organization/api-keys). Make sure to replace your old API key in your codebase and follow our [best practices guide](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety).

401 - You must be a member of an organization to use the API

This error message indicates that your account is not part of an organization. This could happen for several reasons, such as:

- You have left or been removed from your previous organization.
- You have left or been removed from your previous project.
- Your organization has been deleted.

To resolve this error, please follow these steps:

- If you have left or been removed from your previous organization, you can either request a new organization or get invited to an existing one.
- To request a new organization, reach out to us via help.openai.com
- Existing organization owners can invite you to join their organization via the [Team page](/settings/organization/members) or can create a new project from the [Settings page](settings/organization/general)
- If you have left or been removed from a previous project, you can ask your organization or project owner to add you to it, or create a new one.

429 - Rate limit reached for requests

This error message indicates that you have hit your assigned rate limit for the API. This means that you have submitted too many tokens or requests in a short period of time and have exceeded the number of requests allowed. This could happen for several reasons, such as:

- You are using a loop or a script that makes frequent or concurrent requests.
- You are sharing your API key with other users or applications.
- You are using a free plan that has a low rate limit.
- You have reached the defined limit on your project

To resolve this error, please follow these steps:

- Pace your requests and avoid making unnecessary or redundant calls.
- If you are using a loop or a script, make sure to implement a backoff mechanism or a retry logic that respects the rate limit and the response headers. You can read more about our rate limiting policy and best practices in our [rate limit guide](/docs/guides/rate-limits).
- If you are sharing your organization with other users, note that limits are applied per organization and not per user. It is worth checking on the usage of the rest of your team as this will contribute to the limit.
- If you are using a free or low-tier plan, consider upgrading to a pay-as-you-go plan that offers a higher rate limit. You can compare the restrictions of each plan in our [rate limit guide](/docs/guides/rate-limits).
- Reach out to your organization owner to increase the rate limits on your project

429 - You exceeded your current quota, please check your plan and billing details

This error message indicates that you hit your monthly [usage limit](/settings/organization/limits) for the API, or for prepaid credits customers that you've consumed all your credits. You can view your maximum usage limit on the [limits page](/settings/organization/limits). This could happen for several reasons, such as:

- You are using a high-volume or complex service that consumes a lot of credits or tokens.
- Your monthly budget is set too low for your organization’s usage.
- Your monthly budget is set too low for your project's usage.

To resolve this error, please follow these steps:

- Check your [current usage](/settings/organization/usage) of your account, and compare that to your account's [limits](/settings/organization/limits).
- If you are on a free plan, consider [upgrading to a paid plan](/settings/organization/billing) to get higher limits.
- Reach out to your organization owner to increase the budgets for your project.

503 - The engine is currently overloaded, please try again later

This error message indicates that our servers are experiencing high traffic and are unable to process your request at the moment. This could happen for several reasons, such as:

- There is a sudden spike or surge in demand for our services.
- There is scheduled or unscheduled maintenance or update on our servers.
- There is an unexpected or unavoidable outage or incident on our servers.

To resolve this error, please follow these steps:

- Retry your request after a brief wait. We recommend using an exponential backoff strategy or a retry logic that respects the response headers and the rate limit. You can read more about our rate limit [best practices](https://help.openai.com/en/articles/6891753-rate-limit-advice).
- Check our [status page](https://status.openai.com/) for any updates or announcements regarding our services and servers.
- If you are still getting this error after a reasonable amount of time, please contact us for further assistance. We apologize for any inconvenience and appreciate your patience and understanding.

## Python library error types

| Type | Overview |
| --- | --- |
| APIConnectionError | **Cause:** Issue connecting to our services. <br>**Solution:** Check your network settings, proxy configuration, SSL certificates, or firewall rules. |
| APITimeoutError | **Cause:** Request timed out. <br>**Solution:** Retry your request after a brief wait and contact us if the issue persists. |
| AuthenticationError | **Cause:** Your API key or token was invalid, expired, or revoked. <br>**Solution:** Check your API key or token and make sure it is correct and active. You may need to generate a new one from your account dashboard. |
| BadRequestError | **Cause:** Your request was malformed or missing some required parameters, such as a token or an input. <br>**Solution:** The error message should advise you on the specific error made. Check the [documentation](/docs/api-reference/) for the specific API method you are calling and make sure you are sending valid and complete parameters. You may also need to check the encoding, format, or size of your request data. |
| ConflictError | **Cause:** The resource was updated by another request. <br>**Solution:** Try to update the resource again and ensure no other requests are trying to update it. |
| InternalServerError | **Cause:** Issue on our side. <br>**Solution:** Retry your request after a brief wait and contact us if the issue persists. |
| NotFoundError | **Cause:** Requested resource does not exist. <br>**Solution:** Ensure you are the correct resource identifier. |
| PermissionDeniedError | **Cause:** You don't have access to the requested resource. <br>**Solution:** Ensure you are using the correct API key, organization ID, and resource ID. |
| RateLimitError | **Cause:** You have hit your assigned rate limit. <br>**Solution:** Pace your requests. Read more in our [Rate limit guide](/docs/guides/rate-limits). |
| UnprocessableEntityError | **Cause:** Unable to process the request despite the format being correct. <br>**Solution:** Please try the request again. |

APIConnectionError

An `APIConnectionError` indicates that your request could not reach our servers or establish a secure connection. This could be due to a network issue, a proxy configuration, an SSL certificate, or a firewall rule.

If you encounter an `APIConnectionError`, please try the following steps:

- Check your network settings and make sure you have a stable and fast internet connection. You may need to switch to a different network, use a wired connection, or reduce the number of devices or applications using your bandwidth.
- Check your proxy configuration and make sure it is compatible with our services. You may need to update your proxy settings, use a different proxy, or bypass the proxy altogether.
- Check your SSL certificates and make sure they are valid and up-to-date. You may need to install or renew your certificates, use a different certificate authority, or disable SSL verification.
- Check your firewall rules and make sure they are not blocking or filtering our services. You may need to modify your firewall settings.
- If appropriate, check that your container has the correct permissions to send and receive traffic.
- If the issue persists, check out our persistent errors next steps section.

APITimeoutError

A `APITimeoutError` error indicates that your request took too long to complete and our server closed the connection. This could be due to a network issue, a heavy load on our services, or a complex request that requires more processing time.

If you encounter a `APITimeoutError` error, please try the following steps:

- Wait a few seconds and retry your request. Sometimes, the network congestion or the load on our services may be reduced and your request may succeed on the second attempt.
- Check your network settings and make sure you have a stable and fast internet connection. You may need to switch to a different network, use a wired connection, or reduce the number of devices or applications using your bandwidth.
- If the issue persists, check out our persistent errors next steps section.

AuthenticationError

An `AuthenticationError` indicates that your API key or token was invalid, expired, or revoked. This could be due to a typo, a formatting error, or a security breach.

If you encounter an `AuthenticationError`, please try the following steps:

- Check your API key or token and make sure it is correct and active. You may need to generate a new key from the API Key dashboard, ensure there are no extra spaces or characters, or use a different key or token if you have multiple ones.
- Ensure that you have followed the correct formatting.

BadRequestError

An `BadRequestError` (formerly `InvalidRequestError`) indicates that your request was malformed or missing some required parameters, such as a token or an input. This could be due to a typo, a formatting error, or a logic error in your code.

If you encounter an `BadRequestError`, please try the following steps:

- Read the error message carefully and identify the specific error made. The error message should advise you on what parameter was invalid or missing, and what value or format was expected.
- Check the [API Reference](/docs/api-reference/) for the specific API method you were calling and make sure you are sending valid and complete parameters. You may need to review the parameter names, types, values, and formats, and ensure they match the documentation.
- Check the encoding, format, or size of your request data and make sure they are compatible with our services. You may need to encode your data in UTF-8, format your data in JSON, or compress your data if it is too large.
- Test your request using a tool like Postman or curl and make sure it works as expected. You may need to debug your code and fix any errors or inconsistencies in your request logic.
- If the issue persists, check out our persistent errors next steps section.

InternalServerError

An `InternalServerError` indicates that something went wrong on our side when processing your request. This could be due to a temporary error, a bug, or a system outage.

We apologize for any inconvenience and we are working hard to resolve any issues as soon as possible. You can [check our system status page](https://status.openai.com/) for more information.

If you encounter an `InternalServerError`, please try the following steps:

- Wait a few seconds and retry your request. Sometimes, the issue may be resolved quickly and your request may succeed on the second attempt.
- Check our status page for any ongoing incidents or maintenance that may affect our services. If there is an active incident, please follow the updates and wait until it is resolved before retrying your request.
- If the issue persists, check out our Persistent errors next steps section.

Our support team will investigate the issue and get back to you as soon as possible. Note that our support queue times may be long due to high demand. You can also [post in our Community Forum](https://community.openai.com) but be sure to omit any sensitive information.

RateLimitError

A `RateLimitError` indicates that you have hit your assigned rate limit. This means that you have sent too many tokens or requests in a given period of time, and our services have temporarily blocked you from sending more.

We impose rate limits to ensure fair and efficient use of our resources and to prevent abuse or overload of our services.

If you encounter a `RateLimitError`, please try the following steps:

- Send fewer tokens or requests or slow down. You may need to reduce the frequency or volume of your requests, batch your tokens, or implement exponential backoff. You can read our [Rate limit guide](/docs/guides/rate-limits) for more details.
- Wait until your rate limit resets (one minute) and retry your request. The error message should give you a sense of your usage rate and permitted usage.
- You can also check your API usage statistics from your account dashboard.

### Persistent errors

If the issue persists, [contact our support team via chat](https://help.openai.com/en/) and provide them with the following information:

- The model you were using
- The error message and code you received
- The request data and headers you sent
- The timestamp and timezone of your request
- Any other relevant details that may help us diagnose the issue

Our support team will investigate the issue and get back to you as soon as possible. Note that our support queue times may be long due to high demand. You can also [post in our Community Forum](https://community.openai.com) but be sure to omit any sensitive information.

### Handling errors

We advise you to programmatically handle errors returned by the API. To do so, you may want to use a code snippet like below:

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
import openai
from openai import OpenAI
client = OpenAI()

try:
  #Make your OpenAI API request here
  response = client.chat.completions.create(
    prompt="Hello world",
    model="gpt-4o-mini"
  )
except openai.APIError as e:
  #Handle API error here, e.g. retry or log
  print(f"OpenAI API returned an API Error: {e}")
  pass
except openai.APIConnectionError as e:
  #Handle connection error here
  print(f"Failed to connect to OpenAI API: {e}")
  pass
except openai.RateLimitError as e:
  #Handle rate limit error (we recommend using exponential backoff)
  print(f"OpenAI API request exceeded rate limit: {e}")
  pass
```Log in [Sign up](/signup)

# Prompt generation

Copy page

Generate prompts and schemas in Playground.

The **Generate** button in the [Playground](/playground/chat) lets you generate prompts, [functions](/docs/guides/function-calling), and [schemas](/docs/guides/structured-outputs#supported-schemas) from just a description of your task. This guide will walk through exactly how it works.

## Overview

Creating prompts and schemas from scratch can be time-consuming, so generating them can help you get started quickly. The Generate button uses two main approaches:

1. **Prompts:** We use **meta-prompts** that incorporate best practices to generate or improve prompts.
2. **Schemas:** We use **meta-schemas** that produce valid JSON and function syntax.

While we currently use meta prompts and schemas, we may integrate more advanced techniques in the future like [DSPy](https://arxiv.org/abs/2310.03714) and ["Gradient Descent"](https://arxiv.org/abs/2305.03495).

## Prompts

A **meta-prompt** instructs the model to create a good prompt based on your task description or improve an existing one. The meta-prompts in the Playground draw from our [prompt engineering](/docs/guides/prompt-engineering) best practices and real-world experience with users.

We use specific meta-prompts for different output types, like audio, to ensure the generated prompts meet the expected format.

### Meta-prompts

Text-outAudio-out

Text meta-prompt

python

````python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
from openai import OpenAI

client = OpenAI()

META_PROMPT = """
Given a task description or existing prompt, produce a detailed system prompt to guide a language model in completing the task effectively.

# Guidelines

- Understand the Task: Grasp the main objective, goals, requirements, constraints, and expected output.
- Minimal Changes: If an existing prompt is provided, improve it only if it's simple. For complex prompts, enhance clarity and add missing elements without altering the original structure.
- Reasoning Before Conclusions**: Encourage reasoning steps before any conclusions are reached. ATTENTION! If the user provides examples where the reasoning happens afterward, REVERSE the order! NEVER START EXAMPLES WITH CONCLUSIONS!
    - Reasoning Order: Call out reasoning portions of the prompt and conclusion parts (specific fields by name). For each, determine the ORDER in which this is done, and whether it needs to be reversed.
    - Conclusion, classifications, or results should ALWAYS appear last.
- Examples: Include high-quality examples if helpful, using placeholders [in brackets] for complex elements.
   - What kinds of examples may need to be included, how many, and whether they are complex enough to benefit from placeholders.
- Clarity and Conciseness: Use clear, specific language. Avoid unnecessary instructions or bland statements.
- Formatting: Use markdown features for readability. DO NOT USE ``` CODE BLOCKS UNLESS SPECIFICALLY REQUESTED.
- Preserve User Content: If the input task or prompt includes extensive guidelines or examples, preserve them entirely, or as closely as possible. If they are vague, consider breaking down into sub-steps. Keep any details, guidelines, examples, variables, or placeholders provided by the user.
- Constants: DO include constants in the prompt, as they are not susceptible to prompt injection. Such as guides, rubrics, and examples.
- Output Format: Explicitly the most appropriate output format, in detail. This should include length and syntax (e.g. short sentence, paragraph, JSON, etc.)
    - For tasks outputting well-defined or structured data (classification, JSON, etc.) bias toward outputting a JSON.
    - JSON should never be wrapped in code blocks (```) unless explicitly requested.

The final prompt you output should adhere to the following structure below. Do not include any additional commentary, only output the completed system prompt. SPECIFICALLY, do not include any additional messages at the start or end of the prompt. (e.g. no "---")

[Concise instruction describing the task - this should be the first line in the prompt, no section header]

[Additional details as needed.]

[Optional sections with headings or bullet points for detailed steps.]

# Steps [optional]

[optional: a detailed breakdown of the steps necessary to accomplish the task]

# Output Format

[Specifically call out how the output should be formatted, be it response length, structure e.g. JSON, markdown, etc]

# Examples [optional]

[Optional: 1-3 well-defined examples with placeholders if necessary. Clearly mark where examples start and end, and what the input and output are. User placeholders as necessary.]
[If the examples are shorter than what a realistic example is expected to be, make a reference with () explaining how real examples should be longer / shorter / different. AND USE PLACEHOLDERS! ]

# Notes [optional]

[optional: edge cases, details, and an area to call or repeat out specific important considerations]
""".strip()

def generate_prompt(task_or_prompt: str):
    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=[\
            {\
                "role": "system",\
                "content": META_PROMPT,\
            },\
            {\
                "role": "user",\
                "content": "Task, Goal, or Current Prompt:\n" + task_or_prompt,\
            },\
        ],
    )

    return completion.choices[0].message.content
````

### Prompt edits

To edit prompts, we use a slightly modified meta-prompt. While direct edits are straightforward to apply, identifying necessary changes for more open-ended revisions can be challenging. To address this, we include a **reasoning section** at the beginning of the response. This section helps guide the model in determining what changes are needed by evaluating the existing prompt's clarity, chain-of-thought ordering, overall structure, and specificity, among other factors. The reasoning section makes suggestions for improvements and is then parsed out from the final response.

Text-outAudio-out

Text meta-prompt for edits

python

````python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
from openai import OpenAI

client = OpenAI()

META_PROMPT = """
Given a current prompt and a change description, produce a detailed system prompt to guide a language model in completing the task effectively.

Your final output will be the full corrected prompt verbatim. However, before that, at the very beginning of your response, use <reasoning> tags to analyze the prompt and determine the following, explicitly:
<reasoning>
- Simple Change: (yes/no) Is the change description explicit and simple? (If so, skip the rest of these questions.)
- Reasoning: (yes/no) Does the current prompt use reasoning, analysis, or chain of thought?
    - Identify: (max 10 words) if so, which section(s) utilize reasoning?
    - Conclusion: (yes/no) is the chain of thought used to determine a conclusion?
    - Ordering: (before/after) is the chain of though located before or after
- Structure: (yes/no) does the input prompt have a well defined structure
- Examples: (yes/no) does the input prompt have few-shot examples
    - Representative: (1-5) if present, how representative are the examples?
- Complexity: (1-5) how complex is the input prompt?
    - Task: (1-5) how complex is the implied task?
    - Necessity: ()
- Specificity: (1-5) how detailed and specific is the prompt? (not to be confused with length)
- Prioritization: (list) what 1-3 categories are the MOST important to address.
- Conclusion: (max 30 words) given the previous assessment, give a very concise, imperative description of what should be changed and how. this does not have to adhere strictly to only the categories listed
</reasoning>

# Guidelines

- Understand the Task: Grasp the main objective, goals, requirements, constraints, and expected output.
- Minimal Changes: If an existing prompt is provided, improve it only if it's simple. For complex prompts, enhance clarity and add missing elements without altering the original structure.
- Reasoning Before Conclusions**: Encourage reasoning steps before any conclusions are reached. ATTENTION! If the user provides examples where the reasoning happens afterward, REVERSE the order! NEVER START EXAMPLES WITH CONCLUSIONS!
    - Reasoning Order: Call out reasoning portions of the prompt and conclusion parts (specific fields by name). For each, determine the ORDER in which this is done, and whether it needs to be reversed.
    - Conclusion, classifications, or results should ALWAYS appear last.
- Examples: Include high-quality examples if helpful, using placeholders [in brackets] for complex elements.
   - What kinds of examples may need to be included, how many, and whether they are complex enough to benefit from placeholders.
- Clarity and Conciseness: Use clear, specific language. Avoid unnecessary instructions or bland statements.
- Formatting: Use markdown features for readability. DO NOT USE ``` CODE BLOCKS UNLESS SPECIFICALLY REQUESTED.
- Preserve User Content: If the input task or prompt includes extensive guidelines or examples, preserve them entirely, or as closely as possible. If they are vague, consider breaking down into sub-steps. Keep any details, guidelines, examples, variables, or placeholders provided by the user.
- Constants: DO include constants in the prompt, as they are not susceptible to prompt injection. Such as guides, rubrics, and examples.
- Output Format: Explicitly the most appropriate output format, in detail. This should include length and syntax (e.g. short sentence, paragraph, JSON, etc.)
    - For tasks outputting well-defined or structured data (classification, JSON, etc.) bias toward outputting a JSON.
    - JSON should never be wrapped in code blocks (```) unless explicitly requested.

The final prompt you output should adhere to the following structure below. Do not include any additional commentary, only output the completed system prompt. SPECIFICALLY, do not include any additional messages at the start or end of the prompt. (e.g. no "---")

[Concise instruction describing the task - this should be the first line in the prompt, no section header]

[Additional details as needed.]

[Optional sections with headings or bullet points for detailed steps.]

# Steps [optional]

[optional: a detailed breakdown of the steps necessary to accomplish the task]

# Output Format

[Specifically call out how the output should be formatted, be it response length, structure e.g. JSON, markdown, etc]

# Examples [optional]

[Optional: 1-3 well-defined examples with placeholders if necessary. Clearly mark where examples start and end, and what the input and output are. User placeholders as necessary.]
[If the examples are shorter than what a realistic example is expected to be, make a reference with () explaining how real examples should be longer / shorter / different. AND USE PLACEHOLDERS! ]

# Notes [optional]

[optional: edge cases, details, and an area to call or repeat out specific important considerations]
[NOTE: you must start with a <reasoning> section. the immediate next token you produce should be <reasoning>]
""".strip()

def generate_prompt(task_or_prompt: str):
    completion = client.chat.completions.create(
        model="gpt-4o",
        messages=[\
            {\
                "role": "system",\
                "content": META_PROMPT,\
            },\
            {\
                "role": "user",\
                "content": "Task, Goal, or Current Prompt:\n" + task_or_prompt,\
            },\
        ],
    )

    return completion.choices[0].message.content
````

## Schemas

[Structured Outputs](/guides/structured-outputs) schemas and function schemas are themselves JSON objects, so we leverage Structured Outputs to generate them.
This requires defining a schema for the desired output, which in this case is itself a schema. To do this, we use a self-describing schema – a **meta-schema**.

Because the `parameters` field in a function schema is itself a schema, we use the same meta-schema to generate functions.

### Defining a constrained meta-schema

[Structured Outputs](/guides/structured-outputs) supports two modes: `strict=true` and `strict=false`. Both modes use the same model trained to follow the provided schema, but only "strict mode" guarantees perfect adherence through constrained sampling.

Our goal is to generate schemas for strict mode using strict mode itself. However, the official meta-schemas provided by the [JSON Schema Specification](https://json-schema.org/specification#meta-schemas) rely on features [not currently supported](/docs/guides/structured-outputs#some-type-specific-keywords-are-not-yet-supported) in strict mode. This poses challenges that affect both input and output schemas.

1. **Input schema:** We can't use [unsupported features](/docs/guides/structured-outputs#some-type-specific-keywords-are-not-yet-supported) in the input schema to describe the output schema.
2. **Output schema:** The generated schema must not include [unsupported features](/docs/guides/structured-outputs#some-type-specific-keywords-are-not-yet-supported).

Because we need to generate new keys in the output schema, the input meta-schema must use `additionalProperties`. This means we can't currently use strict mode to generate schemas. However, we still want the generated schema to conform to strict mode constraints.

To overcome this limitation, we define a **pseudo-meta-schema** — a meta-schema that uses features not supported in strict mode to describe only the features that are supported in strict mode. Essentially, this approach steps outside strict mode for the meta-schema definition while still ensuring that the generated schemas adhere to strict mode constraints.

Deep dive

How we designed the pseudo-meta-schema

### Output cleaning

Strict mode guarantees perfect schema adherence. Because we can't use it during generation, however, we need to validate and transform the output after generating it.

After generating a schema, we perform the following steps:

1. **Set `additionalProperties` to `false`** for all objects.
2. **Mark all properties as required**.
3. **For structured output schemas**, wrap them in [`json_schema`](/docs/guides/structured-outputs#how-to-use?context=without_parse) object.
4. **For functions**, wrap them in a [`function`](/docs/guides/function-calling#step-3-pass-your-function-definitions-as-available-tools-to-the-model-along-with-the-messages) object.

The Realtime API [function](/docs/guides/realtime#function-calls) object differs slightly from the Chat Completions API, but uses the same schema.

### Meta-schemas

Each meta-schema has a corresponding prompt which includes few-shot examples. When combined with the reliability of Structured Outputs — even without strict mode — we were able to use `gpt-4o-mini` for schema generation.

Structured output schemaFunction schema

Structured output meta-schema

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
from openai import OpenAI
import json

client = OpenAI()

META_SCHEMA = {
  "name": "metaschema",
  "schema": {
    "type": "object",
    "properties": {
      "name": {
        "type": "string",
        "description": "The name of the schema"
      },
      "type": {
        "type": "string",
        "enum": [\
          "object",\
          "array",\
          "string",\
          "number",\
          "boolean",\
          "null"\
        ]
      },
      "properties": {
        "type": "object",
        "additionalProperties": {
          "$ref": "#/$defs/schema_definition"
        }
      },
      "items": {
        "anyOf": [\
          {\
            "$ref": "#/$defs/schema_definition"\
          },\
          {\
            "type": "array",\
            "items": {\
              "$ref": "#/$defs/schema_definition"\
            }\
          }\
        ]
      },
      "required": {
        "type": "array",
        "items": {
          "type": "string"
        }
      },
      "additionalProperties": {
        "type": "boolean"
      }
    },
    "required": [\
      "type"\
    ],
    "additionalProperties": False,
    "if": {
      "properties": {
        "type": {
          "const": "object"
        }
      }
    },
    "then": {
      "required": [\
        "properties"\
      ]
    },
    "$defs": {
      "schema_definition": {
        "type": "object",
        "properties": {
          "type": {
            "type": "string",
            "enum": [\
              "object",\
              "array",\
              "string",\
              "number",\
              "boolean",\
              "null"\
            ]
          },
          "properties": {
            "type": "object",
            "additionalProperties": {
              "$ref": "#/$defs/schema_definition"
            }
          },
          "items": {
            "anyOf": [\
              {\
                "$ref": "#/$defs/schema_definition"\
              },\
              {\
                "type": "array",\
                "items": {\
                  "$ref": "#/$defs/schema_definition"\
                }\
              }\
            ]
          },
          "required": {
            "type": "array",
            "items": {
              "type": "string"
            }
          },
          "additionalProperties": {
            "type": "boolean"
          }
        },
        "required": [\
          "type"\
        ],
        "additionalProperties": False,
        "if": {
          "properties": {
            "type": {
              "const": "object"
            }
          }
        },
        "then": {
          "required": [\
            "properties"\
          ]
        }
      }
    }
  }
}

META_PROMPT = """
# Instructions
Return a valid schema for the described JSON.

You must also make sure:
- all fields in an object are set as required
- I REPEAT, ALL FIELDS MUST BE MARKED AS REQUIRED
- all objects must have additionalProperties set to false
    - because of this, some cases like "attributes" or "metadata" properties that would normally allow additional properties should instead have a fixed set of properties
- all objects must have properties defined
- field order matters. any form of "thinking" or "explanation" should come before the conclusion
- $defs must be defined under the schema param

Notable keywords NOT supported include:
- For strings: minLength, maxLength, pattern, format
- For numbers: minimum, maximum, multipleOf
- For objects: patternProperties, unevaluatedProperties, propertyNames, minProperties, maxProperties
- For arrays: unevaluatedItems, contains, minContains, maxContains, minItems, maxItems, uniqueItems

Other notes:
- definitions and recursion are supported
- only if necessary to include references e.g. "$defs", it must be inside the "schema" object

# Examples
Input: Generate a math reasoning schema with steps and a final answer.
Output: {
    "name": "math_reasoning",
    "type": "object",
    "properties": {
        "steps": {
            "type": "array",
            "description": "A sequence of steps involved in solving the math problem.",
            "items": {
                "type": "object",
                "properties": {
                    "explanation": {
                        "type": "string",
                        "description": "Description of the reasoning or method used in this step."
                    },
                    "output": {
                        "type": "string",
                        "description": "Result or outcome of this specific step."
                    }
                },
                "required": [\
                    "explanation",\
                    "output"\
                ],
                "additionalProperties": false
            }
        },
        "final_answer": {
            "type": "string",
            "description": "The final solution or answer to the math problem."
        }
    },
    "required": [\
        "steps",\
        "final_answer"\
    ],
    "additionalProperties": false
}

Input: Give me a linked list
Output: {
    "name": "linked_list",
    "type": "object",
    "properties": {
        "linked_list": {
            "$ref": "#/$defs/linked_list_node",
            "description": "The head node of the linked list."
        }
    },
    "$defs": {
        "linked_list_node": {
            "type": "object",
            "description": "Defines a node in a singly linked list.",
            "properties": {
                "value": {
                    "type": "number",
                    "description": "The value stored in this node."
                },
                "next": {
                    "anyOf": [\
                        {\
                            "$ref": "#/$defs/linked_list_node"\
                        },\
                        {\
                            "type": "null"\
                        }\
                    ],
                    "description": "Reference to the next node; null if it is the last node."
                }
            },
            "required": [\
                "value",\
                "next"\
            ],
            "additionalProperties": false
        }
    },
    "required": [\
        "linked_list"\
    ],
    "additionalProperties": false
}

Input: Dynamically generated UI
Output: {
    "name": "ui",
    "type": "object",
    "properties": {
        "type": {
            "type": "string",
            "description": "The type of the UI component",
            "enum": [\
                "div",\
                "button",\
                "header",\
                "section",\
                "field",\
                "form"\
            ]
        },
        "label": {
            "type": "string",
            "description": "The label of the UI component, used for buttons or form fields"
        },
        "children": {
            "type": "array",
            "description": "Nested UI components",
            "items": {
                "$ref": "#"
            }
        },
        "attributes": {
            "type": "array",
            "description": "Arbitrary attributes for the UI component, suitable for any element",
            "items": {
                "type": "object",
                "properties": {
                    "name": {
                        "type": "string",
                        "description": "The name of the attribute, for example onClick or className"
                    },
                    "value": {
                        "type": "string",
                        "description": "The value of the attribute"
                    }
                },
                "required": [\
                    "name",\
                    "value"\
                ],
                "additionalProperties": false
            }
        }
    },
    "required": [\
        "type",\
        "label",\
        "children",\
        "attributes"\
    ],
    "additionalProperties": false
}
""".strip()

def generate_schema(description: str):
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        response_format={"type": "json_schema", "json_schema": META_SCHEMA},
        messages=[\
            {\
                "role": "system",\
                "content": META_PROMPT,\
            },\
            {\
                "role": "user",\
                "content": "Description:\n" + description,\
            },\
        ],
    )

    return json.loads(completion.choices[0].message.content)
```Log in [Sign up](/signup)

# Models

Copy page

## Flagship models

[GPT-4o\\
\\
Our high-intelligence flagship model for complex, multi‑step tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Smarter model, higher price per token](/docs/models#gpt-4o)

[GPT-4o mini\\
\\
Our affordable and intelligent small model for fast, lightweight tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Faster model, lower price per token](/docs/models#gpt-4o-mini)

[o1-preview & o1-mini\\
\\
Beta\\
\\
A new series of reasoning models for solving hard problems\\
\\
Text input, text output\\
\\
128k context length\\
\\
Higher latency, uses tokens to think](/docs/models#o1)

[Model pricing details](https://openai.com/api/pricing)

## Models overview

The OpenAI API is powered by a diverse set of models with different capabilities and price points. You can also make customizations to our models for your specific use case with [fine-tuning](/docs/guides/fine-tuning).

| Model | Description |
| --- | --- |
| [GPT-4o](#gpt-4o) | Our high-intelligence flagship model for complex, multi-step tasks |
| [GPT-4o mini](#gpt-4o-mini) | Our affordable and intelligent small model for fast, lightweight tasks |
| [o1-preview and o1-mini](#o1) | Language models trained with reinforcement learning to perform complex reasoning. |
| [GPT-4 Turbo and GPT-4](#gpt-4-turbo-and-gpt-4) | The previous set of high-intelligence models |
| [GPT-3.5 Turbo](#gpt-3-5-turbo) | A fast, inexpensive model for simple tasks |
| [DALL·E](#dall-e) | A model that can generate and edit images given a natural language prompt |
| [TTS](#tts) | A set of models that can convert text into natural sounding spoken audio |
| [Whisper](#whisper) | A model that can convert audio into text |
| [Embeddings](#embeddings) | A set of models that can convert text into a numerical form |
| [Moderation](#moderation) | A fine-tuned model that can detect whether text may be sensitive or unsafe |
| [Deprecated](/docs/deprecations) | A full list of models that have been deprecated along with the suggested replacement |

For GPT-series models, the context window refers to the maximum number of tokens that can be used in a single request, inclusive of both input and output tokens.

We have also published open source models including [Point-E](https://github.com/openai/point-e), [Whisper](https://github.com/openai/whisper), [Jukebox](https://github.com/openai/jukebox), and [CLIP](https://github.com/openai/CLIP).

## Continuous model upgrades

`gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-4`, and `gpt-3.5-turbo` point to their respective latest model version. You can verify this by looking at the [response object](/docs/api-reference/chat/object) after sending a request. The response will include the specific model version used (e.g. `gpt-3.5-turbo-1106`). The `chatgpt-4o-latest` model version continuously points to the version of GPT-4o used in [ChatGPT](https://chatgpt.com), and is updated frequently, when there are significant changes. With the exception of `chatgpt-4o-latest`, we offer pinned model versions that developers can continue using for at least three months after an updated model has been introduced.

Learn more about model deprecation on our [deprecation page](/docs/deprecations).

## GPT-4o

GPT-4o (“o” for “omni”) is our most advanced GPT model. It is multimodal (accepting text or image inputs and outputting text), and it has the same high intelligence as GPT-4 Turbo but is much more efficient—it generates text 2x faster and is 50% cheaper. Additionally, GPT-4o has the best vision and performance across non-English languages of any of our models. GPT-4o is available in the OpenAI API to paying customers. Learn how to use GPT-4o in our [text generation guide](/docs/guides/text-generation).

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4o <br>Our high-intelligence flagship model for complex, multi-step tasks. GPT-4o is cheaper and faster than GPT-4 Turbo. Currently points to `gpt-4o-2024-08-06`. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-2024-11-20 <br>Latest `gpt-4o` snapshot from November 20th, 2024. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-2024-08-06 <br>First snapshot that supports [Structured Outputs](/docs/guides/structured-outputs). `gpt-4o` currently points to this version. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-2024-05-13 <br>Original `gpt-4o` snapshot from May 13, 2024. | 128,000 tokens | 4,096 tokens | Oct 2023 |
| chatgpt-4o-latest <br>The `chatgpt-4o-latest` model version continuously points to the version of GPT-4o used in ChatGPT, and is updated frequently, when there are significant changes. | 128,000 tokens | 16,384 tokens | Oct 2023 |

## GPT-4o mini

GPT-4o mini (“o” for “omni”) is our most advanced model in the small models category, and our cheapest model yet.
It is multimodal (accepting text or image inputs and outputting text), has higher intelligence than `gpt-3.5-turbo` but is just as fast.
It is meant to be used for smaller tasks, including vision tasks.

We recommend choosing `gpt-4o-mini` where you would have previously used `gpt-3.5-turbo` as this model is more capable and cheaper.

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4o-mini<br>Our affordable and intelligent small model for fast, lightweight tasks. GPT-4o mini is cheaper and more capable than GPT-3.5 Turbo. Currently points to `gpt-4o-mini-2024-07-18`. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-mini-2024-07-18<br>`gpt-4o-mini` currently points to this version. | 128,000 tokens | 16,384 tokens | Oct 2023 |

## GPT-4o Realtime + Audio     Beta

This is a preview release of the GPT-4o Realtime and Audio models. The `gpt-4o-realtime-*` models are capable of responding to audio and text inputs over a WebSocket interface. Learn more in the [Realtime API guide](/docs/guides/realtime). The `gpt-4o-audio-*` models below can be used in Chat Completions to [generate audio responses](/docs/guides/audio).

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4o-realtime-preview<br>Preview release for the [Realtime API](/docs/guides/realtime) | 128,000 tokens | 4,096 tokens | Oct 2023 |
| gpt-4o-realtime-preview-2024-10-01<br>Current snapshot for the Realtime API model. | 128,000 tokens | 4,096 tokens | Oct 2023 |
| gpt-4o-audio-preview<br>Preview release for [audio inputs in chat completions](/docs/guides/audio). | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-audio-preview-2024-10-01<br>Current snapshot for the Audio API model. | 128,000 tokens | 16,384 tokens | Oct 2023 |

## o1-preview and o1-mini     Beta

The **o1 series** of large language models are trained with reinforcement
learning to perform complex reasoning. o1 models think before they answer,
producing a long internal chain of thought before responding to the user.

Learn about the capabilities and limitations of o1 models in our
[reasoning guide](/docs/guides/reasoning).

There are two model types available today:

- **o1-preview**: reasoning model designed to solve hard problems across domains.
- **o1-mini**: faster and cheaper reasoning model particularly good at coding, math, and science.

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| o1-preview<br>Points to the most recent snapshot of the o1 model: `o1-preview-2024-09-12` | 128,000 tokens | 32,768 tokens | Oct 2023 |
| o1-preview-2024-09-12<br>Latest o1 model snapshot | 128,000 tokens | 32,768 tokens | Oct 2023 |
| o1-mini<br>Points to the most recent o1-mini snapshot: `o1-mini-2024-09-12` | 128,000 tokens | 65,536 tokens | Oct 2023 |
| o1-mini-2024-09-12<br>Latest o1-mini model snapshot | 128,000 tokens | 65,536 tokens | Oct 2023 |

## GPT-4 Turbo and GPT-4

GPT-4 is a large multimodal model (accepting text or image inputs and outputting text) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. GPT-4 is available in the OpenAI API to [paying customers](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4). Like `gpt-3.5-turbo`, GPT-4 is optimized for chat but works well for traditional completions tasks using the [Chat Completions API](/docs/api-reference/chat). Learn how to use GPT-4 in our [text generation guide](/docs/guides/text-generation).

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4-turbo<br>The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling. Currently points to `gpt-4-turbo-2024-04-09`. | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-turbo-2024-04-09<br>GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. `gpt-4-turbo` currently points to this version. | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-turbo-preview<br>GPT-4 Turbo preview model. Currently points to `gpt-4-0125-preview`. | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-0125-preview<br>GPT-4 Turbo preview model intended to reduce cases of “laziness” where the model doesn’t complete a task. [Learn more](https://openai.com/blog/new-embedding-models-and-api-updates). | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-1106-preview<br>GPT-4 Turbo preview model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. This is a preview model. [Learn more](https://openai.com/blog/new-models-and-developer-products-announced-at-devday). | 128,000 tokens | 4,096 tokens | Apr 2023 |
| gpt-4<br>Currently points to `gpt-4-0613`. See [continuous model upgrades](#continuous-model-upgrades). | 8,192 tokens | 8,192 tokens | Sep 2021 |
| gpt-4-0613<br>Snapshot of `gpt-4` from June 13th 2023 with improved function calling support. | 8,192 tokens | 8,192 tokens | Sep 2021 |
| gpt-4-0314 <br>Legacy<br>Snapshot of `gpt-4` from March 14th 2023. | 8,192 tokens | 8,192 tokens | Sep 2021 |

For many basic tasks, the difference between GPT-4 and GPT-3.5 models is not significant. However, in more complex reasoning situations, GPT-4 is much more capable than any of our previous models.

#### Multilingual capabilities

GPT-4 [outperforms both previous large language models](https://cdn.openai.com/papers/gpt-4.pdf) and as of 2023, most state-of-the-art systems (which often have benchmark-specific training or hand-engineering). On the MMLU benchmark, an English-language suite of multiple-choice questions covering 57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but also demonstrates strong performance in other languages.

## GPT-3.5 Turbo

GPT-3.5 Turbo models can understand and generate natural language or code and have been optimized for chat using the [Chat Completions API](/docs/api-reference/chat) but work well for non-chat tasks as well.

As of July 2024, `gpt-4o-mini` should be used in place of `gpt-3.5-turbo`, as it is cheaper, more capable, multimodal, and just as fast. `gpt-3.5-turbo` is still available for use in the API.

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-3.5-turbo-0125<br>The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls. [Learn more](https://openai.com/blog/new-embedding-models-and-api-updates#:~:text=Other%20new%20models%20and%20lower%20pricing). | 16,385 tokens | 4,096 tokens | Sep 2021 |
| gpt-3.5-turbo<br>Currently points to `gpt-3.5-turbo-0125`. | 16,385 tokens | 4,096 tokens | Sep 2021 |
| gpt-3.5-turbo-1106<br>GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. [Learn more](https://openai.com/blog/new-models-and-developer-products-announced-at-devday). | 16,385 tokens | 4,096 tokens | Sep 2021 |
| gpt-3.5-turbo-instruct<br>Similar capabilities as GPT-3 era models. Compatible with legacy Completions endpoint and not Chat Completions. | 4,096 tokens | 4,096 tokens | Sep 2021 |

## DALL·E

DALL·E is a AI system that can create realistic images and art from a description in natural language. DALL·E 3 currently supports the ability, given a prompt, to create a new image with a specific size. DALL·E 2 also support the ability to edit an existing image, or create variations of a user provided image.

[DALL·E 3](https://openai.com/dall-e-3) is available through our [Images API](/docs/guides/images) along with [DALL·E 2](https://openai.com/blog/dall-e-api-now-available-in-public-beta). You can try DALL·E 3 through [ChatGPT Plus](https://chatgpt.com).

| Model | Description |
| --- | --- |
| `dall-e-3` | The latest DALL·E model released in Nov 2023. [Learn more](https://openai.com/blog/new-models-and-developer-products-announced-at-devday). |
| `dall-e-2` | The previous DALL·E model released in Nov 2022. The 2nd iteration of DALL·E with more realistic, accurate, and 4x greater resolution images than the original model. |

## TTS

TTS is an AI model that converts text to natural sounding spoken text. We offer two different model variates, `tts-1` is optimized for real time text to speech use cases and `tts-1-hd` is optimized for quality. These models can be used with the [Speech endpoint in the Audio API](/docs/guides/text-to-speech).

| Model | Description |
| --- | --- |
| `tts-1` | The latest text to speech model, optimized for speed. |
| `tts-1-hd` | The latest text to speech model, optimized for quality. |

## Whisper

Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. The Whisper v2-large model is currently available through our API with the `whisper-1` model name.

Currently, there is no difference between the [open source version of Whisper](https://github.com/openai/whisper) and the version available through our API. However, [through our API](/docs/guides/speech-to-text), we offer an optimized inference process which makes running Whisper through our API much faster than doing it through other means. For more technical details on Whisper, you can [read the paper](https://arxiv.org/abs/2212.04356).

## Embeddings

Embeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text. Embeddings are useful for search, clustering, recommendations, anomaly detection, and classification tasks. You can read more about our latest embedding models in the [announcement blog post](https://openai.com/blog/new-embedding-models-and-api-updates).

| Model | Output Dimension |
| --- | --- |
| `text-embedding-3-large` <br>Most capable embedding model for both english and non-english tasks | 3,072 |
| `text-embedding-3-small` <br>Increased performance over 2nd generation ada embedding model | 1,536 |
| `text-embedding-ada-002` <br>Most capable 2nd generation embedding model, replacing 16 first generation models | 1,536 |

* * *

## Moderation

The Moderation models are designed to check whether content complies with OpenAI's [usage policies](https://openai.com/policies/usage-policies). The models provide classification capabilities that look for content in categories like hate, self-harm, sexual content, violence, and others. Learn more about moderating text and images in our [moderation guide](/docs/guides/moderation).

| Model | Max tokens |
| --- | --- |
| `omni-moderation-latest` <br>Currently points to `omni-moderation-2024-09-26`. | 32,768 |
| `omni-moderation-2024-09-26` <br>Latest pinned version of our new multi-modal moderation model, capable of analyzing both text and images. | 32,768 |
| `text-moderation-latest` <br>Currently points to `text-moderation-007`. | 32,768 |
| `text-moderation-stable` <br>Currently points to `text-moderation-007`. | 32,768 |
| `text-moderation-007` <br>Previous generation text-only moderation. We expect `omni-moderation-*` models to be the best default moving forward. | 32,768 |

## GPT base

GPT base models can understand and generate natural language or code but are not trained with instruction following. These models are made to be replacements for our original GPT-3 base models and use the legacy Completions API. Most customers should use GPT-3.5 or GPT-4.

| Model | Max tokens | Knowledge cutoff |
| --- | --- | --- |
| `babbage-002` <br>Replacement for the GPT-3 `ada` and `babbage` base models. | 16,384 tokens | Sep 2021 |
| `davinci-002` <br>Replacement for the GPT-3 `curie` and `davinci` base models. | 16,384 tokens | Sep 2021 |

## How we use your data

Your data is your data.

As of March 1, 2023, data sent to the OpenAI API will not be used to train or improve OpenAI models (unless you explicitly opt-in to share data with us, such as by [providing feedback in the Playground](https://help.openai.com/en/articles/9883556-providing-feedback-in-the-api-playground)). One advantage to opting in is that the models may get better at your use case over time.

To help identify abuse, API data may be retained for up to 30 days, after which it will be deleted (unless otherwise required by law). For trusted customers with sensitive applications, zero data retention may be available. With zero data retention, request and response bodies are not persisted to any logging mechanism and exist only in memory in order to serve the request.

Note that this data policy does not apply to OpenAI's non-API consumer services like [ChatGPT](https://chatgpt.com/) or [DALL·E Labs](https://labs.openai.com/).

### Default usage policies by endpoint

| Endpoint | Data used for training | Default retention | Eligible for zero retention |
| --- | --- | --- | --- |
| `/v1/chat/completions`\* | No | 30 days | Yes, except (a) image inputs, (b) schemas provided for Structured Outputs, or (c) audio outputs. \* |
| `/v1/assistants` | No | 30 days \*\* | No |
| `/v1/threads` | No | 30 days \*\* | No |
| `/v1/threads/messages` | No | 30 days \*\* | No |
| `/v1/threads/runs` | No | 30 days \*\* | No |
| `/v1/vector_stores` | No | 30 days \*\* | No |
| `/v1/threads/runs/steps` | No | 30 days \*\* | No |
| `/v1/images/generations` | No | 30 days | No |
| `/v1/images/edits` | No | 30 days | No |
| `/v1/images/variations` | No | 30 days | No |
| `/v1/embeddings` | No | 30 days | Yes |
| `/v1/audio/transcriptions` | No | Zero data retention | - |
| `/v1/audio/translations` | No | Zero data retention | - |
| `/v1/audio/speech` | No | 30 days | Yes |
| `/v1/files` | No | Until deleted by customer | No |
| `/v1/fine_tuning/jobs` | No | Until deleted by customer | No |
| `/v1/batches` | No | Until deleted by customer | No |
| `/v1/moderations` | No | Zero data retention | - |
| `/v1/completions` | No | 30 days | Yes |
| `/v1/realtime` (beta) | No | 30 days | Yes |

**\\* Chat Completions:**

- Image inputs via the `gpt-4o`, `gpt-4o-mini`, `chatgpt-4o-latest`, or `gpt-4-turbo` models (or previously `gpt-4-vision-preview`) are not eligible for zero retention.
- Audio outputs are stored for 1 hour to enable [multi-turn conversations](/docs/guides/audio), and are not currently eligible for zero retention.
- When Structured Outputs is enabled, schemas provided (either as the `response_format` or in the function definition) are not eligible for zero retention, though the completions themselves are.
- When using Stored Completions via the `store: true` option in the API, those completions are stored for 30 days. Completions are stored in an unfiltered form after an API response, so please avoid storing completions that contain sensitive data.

**\\*\\* Assistants API:**

- Objects related to the Assistants API are deleted from our servers 30 days after you delete them via the API or the dashboard. Objects that are not deleted via the API or dashboard are retained indefinitely.

**Evaluations:**

- [Evaluation](/evaluations) data: When you create an evaluation, the data related to that evaluation is deleted from our servers 30 days after you delete it via the dashboard. Evaluation data that is not deleted via the dashboard is retained indefinitely.

For details, see our [API data usage policies](https://openai.com/policies/api-data-usage-policies). To learn more about zero retention, get in touch with our [sales team](https://openai.com/contact-sales).

## Model endpoint compatibility

| Endpoint | Latest models |
| --- | --- |
| /v1/assistants | All GPT-4o (except `chatgpt-4o-latest`), GPT-4o-mini, GPT-4, and GPT-3.5 Turbo models. The `retrieval` tool requires `gpt-4-turbo-preview` (and subsequent dated model releases) or `gpt-3.5-turbo-1106` (and subsequent versions). |
| /v1/audio/transcriptions | `whisper-1` |
| /v1/audio/translations | `whisper-1` |
| /v1/audio/speech | `tts-1`,  `tts-1-hd` |
| /v1/chat/completions | All GPT-4o (except for Realtime preview), GPT-4o-mini, GPT-4, and GPT-3.5 Turbo models and their dated releases. `chatgpt-4o-latest` dynamic model. [Fine-tuned](/docs/guides/fine-tuning) versions of `gpt-4o`,  `gpt-4o-mini`,  `gpt-4`,  and `gpt-3.5-turbo`. |
| /v1/completions (Legacy) | `gpt-3.5-turbo-instruct`,  `babbage-002`,  `davinci-002` |
| /v1/embeddings | `text-embedding-3-small`,  `text-embedding-3-large`,  `text-embedding-ada-002` |
| /v1/fine\_tuning/jobs | `gpt-4o`,  `gpt-4o-mini`,  `gpt-4`,  `gpt-3.5-turbo` |
| /v1/moderations | `text-moderation-stable`,  `text-moderation-latest` |
| /v1/images/generations | `dall-e-2`,  `dall-e-3` |
| /v1/realtime (beta) | `gpt-4o-realtime-preview`, `gpt-4o-realtime-preview-2024-10-01` |

This list excludes all of our [deprecated models](/docs/deprecations).Log in [Sign up](/signup)

# Prompt examples

Explore what's possible with some example prompts

All categories

Grammar correction

Convert ungrammatical statements into standard English.

Summarize for a 2nd grader

Simplify text to a level appropriate for a second-grade student.

Parse unstructured data

Create tables from unstructured text.

Emoji Translation

Translate regular text into emoji text.

Calculate time complexity

Find the time complexity of a function.

Explain code

Explain a complicated piece of code.

Keywords

Extract keywords from a block of text.

Product name generator

Generate product names from a description and seed words.

Python bug fixer

Find and fix bugs in source code.

Spreadsheet creator

Create spreadsheets of various kinds of data.

Tweet classifier

Detect sentiment in a tweet.

Airport code extractor

Extract airport codes from text.

Mood to color

Turn a text description into a color.

VR fitness idea generator

Generate ideas for fitness promoting virtual reality games.

Marv the sarcastic chat bot

Marv is a factual chatbot that is also sarcastic.

Turn by turn directions

Convert natural language to turn-by-turn directions.

Interview questions

Create interview questions.

Function from specification

Create a Python function from a specification.

Improve code efficiency

Provide ideas for efficiency improvements to Python code.

Single page website creator

Create a single page website.

Rap battle writer

Generate a rap battle between two characters.

Memo writer

Generate a company memo based on provided points.

Emoji chatbot

Generate conversational replies using emojis only.

Translation

Translate natural language text.

Socratic tutor

Generate responses as a Socratic tutor.

Natural language to SQL

Convert natural language into SQL queries.

Meeting notes summarizer

Summarize meeting notes including overall discussion, action items, and future topics.

Review classifier

Classify user reviews based on a set of tags.

Pro and con discusser

Analyze the pros and cons of a given topic.

Lesson plan writer

Generate a lesson plan for a specific topic.

Keywords

Extract

Natural Language

Extract keywords from a block of text.

Prompt

SYSTEM

You will be provided with a block of text, and your task is to extract a list of keywords from it.

USER

Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.

Sample response

Black-on-black ware, pottery tradition, Puebloan Native American, ceramic artists, Northern New Mexico, reduction-fired blackware, pueblo artists, smooth surface, designs, selective burnishing, refractory slip, carving, incising designs, polishing, generations, families, Kha'po Owingeh, P'ohwhóge Owingeh pueblos, matriarch potters, contemporary artists, ancestors

API request

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[\
    {\
      "role": "system",\
      "content": "You will be provided with a block of text, and your task is to extract a list of keywords from it."\
    },\
    {\
      "role": "user",\
      "content": "Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. Traditional reduction-fired blackware has been made for centuries by pueblo artists. Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. Another style involves carving or incising designs and selectively polishing the raised areas. For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors."\
    }\
  ],
  temperature=0.5,
  max_tokens=256,
  top_p=1
)
```Log in [Sign up](/signup)

# Rate limits

Copy page

Understand API rate limits and restrictions.

Rate limits are restrictions that our API imposes on the number of times a user or client can
access our services within a specified period of time.

## Why do we have rate limits?

Rate limits are a common practice for APIs, and they're put in place for a few different reasons:

- **They help protect against abuse or misuse of the API.** For example, a malicious actor could flood the API with requests in an attempt to overload it or cause disruptions in service. By setting rate limits, OpenAI can prevent this kind of activity.
- **Rate limits help ensure that everyone has fair access to the API.** If one person or organization makes an excessive number of requests, it could bog down the API for everyone else. By throttling the number of requests that a single user can make, OpenAI ensures that the most number of people have an opportunity to use the API without experiencing slowdowns.
- **Rate limits can help OpenAI manage the aggregate load on its infrastructure.** If requests to the API increase dramatically, it could tax the servers and cause performance issues. By setting rate limits, OpenAI can help maintain a smooth and consistent experience for all users.

Please work through this document in its entirety to better understand how OpenAI’s rate limit system works. We include code examples and possible solutions to handle common issues. We also include details around how your rate limits are automatically increased in the usage tiers section below.

## How do these rate limits work?

Rate limits are measured in five ways: **RPM** (requests per minute), **RPD** (requests per day), **TPM** (tokens per minute), **TPD** (tokens per day), and **IPM** (images per minute). Rate limits can be hit across any of the options depending on what occurs first. For example, you might send 20 requests with only 100 tokens to the ChatCompletions endpoint and that would fill your limit (if your RPM was 20), even if you did not send 150k tokens (if your TPM limit was 150k) within those 20 requests.

[Batch API](/docs/api-reference/batch/create) queue limits are calculated based on the total number of input tokens queued for a given model. Tokens from pending batch jobs are counted against your queue limit. Once a batch job is completed, its tokens are no longer counted against that model's limit.

Other important things worth noting:

- Rate limits are defined at the [organization level](/docs/guides/production-best-practices) and at the project level, not user level.
- Rate limits vary by the [model](/docs/models) being used.
- Limits are also placed on the total amount an organization can spend on the API each month. These are also known as "usage limits".
- Some model families have shared rate limits. Any models listed under a "shared limit" in your [organizations limit page](https://platform.openai.com/settings/organization/limits) share a rate limit between them. For example, if the listed shared TPM is 3.5M, all calls to any model in the given "shared limit" list will count towards that 3.5M.

## Usage tiers

You can view the rate and usage limits for your organization under the [limits](/settings/organization/limits) section of your account settings. As your usage of the OpenAI API and your spend on our API goes up, we automatically graduate you to the next usage tier. This usually results in an increase in rate limits across most models.

| Tier | Qualification | Usage limits |
| --- | --- | --- |
| Free | User must be in an [allowed geography](/docs/supported-countries) | $100 / month |
| Tier 1 | $5 paid | $100 / month |
| Tier 2 | $50 paid and 7+ days since first successful payment | $500 / month |
| Tier 3 | $100 paid and 7+ days since first successful payment | $1,000 / month |
| Tier 4 | $250 paid and 14+ days since first successful payment | $5,000 / month |
| Tier 5 | $1,000 paid and 30+ days since first successful payment | $200,000 / month |

Select a tier below to view a high-level summary of rate limits per model.

FreeTier 1Tier 2Tier 3Tier 4Tier 5

#### Free tier rate limits

This is a high level summary and there are per-model exceptions to these limits (e.g. some legacy models or models with larger context windows have different rate limits). To view the exact rate limits per model for your account, visit the [limits](/settings/organization/limits) section of your account settings.

| Model | RPM | RPD | TPM | Batch Queue Limit |
| --- | --- | --- | --- | --- |
| `gpt-3.5-turbo` | 3 | 200 | 40,000 | 200,000 |
| `text-embedding-3-large` | 3,000 | 200 | 1,000,000 | 3,000,000 |
| `text-embedding-3-small` | 3,000 | 200 | 1,000,000 | 3,000,000 |
| `text-embedding-ada-002` | 3,000 | 200 | 1,000,000 | 3,000,000 |
| `omni-moderation-*` | 500 | 10,000 | 10,000 | - |
| `whisper-1` | 3 | 200 | - | - |
| `tts-1` | 3 | 200 | - | - |
| `dall-e-2` | 5 img/min | - | - | - |
| `dall-e-3` | 1 img/min | - | - | - |

### Rate limits in headers

In addition to seeing your rate limit on your [account page](/settings/organization/limits), you can also view important information about your rate limits such as the remaining requests, tokens, and other metadata in the headers of the HTTP response.

You can expect to see the following header fields:

| Field | Sample Value | Description |
| --- | --- | --- |
| x-ratelimit-limit-requests | 60 | The maximum number of requests that are permitted before exhausting the rate limit. |
| x-ratelimit-limit-tokens | 150000 | The maximum number of tokens that are permitted before exhausting the rate limit. |
| x-ratelimit-remaining-requests | 59 | The remaining number of requests that are permitted before exhausting the rate limit. |
| x-ratelimit-remaining-tokens | 149984 | The remaining number of tokens that are permitted before exhausting the rate limit. |
| x-ratelimit-reset-requests | 1s | The time until the rate limit (based on requests) resets to its initial state. |
| x-ratelimit-reset-tokens | 6m0s | The time until the rate limit (based on tokens) resets to its initial state. |

## Error Mitigation

### What are some steps I can take to mitigate this?

The OpenAI Cookbook has a [Python notebook](https://cookbook.openai.com/examples/how_to_handle_rate_limits) that explains how to avoid rate limit errors, as well an example [Python script](https://github.com/openai/openai-cookbook/blob/main/examples/api_request_parallel_processor.py) for staying under rate limits while batch processing API requests.

You should also exercise caution when providing programmatic access, bulk processing features, and automated social media posting - consider only enabling these for trusted customers.

To protect against automated and high-volume misuse, set a usage limit for individual users within a specified time frame (daily, weekly, or monthly). Consider implementing a hard cap or a manual review process for users who exceed the limit.

#### Retrying with exponential backoff

One easy way to avoid rate limit errors is to automatically retry requests with a random exponential backoff. Retrying with exponential backoff means performing a short sleep when a rate limit error is hit, then retrying the unsuccessful request. If the request is still unsuccessful, the sleep length is increased and the process is repeated. This continues until the request is successful or until a maximum number of retries is reached.
This approach has many benefits:

- Automatic retries means you can recover from rate limit errors without crashes or missing data
- Exponential backoff means that your first retries can be tried quickly, while still benefiting from longer delays if your first few retries fail
- Adding random jitter to the delay helps retries from all hitting at the same time.

Note that unsuccessful requests contribute to your per-minute limit, so continuously resending a request won’t work.

Below are a few example solutions **for Python** that use exponential backoff.

Example 1: Using the Tenacity library

Tenacity is an Apache 2.0 licensed general-purpose retrying library, written in Python, to simplify the task of adding retry behavior to just about anything.
To add exponential backoff to your requests, you can use the `tenacity.retry` decorator. The below example uses the `tenacity.wait_random_exponential` function to add random exponential backoff to a request.

Using the Tenacity library

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
from openai import OpenAI
client = OpenAI()

from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential,
)  # for exponential backoff

@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def completion_with_backoff(**kwargs):
    return client.completions.create(**kwargs)

completion_with_backoff(model="gpt-4o-mini", prompt="Once upon a time,")
```

Note that the Tenacity library is a third-party tool, and OpenAI makes no guarantees about
its reliability or security.

Example 2: Using the backoff library

Another python library that provides function decorators for backoff and retry is [backoff](https://pypi.org/project/backoff/):

Using the Tenacity library

python

```python
1
2
3
4
5
6
7
8
9
10
import backoff
import openai
from openai import OpenAI
client = OpenAI()

@backoff.on_exception(backoff.expo, openai.RateLimitError)
def completions_with_backoff(**kwargs):
    return client.completions.create(**kwargs)

completions_with_backoff(model="gpt-4o-mini", prompt="Once upon a time,")
```

Like Tenacity, the backoff library is a third-party tool, and OpenAI makes no guarantees about its reliability or security.

Example 3: Manual backoff implementation

If you don't want to use third-party libraries, you can implement your own backoff logic following this example:

Using manual backoff implementation

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
# imports
import random
import time

import openai
from openai import OpenAI
client = OpenAI()

# define a retry decorator
def retry_with_exponential_backoff(
    func,
    initial_delay: float = 1,
    exponential_base: float = 2,
    jitter: bool = True,
    max_retries: int = 10,
    errors: tuple = (openai.RateLimitError,),
):
    """Retry a function with exponential backoff."""

    def wrapper(*args, **kwargs):
        # Initialize variables
        num_retries = 0
        delay = initial_delay

        # Loop until a successful response or max_retries is hit or an exception is raised
        while True:
            try:
                return func(*args, **kwargs)

            # Retry on specific errors
            except errors as e:
                # Increment retries
                num_retries += 1

                # Check if max retries has been reached
                if num_retries > max_retries:
                    raise Exception(
                        f"Maximum number of retries ({max_retries}) exceeded."
                    )

                # Increment the delay
                delay *= exponential_base * (1 + jitter * random.random())

                # Sleep for the delay
                time.sleep(delay)

            # Raise exceptions for any errors not specified
            except Exception as e:
                raise e

    return wrapper

@retry_with_exponential_backoff
def completions_with_backoff(**kwargs):
    return client.completions.create(**kwargs)
```

Again, OpenAI makes no guarantees on the security or efficiency of this solution but it can be a good starting place for your own solution.

#### Reduce the `max_tokens` to match the size of your completions

Your rate limit is calculated as the maximum of `max_tokens` and the estimated number of tokens based on the character count of your request. Try to set the `max_tokens` value as close to your expected response size as possible.

#### Batching requests

If your use case does not require immediate responses, you can use the [Batch API](/docs/guides/batch) to more easily submit and execute large collections of requests without impacting your synchronous request rate limits.

For use cases that _do_ requires synchronous respones, the OpenAI API has separate limits for **requests per minute** and **tokens per minute**.

If you're hitting the limit on requests per minute but have available capacity on tokens per minute, you can increase your throughput by batching multiple tasks into each request. This will allow you to process more tokens per minute, especially with our smaller models.

Sending in a batch of prompts works exactly the same as a normal API call, except you pass in a list of strings to the prompt parameter instead of a single string.

Example without batching

No batching

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

num_stories = 10
prompt = "Once upon a time,"

# serial example, with one story completion per request
for _ in range(num_stories):
    response = client.completions.create(
        model="curie",
        prompt=prompt,
        max_tokens=20,
    )
    # print story
    print(prompt + response.choices[0].text)
```

Example with batching

Batching

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
from openai import OpenAI
client = OpenAI()

num_stories = 10
prompts = ["Once upon a time,"] * num_stories

# batched example, with 10 story completions per request
response = client.completions.create(
    model="curie",
    prompt=prompts,
    max_tokens=20,
)

# match completions to prompts by index
stories = [""] * len(prompts)
for choice in response.choices:
    stories[choice.index] = prompts[choice.index] + choice.text

# print stories
for story in stories:
    print(story)
```

Warning: the response object may not return completions in the order of the prompts, so always remember to match responses back to prompts using the index field.Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

# GPT Release Notes

Copy page

Explore updates and new features in GPTs.

Keep track of updates to OpenAI GPTs. You can also view all of the broader [ChatGPT releases](https://help.openai.com/en/articles/6825453-chatgpt-release-notes) which is used to share new features and capabilities. This page is maintained in a best effort fashion and may not reflect all changes
being made.

### May 13th, 2024

- Actions can [return](docs/actions/getting-started/returning-files) up to 10 files per request to be integrated into the conversation

### April 8th, 2024

- Files created by Code Interpreter can now be [included](/docs/actions/getting-started/sending-files) in POST requests

### Mar 18th, 2024

- GPT Builders can view and restore previous versions of their GPTs

### Mar 15th, 2024

- POST requests can [include up to ten files](/docs/actions/getting-started/including-files) (including DALL-E generated images) from the conversation

### Feb 22nd, 2024

- Users can now rate GPTs, which provides feedback for builders and signal for otherusers in the Store

- Users can now leave private feedback for Builders if/when they opt in

- Every GPT now has an About page with information about the GPT including Rating, Category, Conversation Count, Starter Prompts, and more

- Builders can now link their social profiles from Twitter, LinkedIn, and GitHub to their GPT


### Jan 10th, 2024

- The [GPT Store](https://openai.com/blog/introducing-gpts) launched publicly, with categories and various leaderboards

### Nov 6th, 2023

- [GPTs](https://openai.com/blog/introducing-gpts) allow users to customize ChatGPT for various use cases and share these with other usersLog in [Sign up](/signup)

# Advanced usage

Copy page

Use advanced techniques for reproducibility and parameter tuning.

OpenAI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The text inputs to these models are also referred to as "prompts". Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.

## Reproducible outputs

Chat Completions are non-deterministic by default (which means model outputs may differ from request to request). That being said, we offer some control towards deterministic outputs by giving you access to the [seed](/docs/api-reference/chat/create#chat-create-seed) parameter and the [system\_fingerprint](/docs/api-reference/completions/object#completions/object-system_fingerprint) response field.

To receive (mostly) deterministic outputs across API calls, you can:

- Set the [seed](/docs/api-reference/chat/create#chat-create-seed) parameter to any integer of your choice and use the same value across requests you'd like deterministic outputs for.
- Ensure all other parameters (like `prompt` or `temperature`) are the exact same across requests.

Sometimes, determinism may be impacted due to necessary changes OpenAI makes to model configurations on our end. To help you keep track of these changes, we expose the [system\_fingerprint](/docs/api-reference/chat/object#chat/object-system_fingerprint) field. If this value is different, you may see different outputs due to changes we've made on our systems.

[Deterministic outputs\\
\\
Explore the new seed parameter in the OpenAI cookbook](https://cookbook.openai.com/examples/reproducible_outputs_with_the_seed_parameter)

## Managing tokens

Language models read and write text in chunks called tokens. In English, a token can be as short as one character or as long as one word (e.g., `a` or ` apple`), and in some languages tokens can be even shorter than one character or even longer than one word.

As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text.

Check out our [Tokenizer tool](https://platform.openai.com/tokenizer) to test specific strings and see how they are translated into tokens.

For example, the string `"ChatGPT is great!"` is encoded into six tokens: `["Chat", "G", "PT", " is", " great", "!"]`.

The total number of tokens in an API call affects:

- How much your API call costs, as you pay per token
- How long your API call takes, as writing more tokens takes more time
- Whether your API call works at all, as total tokens must be below the model's maximum limit (4097 tokens for `gpt-3.5-turbo`)

Both input and output tokens count toward these quantities. For example, if your API call used 10 tokens in the message input and you received 20 tokens in the message output, you would be billed for 30 tokens. Note however that for some models the price per token is different for tokens in the input vs. the output (see the [pricing](https://openai.com/api/pricing) page for more information).

To see how many tokens are used by an API call, check the `usage` field in the API response (e.g., `response['usage']['total_tokens']`).

Chat models like `gpt-3.5-turbo` and `gpt-4-turbo-preview` use tokens in the same way as the models available in the completions API, but because of their message-based formatting, it's more difficult to count how many tokens will be used by a conversation.

Deep dive

Counting tokens for chat API calls

To see how many tokens are in a text string without making an API call, use OpenAI’s [tiktoken](https://github.com/openai/tiktoken) Python library. Example code can be found in the OpenAI Cookbook’s guide on [how to count tokens with tiktoken](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken).

Each message passed to the API consumes the number of tokens in the content, role, and other fields, plus a few extra for behind-the-scenes formatting. This may change slightly in the future.

If a conversation has too many tokens to fit within a model’s maximum limit (e.g., more than 4097 tokens for `gpt-3.5-turbo` or more than 128k tokens for `gpt-4o`), you will have to truncate, omit, or otherwise shrink your text until it fits. Beware that if a message is removed from the messages input, the model will lose all knowledge of it.

Note that very long conversations are more likely to receive incomplete replies. For example, a `gpt-3.5-turbo` conversation that is 4090 tokens long will have its reply cut off after just 6 tokens.

## Parameter details

### Frequency and presence penalties

The frequency and presence penalties found in the [Chat Completions API](/docs/api-reference/chat/create) and [Legacy Completions API](/docs/api-reference/completions) can be used to reduce the likelihood of sampling repetitive sequences of tokens.

Deep dive

Penalties behind the scenes

Reasonable values for the penalty coefficients are around 0.1 to 1 if the aim is to just reduce repetitive samples somewhat. If the aim is to strongly suppress repetition, then one can increase the coefficients up to 2, but this can noticeably degrade the quality of samples. Negative values can be used to increase the likelihood of repetition.

### Token log probabilities

The [logprobs](/docs/api-reference/chat/create#chat-create-logprobs) parameter found in the [Chat Completions API](/docs/api-reference/chat/create) and [Legacy Completions API](/docs/api-reference/completions), when requested, provides the log probabilities of each output token, and a limited number of the most likely tokens at each token position alongside their log probabilities. This can be useful in some cases to assess the confidence of the model in its output, or to examine alternative responses the model might have given.

### Other parameters

See the full [API reference documentation](https://platform.openai.com/docs/api-reference/chat) to learn more.Log in [Sign up](/signup)

# GPT Actions

Copy page

Customize ChatGPT with GPT Actions and API integrations.

GPT Actions are stored in [Custom GPTs](https://openai.com/blog/introducing-gpts), which enable users to customize ChatGPT for specific use cases by providing instructions, attaching documents as knowledge, and connecting to 3rd party services.

GPT Actions empower ChatGPT users to interact with external applications via RESTful APIs calls outside of ChatGPT simply by using natural language. They convert natural language text into the json schema required for an API call. GPT Actions are usually either used to do [data retrieval](https://platform.openai.com/docs/actions/data-retrieval) to ChatGPT (e.g. query a Data Warehouse) or take action in another application (e.g. file a JIRA ticket).

## How GPT Actions work

At their core, GPT Actions leverage [Function Calling](https://platform.openai.com/docs/guides/function-calling) to execute API calls.

Similar to ChatGPT's Data Analysis capability (which generates Python code and then executes it), they leverage Function Calling to (1) decide which API call is relevant to the user's question and (2) generate the json input necessary for the API call. Then finally, the GPT Action executes the API call using that json input.

Developers can even specify the authentication mechanism of an action, and the Custom GPT will execute the API call using the third party app’s authentication. GPT Actions obfuscates the complexity of the API call to the end user: they simply ask a question in natural language, and ChatGPT provides the output in natural language as well.

## The Power of GPT Actions

APIs allow for **interoperability** to enable your organization to access other applications. However, enabling users to access the right information from 3rd-party APIs can require significant overhead from developers.

GPT Actions provide a viable alternative: developers can now simply describe the schema of an API call, configure authentication, and add in some instructions to the GPT, and ChatGPT provides the bridge between the user's natural language questions and the API layer.

## Simplified example

The [getting started guide](https://platform.openai.com/docs/actions/getting-started) walks through an example using two API calls from [weather.gov](weather.gov) to generate a forecast:

- /points/{latitude},{longitude} inputs lat-long coordinates and outputs forecast office (wfo) and x-y coordinates
- /gridpoints/{office}/{gridX},{gridY}/forecast inputs wfo,x,y coordinates and outputs a forecast

Once a developer has encoded the json schema required to populate both of those API calls in a GPT Action, a user can simply ask "What I should pack on a trip to Washington DC this weekend?" The GPT Action will then figure out the lat-long of that location, execute both API calls in order, and respond with a packing list based on the weekend forecast it receives back.

In this example, GPT Actions will supply api.weather.gov with two API inputs:

/points API call:

```text
1
2
3
4
{
    "latitude": 38.9072,
    "longitude": -77.0369,
}
```

/forecast API call:

```text
1
2
3
4
5
{
    "wfo": "LWX",
    "x": 97,
    "y": 71,
}
```

## Get started on building

Check out the [getting started guide](https://platform.openai.com/docs/actions/getting-started) for a deeper dive on this weather example and our [actions library](https://platform.openai.com/docs/actions/actions-library) for pre-built example GPT Actions of the most common 3rd party apps.

## Additional information

- Familiarize yourself with our [GPT policies](https://openai.com/policies/usage-policies#:~:text=or%20educational%20purposes.-,Building%20with%20ChatGPT,-Shared%20GPTs%20allow)
- Explore the [differences between GPTs and Assistants](https://help.openai.com/en/articles/8673914-gpts-vs-assistants)
- Check out the [GPT data privacy FAQ's](https://help.openai.com/en/articles/8554402-gpts-data-privacy-faqs)
- Find answers to [common GPT questions](https://help.openai.com/en/articles/8554407-gpts-faq)Log in [Sign up](/signup)

# Assistants API deep dive  Beta

Copy page

In-depth guide to creating and managing assistants.

As described in the [Assistants Overview](/docs/assistants/overview), there are several concepts involved in building an app with the Assistants API.

This guide goes deeper into each of these concepts.

If you want to get started coding right away, check out the [Assistants API Quickstart](/docs/assistants/quickstart).

## Creating Assistants

We recommend using OpenAI's
[latest models](/docs/models#gpt-4-turbo-and-gpt-4) with the Assistants API
for best results and maximum compatibility with tools.

To get started, creating an Assistant only requires specifying the `model` to use. But you can further customize the behavior of the Assistant:

1. Use the `instructions` parameter to guide the personality of the Assistant and define its goals. Instructions are similar to system messages in the Chat Completions API.
2. Use the `tools` parameter to give the Assistant access to up to 128 tools. You can give it access to OpenAI-hosted tools like `code_interpreter` and `file_search`, or call a third-party tools via a `function` calling.
3. Use the `tool_resources` parameter to give the tools like `code_interpreter` and `file_search` access to files. Files are uploaded using the `File` [upload endpoint](/docs/api-reference/files/create) and must have the `purpose` set to `assistants` to be used with this API.

For example, to create an Assistant that can create data visualization based on a `.csv` file, first upload a file.

python

```python
1
2
3
4
file = client.files.create(
  file=open("revenue-forecast.csv", "rb"),
  purpose='assistants'
)
```

Then, create the Assistant with the `code_interpreter` tool enabled and provide the file as a resource to the tool.

python

```python
1
2
3
4
5
6
7
8
9
10
11
assistant = client.beta.assistants.create(
  name="Data visualizer",
  description="You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.",
  model="gpt-4o",
  tools=[{"type": "code_interpreter"}],
  tool_resources={
    "code_interpreter": {
      "file_ids": [file.id]
    }
  }
)
```

You can attach a maximum of 20 files to `code_interpreter` and 10,000 files to `file_search` (using `vector_store` [objects](/docs/api-reference/vector-stores/object)).

Each file can be at most 512 MB in size and have a maximum of 5,000,000 tokens. By default, the size of all the files uploaded in your project cannot exceed 100 GB, but you can reach out to our support team to increase this limit.

## Managing Threads and Messages

Threads and Messages represent a conversation session between an Assistant and a user. There is a limit of 100,000 Messages per Thread. Once the size of the Messages exceeds the context window of the model, the Thread will attempt to smartly truncate messages, before fully dropping the ones it considers the least important.

You can create a Thread with an initial list of Messages like this:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
thread = client.beta.threads.create(
  messages=[\
    {\
      "role": "user",\
      "content": "Create 3 data visualizations based on the trends in this file.",\
      "attachments": [\
        {\
          "file_id": file.id,\
          "tools": [{"type": "code_interpreter"}]\
        }\
      ]\
    }\
  ]
)
```

Messages can contain text, images, or file attachment. Message `attachments` are helper methods that add files to a thread's `tool_resources`. You can also choose to add files to the `thread.tool_resources` directly.

### Creating image input content

Message content can contain either external image URLs or File IDs uploaded via the [File API](/docs/api-reference/files/create). Only [models](/docs/models) with Vision support can accept image input. Supported image content types include png, jpg, gif, and webp. When creating image files, pass `purpose="vision"` to allow you to later download and display the input content. Currently, there is a 100GB limit per project. Please contact us to request a limit increase.

Tools cannot access image content unless specified. To pass image files to Code Interpreter, add the file ID in the message `attachments` list to allow the tool to read and analyze the input. Image URLs cannot be downloaded in Code Interpreter today.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
file = client.files.create(
  file=open("myimage.png", "rb"),
  purpose="vision"
)
thread = client.beta.threads.create(
  messages=[\
    {\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": "What is the difference between these images?"\
        },\
        {\
          "type": "image_url",\
          "image_url": {"url": "https://example.com/image.png"}\
        },\
        {\
          "type": "image_file",\
          "image_file": {"file_id": file.id}\
        },\
      ],\
    }\
  ]
)
```

#### Low or high fidelity image understanding

By controlling the `detail` parameter, which has three options, `low`, `high`, or `auto`, you have control over how the model processes the image and generates its textual understanding.

- `low` will enable the "low res" mode. The model will receive a low-res 512px x 512px version of the image, and represent the image with a budget of 85 tokens. This allows the API to return faster responses and consume fewer input tokens for use cases that do not require high detail.
- `high` will enable "high res" mode, which first allows the model to see the low res image and then creates detailed crops of input images based on the input image size. Use the [pricing calculator](https://openai.com/api/pricing/) to see token counts for various image sizes.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
thread = client.beta.threads.create(
  messages=[\
    {\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": "What is this an image of?"\
        },\
        {\
          "type": "image_url",\
          "image_url": {\
            "url": "https://example.com/image.png",\
            "detail": "high"\
          }\
        },\
      ],\
    }\
  ]
)
```

### Context window management

The Assistants API automatically manages the truncation to ensure it stays within the model's maximum context length. You can customize this behavior by specifying the maximum tokens you'd like a run to utilize and/or the maximum number of recent messages you'd like to include in a run.

#### Max Completion and Max Prompt Tokens

To control the token usage in a single Run, set `max_prompt_tokens` and `max_completion_tokens` when creating the Run. These limits apply to the total number of tokens used in all completions throughout the Run's lifecycle.

For example, initiating a Run with `max_prompt_tokens` set to 500 and `max_completion_tokens` set to 1000 means the first completion will truncate the thread to 500 tokens and cap the output at 1000 tokens. If only 200 prompt tokens and 300 completion tokens are used in the first completion, the second completion will have available limits of 300 prompt tokens and 700 completion tokens.

If a completion reaches the `max_completion_tokens` limit, the Run will terminate with a status of `incomplete`, and details will be provided in the `incomplete_details` field of the Run object.

When using the File Search tool, we recommend setting the max\_prompt\_tokens to no less
than 20,000. For longer conversations or multiple interactions with File Search,
consider increasing this limit to 50,000, or ideally, removing the max\_prompt\_tokens
limits altogether to get the highest quality results.

#### Truncation Strategy

You may also specify a truncation strategy to control how your thread should be rendered into the model's context window.
Using a truncation strategy of type `auto` will use OpenAI's default truncation strategy. Using a truncation strategy of type `last_messages` will allow you to specify the number of the most recent messages to include in the context window.

### Message annotations

Messages created by Assistants may contain [`annotations`](/docs/api-reference/messages/object#messages/object-content) within the `content` array of the object. Annotations provide information around how you should annotate the text in the Message.

There are two types of Annotations:

1. `file_citation`: File citations are created by the [`file_search`](/docs/assistants/tools/file-search) tool and define references to a specific file that was uploaded and used by the Assistant to generate the response.
2. `file_path`: File path annotations are created by the [`code_interpreter`](/docs/assistants/tools/code-interpreter) tool and contain references to the files generated by the tool.

When annotations are present in the Message object, you'll see illegible model-generated substrings in the text that you should replace with the annotations. These strings may look something like `【13†source】` or `sandbox:/mnt/data/file.csv`. Here’s an example python code snippet that replaces these strings with information present in the annotations.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
# Retrieve the message object
message = client.beta.threads.messages.retrieve(
  thread_id="...",
  message_id="..."
)
# Extract the message content
message_content = message.content[0].text
annotations = message_content.annotations
citations = []
# Iterate over the annotations and add footnotes
for index, annotation in enumerate(annotations):
    # Replace the text with a footnote
    message_content.value = message_content.value.replace(annotation.text, f' [{index}]')
    # Gather citations based on annotation attributes
    if (file_citation := getattr(annotation, 'file_citation', None)):
        cited_file = client.files.retrieve(file_citation.file_id)
        citations.append(f'[{index}] {file_citation.quote} from {cited_file.filename}')
    elif (file_path := getattr(annotation, 'file_path', None)):
        cited_file = client.files.retrieve(file_path.file_id)
        citations.append(f'[{index}] Click <here> to download {cited_file.filename}')
        # Note: File download functionality not implemented above for brevity
# Add footnotes to the end of the message before displaying to user
message_content.value += '\n' + '\n'.join(citations)
```

## Runs and Run Steps

When you have all the context you need from your user in the Thread, you can run the Thread with an Assistant of your choice.

python

```python
1
2
3
4
run = client.beta.threads.runs.create(
  thread_id=thread.id,
  assistant_id=assistant.id
)
```

By default, a Run will use the `model` and `tools` configuration specified in Assistant object, but you can override most of these when creating the Run for added flexibility:

python

```python
1
2
3
4
5
6
7
run = client.beta.threads.runs.create(
  thread_id=thread.id,
  assistant_id=assistant.id,
  model="gpt-4o",
  instructions="New instructions that override the Assistant instructions",
  tools=[{"type": "code_interpreter"}, {"type": "file_search"}]
)
```

Note: `tool_resources` associated with the Assistant cannot be overridden during Run creation. You must use the [modify Assistant](/docs/api-reference/assistants/modifyAssistant) endpoint to do this.

#### Run lifecycle

Run objects can have multiple statuses.

![Run lifecycle - diagram showing possible status transitions](https://cdn.openai.com/API/docs/images/diagram-run-statuses-v2.png)

| Status | Definition |
| --- | --- |
| `queued` | When Runs are first created or when you complete the `required_action`, they are moved to a queued status. They should almost immediately move to `in_progress`. |
| `in_progress` | While in\_progress, the Assistant uses the model and tools to perform steps. You can view progress being made by the Run by examining the [Run Steps](/docs/api-reference/runs/step-object). |
| `completed` | The Run successfully completed! You can now view all Messages the Assistant added to the Thread, and all the steps the Run took. You can also continue the conversation by adding more user Messages to the Thread and creating another Run. |
| `requires_action` | When using the [Function calling](/docs/assistants/tools/function-calling) tool, the Run will move to a `required_action` state once the model determines the names and arguments of the functions to be called. You must then run those functions and [submit the outputs](/docs/api-reference/runs/submitToolOutputs) before the run proceeds. If the outputs are not provided before the `expires_at` timestamp passes (roughly 10 mins past creation), the run will move to an expired status. |
| `expired` | This happens when the function calling outputs were not submitted before `expires_at` and the run expires. Additionally, if the runs take too long to execute and go beyond the time stated in `expires_at`, our systems will expire the run. |
| `cancelling` | You can attempt to cancel an `in_progress` run using the [Cancel Run](/docs/api-reference/runs/cancelRun) endpoint. Once the attempt to cancel succeeds, status of the Run moves to `cancelled`. Cancellation is attempted but not guaranteed. |
| `cancelled` | Run was successfully cancelled. |
| `failed` | You can view the reason for the failure by looking at the `last_error` object in the Run. The timestamp for the failure will be recorded under `failed_at`. |
| `incomplete` | Run ended due to `max_prompt_tokens` or `max_completion_tokens` reached. You can view the specific reason by looking at the `incomplete_details` object in the Run. |

#### Polling for updates

If you are not using [streaming](/docs/assistants/overview#step-4-create-a-run?context=with-streaming), in order to keep the status of your run up to date, you will have to periodically [retrieve the Run](/docs/api-reference/runs/getRun) object. You can check the status of the run each time you retrieve the object to determine what your application should do next.

You can optionally use Polling Helpers in our [Node](https://github.com/openai/openai-node?tab=readme-ov-file#polling-helpers) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#polling-helpers) SDKs to help you with this. These helpers will automatically poll the Run object for you and return the Run object when it's in a terminal state.

#### Thread locks

When a Run is `in_progress` and not in a terminal state, the Thread is locked. This means that:

- New Messages cannot be added to the Thread.
- New Runs cannot be created on the Thread.

#### Run steps

![Run steps lifecycle - diagram showing possible status transitions](https://cdn.openai.com/API/docs/images/diagram-2.png)

Run step statuses have the same meaning as Run statuses.

Most of the interesting detail in the Run Step object lives in the `step_details` field. There can be two types of step details:

1. `message_creation`: This Run Step is created when the Assistant creates a Message on the Thread.
2. `tool_calls`: This Run Step is created when the Assistant calls a tool. Details around this are covered in the relevant sections of the [Tools](/docs/assistants/tools) guide.

## Data Access Guidance

Currently, Assistants, Threads, Messages, and Vector Stores created via the API are scoped to the Project they're created in. As such, any person with API key access to that Project is able to read or write Assistants, Threads, Messages, and Runs in the Project.

We strongly recommend the following data access controls:

- _Implement authorization._ Before performing reads or writes on Assistants, Threads, Messages, and Vector Stores, ensure that the end-user is authorized to do so. For example, store in your database the object IDs that the end-user has access to, and check it before fetching the object ID with the API.
- _Restrict API key access._ Carefully consider who in your organization should have API keys and be part of a Project. Periodically audit this list. API keys enable a wide range of operations including reading and modifying sensitive information, such as Messages and Files.
- _Create separate accounts._ Consider creating separate Projects for different applications in order to isolate data across multiple applications.Log in [Sign up](/signup)

# Models

Copy page

## Flagship models

[GPT-4o\\
\\
Our high-intelligence flagship model for complex, multi‑step tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Smarter model, higher price per token](/docs/models#gpt-4o)

[GPT-4o mini\\
\\
Our affordable and intelligent small model for fast, lightweight tasks\\
\\
Text and image input, text output\\
\\
128k context length\\
\\
Faster model, lower price per token](/docs/models#gpt-4o-mini)

[o1-preview & o1-mini\\
\\
Beta\\
\\
A new series of reasoning models for solving hard problems\\
\\
Text input, text output\\
\\
128k context length\\
\\
Higher latency, uses tokens to think](/docs/models#o1)

[Model pricing details](https://openai.com/api/pricing)

## Models overview

The OpenAI API is powered by a diverse set of models with different capabilities and price points. You can also make customizations to our models for your specific use case with [fine-tuning](/docs/guides/fine-tuning).

| Model | Description |
| --- | --- |
| [GPT-4o](#gpt-4o) | Our high-intelligence flagship model for complex, multi-step tasks |
| [GPT-4o mini](#gpt-4o-mini) | Our affordable and intelligent small model for fast, lightweight tasks |
| [o1-preview and o1-mini](#o1) | Language models trained with reinforcement learning to perform complex reasoning. |
| [GPT-4 Turbo and GPT-4](#gpt-4-turbo-and-gpt-4) | The previous set of high-intelligence models |
| [GPT-3.5 Turbo](#gpt-3-5-turbo) | A fast, inexpensive model for simple tasks |
| [DALL·E](#dall-e) | A model that can generate and edit images given a natural language prompt |
| [TTS](#tts) | A set of models that can convert text into natural sounding spoken audio |
| [Whisper](#whisper) | A model that can convert audio into text |
| [Embeddings](#embeddings) | A set of models that can convert text into a numerical form |
| [Moderation](#moderation) | A fine-tuned model that can detect whether text may be sensitive or unsafe |
| [Deprecated](/docs/deprecations) | A full list of models that have been deprecated along with the suggested replacement |

For GPT-series models, the context window refers to the maximum number of tokens that can be used in a single request, inclusive of both input and output tokens.

We have also published open source models including [Point-E](https://github.com/openai/point-e), [Whisper](https://github.com/openai/whisper), [Jukebox](https://github.com/openai/jukebox), and [CLIP](https://github.com/openai/CLIP).

## Continuous model upgrades

`gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`, `gpt-4`, and `gpt-3.5-turbo` point to their respective latest model version. You can verify this by looking at the [response object](/docs/api-reference/chat/object) after sending a request. The response will include the specific model version used (e.g. `gpt-3.5-turbo-1106`). The `chatgpt-4o-latest` model version continuously points to the version of GPT-4o used in [ChatGPT](https://chatgpt.com), and is updated frequently, when there are significant changes. With the exception of `chatgpt-4o-latest`, we offer pinned model versions that developers can continue using for at least three months after an updated model has been introduced.

Learn more about model deprecation on our [deprecation page](/docs/deprecations).

## GPT-4o

GPT-4o (“o” for “omni”) is our most advanced GPT model. It is multimodal (accepting text or image inputs and outputting text), and it has the same high intelligence as GPT-4 Turbo but is much more efficient—it generates text 2x faster and is 50% cheaper. Additionally, GPT-4o has the best vision and performance across non-English languages of any of our models. GPT-4o is available in the OpenAI API to paying customers. Learn how to use GPT-4o in our [text generation guide](/docs/guides/text-generation).

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4o <br>Our high-intelligence flagship model for complex, multi-step tasks. GPT-4o is cheaper and faster than GPT-4 Turbo. Currently points to `gpt-4o-2024-08-06`. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-2024-11-20 <br>Latest `gpt-4o` snapshot from November 20th, 2024. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-2024-08-06 <br>First snapshot that supports [Structured Outputs](/docs/guides/structured-outputs). `gpt-4o` currently points to this version. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-2024-05-13 <br>Original `gpt-4o` snapshot from May 13, 2024. | 128,000 tokens | 4,096 tokens | Oct 2023 |
| chatgpt-4o-latest <br>The `chatgpt-4o-latest` model version continuously points to the version of GPT-4o used in ChatGPT, and is updated frequently, when there are significant changes. | 128,000 tokens | 16,384 tokens | Oct 2023 |

## GPT-4o mini

GPT-4o mini (“o” for “omni”) is our most advanced model in the small models category, and our cheapest model yet.
It is multimodal (accepting text or image inputs and outputting text), has higher intelligence than `gpt-3.5-turbo` but is just as fast.
It is meant to be used for smaller tasks, including vision tasks.

We recommend choosing `gpt-4o-mini` where you would have previously used `gpt-3.5-turbo` as this model is more capable and cheaper.

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4o-mini<br>Our affordable and intelligent small model for fast, lightweight tasks. GPT-4o mini is cheaper and more capable than GPT-3.5 Turbo. Currently points to `gpt-4o-mini-2024-07-18`. | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-mini-2024-07-18<br>`gpt-4o-mini` currently points to this version. | 128,000 tokens | 16,384 tokens | Oct 2023 |

## GPT-4o Realtime + Audio     Beta

This is a preview release of the GPT-4o Realtime and Audio models. The `gpt-4o-realtime-*` models are capable of responding to audio and text inputs over a WebSocket interface. Learn more in the [Realtime API guide](/docs/guides/realtime). The `gpt-4o-audio-*` models below can be used in Chat Completions to [generate audio responses](/docs/guides/audio).

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4o-realtime-preview<br>Preview release for the [Realtime API](/docs/guides/realtime) | 128,000 tokens | 4,096 tokens | Oct 2023 |
| gpt-4o-realtime-preview-2024-10-01<br>Current snapshot for the Realtime API model. | 128,000 tokens | 4,096 tokens | Oct 2023 |
| gpt-4o-audio-preview<br>Preview release for [audio inputs in chat completions](/docs/guides/audio). | 128,000 tokens | 16,384 tokens | Oct 2023 |
| gpt-4o-audio-preview-2024-10-01<br>Current snapshot for the Audio API model. | 128,000 tokens | 16,384 tokens | Oct 2023 |

## o1-preview and o1-mini     Beta

The **o1 series** of large language models are trained with reinforcement
learning to perform complex reasoning. o1 models think before they answer,
producing a long internal chain of thought before responding to the user.

Learn about the capabilities and limitations of o1 models in our
[reasoning guide](/docs/guides/reasoning).

There are two model types available today:

- **o1-preview**: reasoning model designed to solve hard problems across domains.
- **o1-mini**: faster and cheaper reasoning model particularly good at coding, math, and science.

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| o1-preview<br>Points to the most recent snapshot of the o1 model: `o1-preview-2024-09-12` | 128,000 tokens | 32,768 tokens | Oct 2023 |
| o1-preview-2024-09-12<br>Latest o1 model snapshot | 128,000 tokens | 32,768 tokens | Oct 2023 |
| o1-mini<br>Points to the most recent o1-mini snapshot: `o1-mini-2024-09-12` | 128,000 tokens | 65,536 tokens | Oct 2023 |
| o1-mini-2024-09-12<br>Latest o1-mini model snapshot | 128,000 tokens | 65,536 tokens | Oct 2023 |

## GPT-4 Turbo and GPT-4

GPT-4 is a large multimodal model (accepting text or image inputs and outputting text) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. GPT-4 is available in the OpenAI API to [paying customers](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4). Like `gpt-3.5-turbo`, GPT-4 is optimized for chat but works well for traditional completions tasks using the [Chat Completions API](/docs/api-reference/chat). Learn how to use GPT-4 in our [text generation guide](/docs/guides/text-generation).

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-4-turbo<br>The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling. Currently points to `gpt-4-turbo-2024-04-09`. | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-turbo-2024-04-09<br>GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. `gpt-4-turbo` currently points to this version. | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-turbo-preview<br>GPT-4 Turbo preview model. Currently points to `gpt-4-0125-preview`. | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-0125-preview<br>GPT-4 Turbo preview model intended to reduce cases of “laziness” where the model doesn’t complete a task. [Learn more](https://openai.com/blog/new-embedding-models-and-api-updates). | 128,000 tokens | 4,096 tokens | Dec 2023 |
| gpt-4-1106-preview<br>GPT-4 Turbo preview model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. This is a preview model. [Learn more](https://openai.com/blog/new-models-and-developer-products-announced-at-devday). | 128,000 tokens | 4,096 tokens | Apr 2023 |
| gpt-4<br>Currently points to `gpt-4-0613`. See [continuous model upgrades](#continuous-model-upgrades). | 8,192 tokens | 8,192 tokens | Sep 2021 |
| gpt-4-0613<br>Snapshot of `gpt-4` from June 13th 2023 with improved function calling support. | 8,192 tokens | 8,192 tokens | Sep 2021 |
| gpt-4-0314 <br>Legacy<br>Snapshot of `gpt-4` from March 14th 2023. | 8,192 tokens | 8,192 tokens | Sep 2021 |

For many basic tasks, the difference between GPT-4 and GPT-3.5 models is not significant. However, in more complex reasoning situations, GPT-4 is much more capable than any of our previous models.

#### Multilingual capabilities

GPT-4 [outperforms both previous large language models](https://cdn.openai.com/papers/gpt-4.pdf) and as of 2023, most state-of-the-art systems (which often have benchmark-specific training or hand-engineering). On the MMLU benchmark, an English-language suite of multiple-choice questions covering 57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but also demonstrates strong performance in other languages.

## GPT-3.5 Turbo

GPT-3.5 Turbo models can understand and generate natural language or code and have been optimized for chat using the [Chat Completions API](/docs/api-reference/chat) but work well for non-chat tasks as well.

As of July 2024, `gpt-4o-mini` should be used in place of `gpt-3.5-turbo`, as it is cheaper, more capable, multimodal, and just as fast. `gpt-3.5-turbo` is still available for use in the API.

| Model | Context window | Max output tokens | Knowledge cutoff |
| --- | --- | --- | --- |
| gpt-3.5-turbo-0125<br>The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a text encoding issue for non-English language function calls. [Learn more](https://openai.com/blog/new-embedding-models-and-api-updates#:~:text=Other%20new%20models%20and%20lower%20pricing). | 16,385 tokens | 4,096 tokens | Sep 2021 |
| gpt-3.5-turbo<br>Currently points to `gpt-3.5-turbo-0125`. | 16,385 tokens | 4,096 tokens | Sep 2021 |
| gpt-3.5-turbo-1106<br>GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. [Learn more](https://openai.com/blog/new-models-and-developer-products-announced-at-devday). | 16,385 tokens | 4,096 tokens | Sep 2021 |
| gpt-3.5-turbo-instruct<br>Similar capabilities as GPT-3 era models. Compatible with legacy Completions endpoint and not Chat Completions. | 4,096 tokens | 4,096 tokens | Sep 2021 |

## DALL·E

DALL·E is a AI system that can create realistic images and art from a description in natural language. DALL·E 3 currently supports the ability, given a prompt, to create a new image with a specific size. DALL·E 2 also support the ability to edit an existing image, or create variations of a user provided image.

[DALL·E 3](https://openai.com/dall-e-3) is available through our [Images API](/docs/guides/images) along with [DALL·E 2](https://openai.com/blog/dall-e-api-now-available-in-public-beta). You can try DALL·E 3 through [ChatGPT Plus](https://chatgpt.com).

| Model | Description |
| --- | --- |
| `dall-e-3` | The latest DALL·E model released in Nov 2023. [Learn more](https://openai.com/blog/new-models-and-developer-products-announced-at-devday). |
| `dall-e-2` | The previous DALL·E model released in Nov 2022. The 2nd iteration of DALL·E with more realistic, accurate, and 4x greater resolution images than the original model. |

## TTS

TTS is an AI model that converts text to natural sounding spoken text. We offer two different model variates, `tts-1` is optimized for real time text to speech use cases and `tts-1-hd` is optimized for quality. These models can be used with the [Speech endpoint in the Audio API](/docs/guides/text-to-speech).

| Model | Description |
| --- | --- |
| `tts-1` | The latest text to speech model, optimized for speed. |
| `tts-1-hd` | The latest text to speech model, optimized for quality. |

## Whisper

Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. The Whisper v2-large model is currently available through our API with the `whisper-1` model name.

Currently, there is no difference between the [open source version of Whisper](https://github.com/openai/whisper) and the version available through our API. However, [through our API](/docs/guides/speech-to-text), we offer an optimized inference process which makes running Whisper through our API much faster than doing it through other means. For more technical details on Whisper, you can [read the paper](https://arxiv.org/abs/2212.04356).

## Embeddings

Embeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text. Embeddings are useful for search, clustering, recommendations, anomaly detection, and classification tasks. You can read more about our latest embedding models in the [announcement blog post](https://openai.com/blog/new-embedding-models-and-api-updates).

| Model | Output Dimension |
| --- | --- |
| `text-embedding-3-large` <br>Most capable embedding model for both english and non-english tasks | 3,072 |
| `text-embedding-3-small` <br>Increased performance over 2nd generation ada embedding model | 1,536 |
| `text-embedding-ada-002` <br>Most capable 2nd generation embedding model, replacing 16 first generation models | 1,536 |

* * *

## Moderation

The Moderation models are designed to check whether content complies with OpenAI's [usage policies](https://openai.com/policies/usage-policies). The models provide classification capabilities that look for content in categories like hate, self-harm, sexual content, violence, and others. Learn more about moderating text and images in our [moderation guide](/docs/guides/moderation).

| Model | Max tokens |
| --- | --- |
| `omni-moderation-latest` <br>Currently points to `omni-moderation-2024-09-26`. | 32,768 |
| `omni-moderation-2024-09-26` <br>Latest pinned version of our new multi-modal moderation model, capable of analyzing both text and images. | 32,768 |
| `text-moderation-latest` <br>Currently points to `text-moderation-007`. | 32,768 |
| `text-moderation-stable` <br>Currently points to `text-moderation-007`. | 32,768 |
| `text-moderation-007` <br>Previous generation text-only moderation. We expect `omni-moderation-*` models to be the best default moving forward. | 32,768 |

## GPT base

GPT base models can understand and generate natural language or code but are not trained with instruction following. These models are made to be replacements for our original GPT-3 base models and use the legacy Completions API. Most customers should use GPT-3.5 or GPT-4.

| Model | Max tokens | Knowledge cutoff |
| --- | --- | --- |
| `babbage-002` <br>Replacement for the GPT-3 `ada` and `babbage` base models. | 16,384 tokens | Sep 2021 |
| `davinci-002` <br>Replacement for the GPT-3 `curie` and `davinci` base models. | 16,384 tokens | Sep 2021 |

## How we use your data

Your data is your data.

As of March 1, 2023, data sent to the OpenAI API will not be used to train or improve OpenAI models (unless you explicitly opt-in to share data with us, such as by [providing feedback in the Playground](https://help.openai.com/en/articles/9883556-providing-feedback-in-the-api-playground)). One advantage to opting in is that the models may get better at your use case over time.

To help identify abuse, API data may be retained for up to 30 days, after which it will be deleted (unless otherwise required by law). For trusted customers with sensitive applications, zero data retention may be available. With zero data retention, request and response bodies are not persisted to any logging mechanism and exist only in memory in order to serve the request.

Note that this data policy does not apply to OpenAI's non-API consumer services like [ChatGPT](https://chatgpt.com/) or [DALL·E Labs](https://labs.openai.com/).

### Default usage policies by endpoint

| Endpoint | Data used for training | Default retention | Eligible for zero retention |
| --- | --- | --- | --- |
| `/v1/chat/completions`\* | No | 30 days | Yes, except (a) image inputs, (b) schemas provided for Structured Outputs, or (c) audio outputs. \* |
| `/v1/assistants` | No | 30 days \*\* | No |
| `/v1/threads` | No | 30 days \*\* | No |
| `/v1/threads/messages` | No | 30 days \*\* | No |
| `/v1/threads/runs` | No | 30 days \*\* | No |
| `/v1/vector_stores` | No | 30 days \*\* | No |
| `/v1/threads/runs/steps` | No | 30 days \*\* | No |
| `/v1/images/generations` | No | 30 days | No |
| `/v1/images/edits` | No | 30 days | No |
| `/v1/images/variations` | No | 30 days | No |
| `/v1/embeddings` | No | 30 days | Yes |
| `/v1/audio/transcriptions` | No | Zero data retention | - |
| `/v1/audio/translations` | No | Zero data retention | - |
| `/v1/audio/speech` | No | 30 days | Yes |
| `/v1/files` | No | Until deleted by customer | No |
| `/v1/fine_tuning/jobs` | No | Until deleted by customer | No |
| `/v1/batches` | No | Until deleted by customer | No |
| `/v1/moderations` | No | Zero data retention | - |
| `/v1/completions` | No | 30 days | Yes |
| `/v1/realtime` (beta) | No | 30 days | Yes |

**\\* Chat Completions:**

- Image inputs via the `gpt-4o`, `gpt-4o-mini`, `chatgpt-4o-latest`, or `gpt-4-turbo` models (or previously `gpt-4-vision-preview`) are not eligible for zero retention.
- Audio outputs are stored for 1 hour to enable [multi-turn conversations](/docs/guides/audio), and are not currently eligible for zero retention.
- When Structured Outputs is enabled, schemas provided (either as the `response_format` or in the function definition) are not eligible for zero retention, though the completions themselves are.
- When using Stored Completions via the `store: true` option in the API, those completions are stored for 30 days. Completions are stored in an unfiltered form after an API response, so please avoid storing completions that contain sensitive data.

**\\*\\* Assistants API:**

- Objects related to the Assistants API are deleted from our servers 30 days after you delete them via the API or the dashboard. Objects that are not deleted via the API or dashboard are retained indefinitely.

**Evaluations:**

- [Evaluation](/evaluations) data: When you create an evaluation, the data related to that evaluation is deleted from our servers 30 days after you delete it via the dashboard. Evaluation data that is not deleted via the dashboard is retained indefinitely.

For details, see our [API data usage policies](https://openai.com/policies/api-data-usage-policies). To learn more about zero retention, get in touch with our [sales team](https://openai.com/contact-sales).

## Model endpoint compatibility

| Endpoint | Latest models |
| --- | --- |
| /v1/assistants | All GPT-4o (except `chatgpt-4o-latest`), GPT-4o-mini, GPT-4, and GPT-3.5 Turbo models. The `retrieval` tool requires `gpt-4-turbo-preview` (and subsequent dated model releases) or `gpt-3.5-turbo-1106` (and subsequent versions). |
| /v1/audio/transcriptions | `whisper-1` |
| /v1/audio/translations | `whisper-1` |
| /v1/audio/speech | `tts-1`,  `tts-1-hd` |
| /v1/chat/completions | All GPT-4o (except for Realtime preview), GPT-4o-mini, GPT-4, and GPT-3.5 Turbo models and their dated releases. `chatgpt-4o-latest` dynamic model. [Fine-tuned](/docs/guides/fine-tuning) versions of `gpt-4o`,  `gpt-4o-mini`,  `gpt-4`,  and `gpt-3.5-turbo`. |
| /v1/completions (Legacy) | `gpt-3.5-turbo-instruct`,  `babbage-002`,  `davinci-002` |
| /v1/embeddings | `text-embedding-3-small`,  `text-embedding-3-large`,  `text-embedding-ada-002` |
| /v1/fine\_tuning/jobs | `gpt-4o`,  `gpt-4o-mini`,  `gpt-4`,  `gpt-3.5-turbo` |
| /v1/moderations | `text-moderation-stable`,  `text-moderation-latest` |
| /v1/images/generations | `dall-e-2`,  `dall-e-3` |
| /v1/realtime (beta) | `gpt-4o-realtime-preview`, `gpt-4o-realtime-preview-2024-10-01` |

This list excludes all of our [deprecated models](/docs/deprecations).Log in [Sign up](/signup)

# Latency optimization

Copy page

Improve latency across a wide variety of LLM-related use cases.

This guide covers the core set of principles you can apply to improve latency across a wide variety of LLM-related use cases. These techniques come from working with a wide range of customers and developers on production applications, so they should apply regardless of what you're building – from a granular workflow to an end-to-end chatbot.

While there's many individual techniques, we'll be grouping them into **seven principles** meant to represent a high-level taxonomy of approaches for improving latency.

At the end, we'll walk through an [example](#example) to see how they can be applied.

### Seven principles

1. [Process tokens faster.](#process-tokens-faster)
2. [Generate fewer tokens.](#generate-fewer-tokens)
3. [Use fewer input tokens.](#use-fewer-input-tokens)
4. [Make fewer requests.](#make-fewer-requests)
5. [Parallelize.](#parallelize)
6. [Make your users wait less.](#make-your-users-wait-less)
7. [Don't default to an LLM.](#don-t-default-to-an-llm)

## Process tokens faster

**Inference speed** is probably the first thing that comes to mind when addressing latency (but as you'll see soon, it's far from the only one). This refers to the actual **rate at which the LLM processes tokens**, and is often measured in TPM (tokens per minute) or TPS (tokens per second).

The main factor that influences inference speed is **model size** – smaller models usually run faster (and cheaper), and when used correctly can even outperform larger models. To maintain high quality performance with smaller models you can explore:

- using a longer, [more detailed prompt](/docs/guides/prompt-engineering#tactic-specify-the-steps-required-to-complete-a-task),
- adding (more) [few-shot examples](/docs/guides/prompt-engineering#tactic-provide-examples), or
- [fine-tuning](/docs/guides/fine-tuning) / distillation.

You can also employ inference optimizations like our [**Predicted outputs**](/docs/guides/predicted-outputs) feature. Predicted outputs let you significantly reduce latency of a generation when you know most of the output ahead of time, such as code editing tasks. By giving the model a prediction, the LLM can focus more on the actual changes, and less on the content that will remain the same.

Deep dive

Compute capacity & additional inference optimizations

## Generate fewer tokens

Generating tokens is almost always the highest latency step when using an LLM: as a general heuristic, **cutting 50% of your output tokens may cut ~50% your latency**. The way you reduce your output size will depend on output type:

If you're generating **natural language**, simply **asking the model to be more concise** ("under 20 words" or "be very brief") may help. You can also use few shot examples and/or fine-tuning to teach the model shorter responses.

If you're generating **structured output**, try to **minimize your output syntax** where possible: shorten function names, omit named arguments, coalesce parameters, etc.

Finally, while not common, you can also use `max_tokens` or `stop_tokens` to end your generation early.

Always remember: an output token cut is a (milli)second earned!

## Use fewer input tokens

While reducing the number of input tokens does result in lower latency, this is not usually a significant factor – **cutting 50% of your prompt may only result in a 1-5% latency improvement**. Unless you're working with truly massive context sizes (documents, images), you may want to spend your efforts elsewhere.

That being said, if you _are_ working with massive contexts (or you're set on squeezing every last bit of performance _and_ you've exhausted all other options) you can use the following techniques to reduce your input tokens:

- **Fine-tuning the model**, to replace the need for lengthy instructions / examples.
- **Filtering context input**, like pruning RAG results, cleaning HTML, etc.
- **Maximize shared prompt prefix**, by putting dynamic portions (e.g. RAG results, history, etc) later in the prompt. This makes your request more [KV cache](https://medium.com/@joaolages/kv-caching-explained-276520203249)-friendly (which most LLM providers use) and means fewer input tokens are processed on each request.

Check out our docs to learn more about how [prompt caching](/docs/guides/prompt-engineering#prompt-caching) works.

## Make fewer requests

Each time you make a request you incur some round-trip latency – this can start to add up.

If you have sequential steps for the LLM to perform, instead of firing off one request per step consider **putting them in a single prompt and getting them all in a single response**. You'll avoid the additional round-trip latency, and potentially also reduce complexity of processing multiple responses.

An approach to doing this is by collecting your steps in an enumerated list in the combined prompt, and then requesting the model to return the results in named fields in a JSON. This way you can easily parse out and reference each result!

## Parallelize

Parallelization can be very powerful when performing multiple steps with an LLM.

If the steps **are _not_ strictly sequential**, you can **split them out into parallel calls**. Two shirts take just as long to dry as one.

If the steps **_are_ strictly sequential**, however, you might still be able to **leverage speculative execution**. This is particularly effective for classification steps where one outcome is more likely than the others (e.g. moderation).

1. Start step 1 & step 2 simultaneously (e.g. input moderation & story generation)
2. Verify the result of step 1
3. If result was not the expected, cancel step 2 (and retry if necessary)

If your guess for step 1 is right, then you essentially got to run it with zero added latency!

## Make your users wait less

There's a huge difference between **waiting** and **watching progress happen** – make sure your users experience the latter. Here are a few techniques:

- **Streaming**: The single most effective approach, as it cuts the _waiting_ time to a second or less. (ChatGPT would feel pretty different if you saw nothing until each response was done.)
- **Chunking**: If your output needs further processing before being shown to the user (moderation, translation) consider **processing it in chunks** instead of all at once. Do this by streaming to your backend, then sending processed chunks to your frontend.
- **Show your steps**: If you're taking multiple steps or using tools, surface this to the user. The more real progress you can show, the better.
- **Loading states**: Spinners and progress bars go a long way.

Note that while **showing your steps & having loading states** have a mostly
psychological effect, **streaming & chunking** genuinely do reduce overall
latency once you consider the app + user system: the user will finish reading a response
sooner.

## Don't default to an LLM

LLMs are extremely powerful and versatile, and are therefore sometimes used in cases where a **faster classical method** would be more appropriate. Identifying such cases may allow you to cut your latency significantly. Consider the following examples:

- **Hard-coding:** If your **output** is highly constrained, you may not need an LLM to generate it. Action confirmations, refusal messages, and requests for standard input are all great candidates to be hard-coded. (You can even use the age-old method of coming up with a few variations for each.)
- **Pre-computing:** If your **input** is constrained (e.g. category selection) you can generate multiple responses in advance, and just make sure you never show the same one to a user twice.
- **Leveraging UI:** Summarized metrics, reports, or search results are sometimes better conveyed with classical, bespoke UI components rather than LLM-generated text.
- **Traditional optimization techniques:** An LLM application is still an application; binary search, caching, hash maps, and runtime complexity are all _still_ useful in a world of LLMs.

## Example

Let's now look at a sample application, identify potential latency optimizations, and propose some solutions!

We'll be analyzing the architecture and prompts of a hypothetical customer service bot inspired by real production applications. The [architecture and prompts](#architecture-and-prompts) section sets the stage, and the [analysis and optimizations](#analysis-and-optimizations) section will walk through the latency optimization process.

You'll notice this example doesn't cover every single principle, much like real-world use cases don't require applying every technique.

### Architecture and prompts

The following is the **initial architecture** for a hypothetical **customer service bot**. This is what we'll be making changes to.

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-0.png)

At a high level, the diagram flow describes the following process:

1. A user sends a message as part of an ongoing conversation.
2. The last message is turned into a **self-contained query** (see examples in prompt).
3. We determine whether or not **additional (retrieved) information is required** to respond to that query.
4. **Retrieval** is performed, producing search results.
5. The assistant **reasons** about the user's query and search results, and **produces a response**.
6. The response is sent back to the user.

Below are the prompts used in each part of the diagram. While they are still only hypothetical and simplified, they are written with the same structure and wording that you would find in a production application.

Places where you see placeholders like " **\[user input here\]**" represent dynamic portions, that would be replaced by actual data at runtime.

Query contextualization prompt

Re-writes user query to be a self-contained search query.

SYSTEM

Given the previous conversation, re-write the last user query so it contains
all necessary context.

\# Example
History: \[{user: "What is your return policy?"},{assistant: "..."}\]
User Query: "How long does it cover?"
Response: "How long does the return policy cover?"

\# Conversation
\[last 3 messages of conversation\]

\# User Query
\[last user query\]

USER

\[JSON-formatted input conversation here\]

Retrieval check prompt

Determines whether a query requires performing retrieval to respond.

SYSTEM

Given a user query, determine whether it requires doing a realtime lookup to
respond to.

\# Examples
User Query: "How can I return this item after 30 days?"
Response: "true"

User Query: "Thank you!"
Response: "false"

USER

\[input user query here\]

Assistant prompt

Fills the fields of a JSON to reason through a pre-defined set of steps to produce a final response given a user conversation and relevant retrieved information.

SYSTEM

You are a helpful customer service bot.

Use the result JSON to reason about each user query - use the retrieved context.

\# Example

User: "My computer screen is cracked! I want it fixed now!!!"

Assistant Response:
{
"message\_is\_conversation\_continuation": "True",
"number\_of\_messages\_in\_conversation\_so\_far": "1",
"user\_sentiment": "Aggravated",
"query\_type": "Hardware Issue",
"response\_tone": "Validating and solution-oriented",
"response\_requirements": "Propose options for repair or replacement.",
"user\_requesting\_to\_talk\_to\_human": "False",
"enough\_information\_in\_context": "True"
"response": "..."
}

USER

\# Relevant Information
\` \` \`
\[retrieved context\]
\` \` \`

USER

\[input user query here\]

### Analysis and optimizations

#### Part 1: Looking at retrieval prompts

Looking at the architecture, the first thing that stands out is the **consecutive GPT-4 calls** \- these hint at a potential inefficiency, and can often be replaced by a single call or parallel calls.

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-2.png)

In this case, since the check for retrieval requires the contextualized query, let's **combine them into a single prompt** to [make fewer requests](#make-fewer-requests).

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-3.png)

Combined query contextualization and retrieval check prompt

**What changed?** Before, we had one prompt to re-write the query and one to determine whether this requires doing a retrieval lookup. Now, this combined prompt does both. Specifically, notice the updated instruction in the first line of the prompt, and the updated output JSON:

```jsx
1
2
3
4
{
query:"[contextualized query]",
retrieval:"[true/false - whether retrieval is required]"
}
```

SYSTEM

Given the previous conversation, re-write the last user query so it contains
all necessary context. Then, determine whether the full request requires doing a
realtime lookup to respond to.

Respond in the following form:
{
query:"\[contextualized query\]",
retrieval:"\[true/false - whether retrieval is required\]"
}

\# Examples

History: \[{user: "What is your return policy?"},{assistant: "..."}\]
User Query: "How long does it cover?"
Response: {query: "How long does the return policy cover?", retrieval: "true"}

History: \[{user: "How can I return this item after 30 days?"},{assistant: "..."}\]
User Query: "Thank you!"
Response: {query: "Thank you!", retrieval: "false"}

\# Conversation
\[last 3 messages of conversation\]

\# User Query
\[last user query\]

USER

\[JSON-formatted input conversation here\]

Actually, adding context and determining whether to retrieve are very straightforward and well defined tasks, so we can likely use a **smaller, fine-tuned model** instead. Switching to GPT-3.5 will let us [process tokens faster](#process-tokens-faster).

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-4.png)

#### Part 2: Analyzing the assistant prompt

Let's now direct our attention to the Assistant prompt. There seem to be many distinct steps happening as it fills the JSON fields – this could indicate an opportunity to [parallelize](#parallelize).

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-5.png)

However, let's pretend we have run some tests and discovered that splitting the reasoning steps in the JSON produces worse responses, so we need to explore different solutions.

**Could we use a fine-tuned GPT-3.5 instead of GPT-4?** Maybe – but in general, open-ended responses from assistants are best left to GPT-4 so it can better handle a greater range of cases. That being said, looking at the reasoning steps themselves, they may not all require GPT-4 level reasoning to produce. The well defined, limited scope nature makes them and **good potential candidates for fine-tuning**.

```jsx
1
2
3
4
5
6
7
8
9
10
11
{
"message_is_conversation_continuation": "True", // <-
"number_of_messages_in_conversation_so_far": "1", // <-
"user_sentiment": "Aggravated", // <-
"query_type": "Hardware Issue", // <-
"response_tone": "Validating and solution-oriented", // <-
"response_requirements": "Propose options for repair or replacement.", // <-
"user_requesting_to_talk_to_human": "False", // <-
"enough_information_in_context": "True" // <-
"response": "..." // X -- benefits from GPT-4
}
```

This opens up the possibility of a trade-off. Do we keep this as a **single request entirely generated by GPT-4**, or **split it into two sequential requests** and use GPT-3.5 for all but the final response? We have a case of conflicting principles: the first option lets us [make fewer requests](#make-fewer-requests), but the second may let us [process tokens faster](#1-process-tokens-faster).

As with many optimization tradeoffs, the answer will depend on the details. For example:

- The proportion of tokens in the `response` vs the other fields.
- The average latency decrease from processing most fields faster.
- The average latency _increase_ from doing two requests instead of one.

The conclusion will vary by case, and the best way to make the determiation is by testing this with production examples. In this case let's pretend the tests indicated it's favorable to split the prompt in two to [process tokens faster](#process-tokens-faster).

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-6.png)

**Note:** We'll be grouping `response` and `enough_information_in_context` together in the second prompt to avoid passing the retrieved context to both new prompts.

Assistants prompt - reasoning

This prompt will be passed to GPT-3.5 and can be fine-tuned on curated examples.

**What changed?** The "enough\_information\_in\_context" and "response" fields were removed, and the retrieval results are no longer loaded into this prompt.

SYSTEM

You are a helpful customer service bot.

Based on the previous conversation, respond in a JSON to determine the required
fields.

\# Example

User: "My freaking computer screen is cracked!"

Assistant Response:
{
"message\_is\_conversation\_continuation": "True",
"number\_of\_messages\_in\_conversation\_so\_far": "1",
"user\_sentiment": "Aggravated",
"query\_type": "Hardware Issue",
"response\_tone": "Validating and solution-oriented",
"response\_requirements": "Propose options for repair or replacement.",
"user\_requesting\_to\_talk\_to\_human": "False",
}

Assistants prompt - response

This prompt will be processed by GPT-4 and will receive the reasoning steps determined in the prior prompt, as well as the results from retrieval.

**What changed?** All steps were removed except for "enough\_information\_in\_context" and "response". Additionally, the JSON we were previously filling in as output will be passed in to this prompt.

SYSTEM

You are a helpful customer service bot.

Use the retrieved context, as well as these pre-classified fields, to respond to
the user's query.

\# Reasoning Fields
\` \` \`
\[reasoning json determined in previous GPT-3.5 call\]
\` \` \`

\# Example

User: "My freaking computer screen is cracked!"

Assistant Response:
{
"enough\_information\_in\_context": "True"
"response": "..."
}

USER

\# Relevant Information
\` \` \`
\[retrieved context\]
\` \` \`

In fact, now that the reasoning prompt does not depend on the retrieved context we can [parallelize](#parallelize) and fire it off at the same time as the retrieval prompts.

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-6b.png)

#### Part 3: Optimizing the structured output

Let's take another look at the reasoning prompt.

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-7b.png)

Taking a closer look at the reasoning JSON you may notice the field names themselves are quite long.

```jsx
1
2
3
4
5
6
7
8
9
{
"message_is_conversation_continuation": "True", // <-
"number_of_messages_in_conversation_so_far": "1", // <-
"user_sentiment": "Aggravated", // <-
"query_type": "Hardware Issue", // <-
"response_tone": "Validating and solution-oriented", // <-
"response_requirements": "Propose options for repair or replacement.", // <-
"user_requesting_to_talk_to_human": "False", // <-
}
```

By making them shorter and moving explanations to the comments we can [generate fewer tokens](#generate-fewer-tokens).

```jsx
1
2
3
4
5
6
7
8
9
{
"cont": "True", // whether last message is a continuation
"n_msg": "1", // number of messages in the continued conversation
"tone_in": "Aggravated", // sentiment of user query
"type": "Hardware Issue", // type of the user query
"tone_out": "Validating and solution-oriented", // desired tone for response
"reqs": "Propose options for repair or replacement.", // response requirements
"human": "False", // whether user is expressing want to talk to human
}
```

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-8b.png)

This small change removed 19 output tokens. While with GPT-3.5 this may only result in a few millisecond improvement, with GPT-4 this could shave off up to a second.

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/token-counts-latency-customer-service-large.png)

You might imagine, however, how this can have quite a significant impact for larger model outputs.

We could go further and use single chatacters for the JSON fields, or put everything in an array, but this may start to hurt our response quality. The best way to know, once again, is through testing.

#### Example wrap-up

Let's review the optimizations we implemented for the customer service bot example:

![Assistants object architecture diagram](https://cdn.openai.com/API/docs/images/diagram-latency-customer-service-11b.png)

1. **Combined** query contextualization and retrieval check steps to [make fewer requests](#make-fewer-requests).
2. For the new prompt, **switched to a smaller, fine-tuned GPT-3.5** to [process tokens faster](process-tokens-faster).
3. Split the assistant prompt in two, **switching to a smaller, fine-tuned GPT-3.5** for the reasoning, again to [process tokens faster](#process-tokens-faster).
4. [Parallelized](#parallelize) the retrieval checks and the reasoning steps.
5. **Shortened reasoning field names** and moved comments into the prompt, to [generate fewer tokens](#generate-fewer-tokens).Log in [Sign up](/signup)

# Structured Outputs

Copy page

Ensure responses follow JSON Schema for Structured Outputs.

## Try it out

Try it out in the [Playground](/playground) or generate a ready-to-use schema definition to experiment with structured outputs.

Generate

## Introduction

JSON is one of the most widely used formats in the world for applications to exchange data.

Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied [JSON Schema](https://json-schema.org/overview/what-is-jsonschema), so you don't need to worry about the model omitting a required key, or hallucinating an invalid enum value.

Some benefits of Structed Outputs include:

1. **Reliable type-safety:** No need to validate or retry incorrectly formatted responses
2. **Explicit refusals:** Safety-based model refusals are now programmatically detectable
3. **Simpler prompting:** No need for strongly worded prompts to achieve consistent formatting

In addition to supporting JSON Schema in the REST API, the OpenAI SDKs for [Python](https://github.com/openai/openai-python/blob/main/helpers.md#structured-outputs-parsing-helpers) and [JavaScript](https://github.com/openai/openai-node/blob/master/helpers.md#structured-outputs-parsing-helpers) also make it easy to define object schemas using [Pydantic](https://docs.pydantic.dev/latest/) and [Zod](https://zod.dev/) respectively. Below, you can see how to extract information from unstructured text that conforms to a schema defined in code.

Getting a structured response

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
from pydantic import BaseModel
from openai import OpenAI

client = OpenAI()

class CalendarEvent(BaseModel):
    name: str
    date: str
    participants: list[str]

completion = client.beta.chat.completions.parse(
    model="gpt-4o-2024-08-06",
    messages=[\
        {"role": "system", "content": "Extract the event information."},\
        {"role": "user", "content": "Alice and Bob are going to a science fair on Friday."},\
    ],
    response_format=CalendarEvent,
)

event = completion.choices[0].message.parsed
```

### Supported models

Structured Outputs are available in our [latest large language models](/docs/models), starting with GPT-4o:

- `gpt-4o-mini-2024-07-18` and later
- `gpt-4o-2024-08-06` and later

Older models like `gpt-4-turbo` and earlier may use [JSON mode](#json-mode) instead.

## When to use Structured Outputs via function calling vs via response\_format

Structured Outputs is available in two forms in the OpenAI API:

1. When using [function calling](/docs/guides/function-calling)
2. When using a `json_schema` response format

Function calling is useful when you are building an application that bridges the models and functionality of your application.

For example, you can give the model access to functions that query a database in order to build an AI assistant that can help users with their orders, or functions that can interact with the UI.

Conversely, Structured Outputs via `response_format` are more suitable when you want to indicate a structured schema for use when the model responds to the user, rather than when the model calls a tool.

For example, if you are building a math tutoring application, you might want the assistant to respond to your user using a specific JSON Schema so that you can generate a UI that displays different parts of the model's output in distinct ways.

Put simply:

- If you are connecting the model to tools, functions, data, etc. in your system, then you should use function calling
- If you want to structure the model's output when it responds to the user, then you should use a structured `response_format`

The remainder of this guide will focus on non-function calling use cases in the Chat Completions API. To learn more about how to use Structured Outputs with function calling, check out the [Function Calling](/docs/guides/function-calling#function-calling-with-structured-outputs) guide.

### Structured Outputs vs JSON mode

Structured Outputs is the evolution of [JSON mode](#json-mode). While both ensure valid JSON is produced, only Structured Outputs ensure schema adherance. Both Structured Outputs and JSON mode are supported in the Chat Completions API, Assistants API, Fine-tuning API and Batch API.

We recommend always using Structured Outputs instead of JSON mode when possible.

However, Structured Outputs with `response_format: {type: "json_schema", ...}` is only supported with the `gpt-4o-mini`, `gpt-4o-mini-2024-07-18`, and `gpt-4o-2024-08-06` model snapshots and later.

|  | Structured Outputs | JSON Mode |
| --- | --- | --- |
| **Outputs valid JSON** | Yes | Yes |
| **Adheres to schema** | Yes (see [supported schemas](#supported-schemas)) | No |
| **Compatible models** | `gpt-4o-mini`, `gpt-4o-2024-08-06`, and later | `gpt-3.5-turbo`, `gpt-4-*` and `gpt-4o-*` models |
| **Enabling** | `response_format: { type: "json_schema", json_schema: {"strict": true, "schema": ...} }` | `response_format: { type: "json_object" }` |

## Examples

Chain of thoughtStructured data extractionUI generationModeration

### Chain of thought

You can ask the model to output an answer in a structured, step-by-step way, to guide the user through the solution.

Structured Outputs for chain-of-thought math tutoring

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
from pydantic import BaseModel
from openai import OpenAI

client = OpenAI()

class Step(BaseModel):
    explanation: str
    output: str

class MathReasoning(BaseModel):
    steps: list[Step]
    final_answer: str

completion = client.beta.chat.completions.parse(
    model="gpt-4o-2024-08-06",
    messages=[\
        {"role": "system", "content": "You are a helpful math tutor. Guide the user through the solution step by step."},\
        {"role": "user", "content": "how can I solve 8x + 7 = -23"}\
    ],
    response_format=MathReasoning,
)

math_reasoning = completion.choices[0].message.parsed
```

#### Example response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
  "steps": [\
    {\
      "explanation": "Start with the equation 8x + 7 = -23.",\
      "output": "8x + 7 = -23"\
    },\
    {\
      "explanation": "Subtract 7 from both sides to isolate the term with the variable.",\
      "output": "8x = -23 - 7"\
    },\
    {\
      "explanation": "Simplify the right side of the equation.",\
      "output": "8x = -30"\
    },\
    {\
      "explanation": "Divide both sides by 8 to solve for x.",\
      "output": "x = -30 / 8"\
    },\
    {\
      "explanation": "Simplify the fraction.",\
      "output": "x = -15 / 4"\
    }\
  ],
  "final_answer": "x = -15 / 4"
}
```

## How to use Structured Outputs with response\_format

You can use Structured Outputs with the new SDK helper to parse the model's output into your desired format, or you can specify the JSON schema directly.

**Note:** the first request you make with any schema will have additional latency as our API processes the schema, but subsequent requests with the same schema will not have additional latency.

SDK objectsManual schema

Step 1: Define your object

First you must define an object or data structure to represent the JSON Schema that the model should be constrained to follow. See the [examples](/docs/guides/structured-outputs#examples) at the top of this guide for reference.

While Structured Outputs supports much of JSON Schema, some features are unavailable either for performance or technical reasons. See [here](/docs/guides/structured-outputs#supported-schemas) for more details.

For example, you can define an object like this:

python

```python
1
2
3
4
5
6
7
8
9
from pydantic import BaseModel

class Step(BaseModel):
    explanation: str
    output: str

class MathResponse(BaseModel):
    steps: list[Step]
    final_answer: str
```

#### Tips for your data structure

To maximize the quality of model generations, we recommend the following:

- Name keys clearly and intuitively
- Create clear titles and descriptions for important keys in your structure
- Create and use evals to determine the structure that works best for your use case

Step 2: Supply your object in the API call

You can use the `parse` method to automatically parse the JSON response into the object you defined.

Under the hood, the SDK takes care of supplying the JSON schema corresponding to your data structure, and then parsing the response as an object.

python

```python
1
2
3
4
5
6
7
8
completion = client.beta.chat.completions.parse(
    model="gpt-4o-2024-08-06",
    messages=[\
        {"role": "system", "content": "You are a helpful math tutor. Guide the user through the solution step by step."},\
        {"role": "user", "content": "how can I solve 8x + 7 = -23"}\
    ],
    response_format=MathResponse
  )
```

Step 3: Handle edge cases

In some cases, the model might not generate a valid response that matches the provided JSON schema.

This can happen in the case of a refusal, if the model refuses to answer for safety reasons, or if for example you reach a max tokens limit and the response is incomplete.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
try:
    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[\
            {"role": "system", "content": "You are a helpful math tutor. Guide the user through the solution step by step."},\
            {"role": "user", "content": "how can I solve 8x + 7 = -23"}\
        ],
        response_format=MathResponse,
        max_tokens=50
    )
    math_response = completion.choices[0].message
    if math_response.parsed:
        print(math_response.parsed)
    elif math_response.refusal:
        # handle refusal
        print(math_response.refusal)
except Exception as e:
    # Handle edge cases
    if type(e) == openai.LengthFinishReasonError:
        # Retry with a higher max tokens
        print("Too many tokens: ", e)
        pass
    else:
        # Handle other exceptions
        print(e)
        pass
```

Step 4: Use the generated structured data in a type-safe way

When using the SDK, you can use the `parsed` attribute to access the parsed JSON response as an object. This object will be of the type you defined in the `response_format` parameter.

python

```python
1
2
3
math_response = completion.choices[0].message.parsed
print(math_response.steps)
print(math_response.final_answer)
```

### Refusals with Structured Outputs

When using Structured Outputs with user-generated input, OpenAI models may occasionally refuse to fulfill the request for safety reasons. Since a refusal does not necessarily follow the schema you have supplied in `response_format`, the API response will include a new field called `refusal` to indicate that the model refused to fulfill the request.

When the `refusal` property appears in your output object, you might present the refusal in your UI, or include conditional logic in code that consumes the response to handle the case of a refused request.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
class Step(BaseModel):
    explanation: str
    output: str

class MathReasoning(BaseModel):
    steps: list[Step]
    final_answer: str

completion = client.beta.chat.completions.parse(
    model="gpt-4o-2024-08-06",
    messages=[\
        {"role": "system", "content": "You are a helpful math tutor. Guide the user through the solution step by step."},\
        {"role": "user", "content": "how can I solve 8x + 7 = -23"}\
    ],
    response_format=MathReasoning,
)

math_reasoning = completion.choices[0].message

# If the model refuses to respond, you will get a refusal message
if (math_reasoning.refusal):
    print(math_reasoning.refusal)
else:
    print(math_reasoning.parsed)
```

The API response from a refusal will look something like this:

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
  "id": "chatcmpl-9nYAG9LPNonX8DAyrkwYfemr3C8HC",
  "object": "chat.completion",
  "created": 1721596428,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
	  "index": 0,\
	  "message": {\
            "role": "assistant",\
            "refusal": "I'm sorry, I cannot assist with that request."\
	  },\
	  "logprobs": null,\
	  "finish_reason": "stop"\
	}\
  ],
  "usage": {
      "prompt_tokens": 81,
      "completion_tokens": 11,
      "total_tokens": 92,
      "completion_tokens_details": {
        "reasoning_tokens": 0,
        "accepted_prediction_tokens": 0,
        "rejected_prediction_tokens": 0
      }
  },
  "system_fingerprint": "fp_3407719c7f"
}
```

### Tips and best practices

#### Handling user-generated input

If your application is using user-generated input, make sure your prompt includes instructions on how to handle situations where the input cannot result in a valid response.

The model will always try to adhere to the provided schema, which can result in hallucinations if the input is completely unrelated to the schema.

You could include language in your prompt to specify that you want to return empty parameters, or a specific sentence, if the model detects that the input is incompatible with the task.

#### Handling mistakes

Structured Outputs can still contain mistakes. If you see mistakes, try adjusting your instructions, providing examples in the system instructions, or splitting tasks into simpler subtasks. Refer to the [prompt engineering guide](/docs/guides/prompt-engineering) for more guidance on how to tweak your inputs.

#### Avoid JSON schema divergence

To prevent your JSON Schema and corresponding types in your programming language from diverging, we strongly recommend using the native Pydantic/zod sdk support.

If you prefer to specify the JSON schema directly, you could add CI rules that flag when either the JSON schema or underlying data objects are edited, or add a CI step that auto-generates the JSON Schema from type definitions (or vice-versa).

## Supported schemas

Structured Outputs supports a subset of the [JSON Schema](https://json-schema.org/docs) language.

#### Supported types

The following types are supported for Structured Outputs:

- String
- Number
- Boolean
- Integer
- Object
- Array
- Enum
- anyOf

#### Root objects must not be `anyOf`

Note that the root level object of a schema must be an object, and not use `anyOf`. A pattern that appears in Zod (as one example) is using a discriminated union, which produces an `anyOf` at the top level. So code such as the following won't work:

javascript

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
import { z } from 'zod';
import { zodResponseFormat } from 'openai/helpers/zod';

const BaseResponseSchema = z.object({ /* ... */ });
const UnsuccessfulResponseSchema = z.object({ /* ... */ });

const finalSchema = z.discriminatedUnion('status', [\
    BaseResponseSchema,\
    UnsuccessfulResponseSchema,\
]);

// Invalid JSON Schema for Structured Outputs
const json = zodResponseFormat(finalSchema, 'final_schema');
```

#### All fields must be `required`

To use Structured Outputs, all fields or function parameters must be specified as `required`.

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
    "name": "get_weather",
    "description": "Fetches the weather in the given location",
    "strict": true,
    "parameters": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The location to get the weather for"
            },
            "unit": {
                "type": "string",
                "description": "The unit to return the temperature in",
                "enum": ["F", "C"]
            }
        },
        "additionalProperties": false,
        "required": ["location", "unit"]
    }
}
```

Although all fields must be required (and the model will return a value for each parameter), it is possible to emulate an optional parameter by using a union type with `null`.

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "name": "get_weather",
    "description": "Fetches the weather in the given location",
    "strict": true,
    "parameters": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The location to get the weather for"
            },
            "unit": {
                "type": ["string", "null"],
                "description": "The unit to return the temperature in",
                "enum": ["F", "C"]
            }
        },
        "additionalProperties": false,
        "required": [\
            "location", "unit"\
        ]
    }
}
```

#### Objects have limitations on nesting depth and size

A schema may have up to 100 object properties total, with up to 5 levels of nesting.

#### Limitations on total string size

In a schema, total string length of all property names, definition names, enum values, and const values cannot exceed 15,000 characters.

#### Limitations on enum size

A schema may have up to 500 enum values across all enum properties.

For a single enum property with string values, the total string length of all enum values cannot exceed 7,500 characters when there are more than 250 enum values.

#### `additionalProperties: false` must always be set in objects

`additionalProperties` controls whether it is allowable for an object to contain additional keys / values that were not defined in the JSON Schema.

Structured Outputs only supports generating specified keys / values, so we require developers to set `additionalProperties: false` to opt into Structured Outputs.

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "name": "get_weather",
    "description": "Fetches the weather in the given location",
    "strict": true,
    "schema": {
        "type": "object",
        "properties": {
            "location": {
                "type": "string",
                "description": "The location to get the weather for"
            },
            "unit": {
                "type": "string",
                "description": "The unit to return the temperature in",
                "enum": ["F", "C"]
            }
        },
        "additionalProperties": false,
        "required": [\
            "location", "unit"\
        ]
    }
}
```

#### Key ordering

When using Structured Outputs, outputs will be produced in the same order as the ordering of keys in the schema.

#### Some type-specific keywords are not yet supported

Notable keywords not supported include:

- **For strings:** `minLength`, `maxLength`, `pattern`, `format`
- **For numbers:** `minimum`, `maximum`, `multipleOf`
- **For objects:** `patternProperties`, `unevaluatedProperties`, `propertyNames`, `minProperties`, `maxProperties`
- **For arrays:** `unevaluatedItems`, `contains`, `minContains`, `maxContains`, `minItems`, `maxItems`, `uniqueItems`

If you turn on Structured Outputs by supplying `strict: true` and call the API with an unsupported JSON Schema, you will receive an error.

#### For `anyOf`, the nested schemas must each be a valid JSON Schema per this subset

Here's an example supported anyOf schema:

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
{
	"type": "object",
	"properties": {
		"item": {
			"anyOf": [\
				{\
					"type": "object",\
					"description": "The user object to insert into the database",\
					"properties": {\
						"name": {\
							"type": "string",\
							"description": "The name of the user"\
						},\
						"age": {\
							"type": "number",\
							"description": "The age of the user"\
						}\
					},\
					"additionalProperties": false,\
					"required": [\
						"name",\
						"age"\
					]\
				},\
				{\
					"type": "object",\
					"description": "The address object to insert into the database",\
					"properties": {\
						"number": {\
							"type": "string",\
							"description": "The number of the address. Eg. for 123 main st, this would be 123"\
						},\
						"street": {\
							"type": "string",\
							"description": "The street name. Eg. for 123 main st, this would be main st"\
						},\
						"city": {\
							"type": "string",\
							"description": "The city of the address"\
						}\
					},\
					"additionalProperties": false,\
					"required": [\
						"number",\
						"street",\
						"city"\
					]\
				}\
			]
		}
	},
	"additionalProperties": false,
	"required": [\
		"item"\
	]
}
```

#### Definitions are supported

You can use definitions to define subschemas which are referenced throughout your schema. The following is a simple example.

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
	"type": "object",
	"properties": {
		"steps": {
			"type": "array",
			"items": {
				"$ref": "#/$defs/step"
			}
		},
		"final_answer": {
			"type": "string"
		}
	},
	"$defs": {
		"step": {
			"type": "object",
			"properties": {
				"explanation": {
					"type": "string"
				},
				"output": {
					"type": "string"
				}
			},
			"required": [\
				"explanation",\
				"output"\
			],
			"additionalProperties": false
		}
	},
	"required": [\
		"steps",\
		"final_answer"\
	],
	"additionalProperties": false
}
```

#### Recursive schemas are supported

Sample recursive schema using `#` to indicate root recursion.

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
{
        "name": "ui",
        "description": "Dynamically generated UI",
        "strict": true,
        "schema": {
            "type": "object",
            "properties": {
                "type": {
                    "type": "string",
                    "description": "The type of the UI component",
                    "enum": ["div", "button", "header", "section", "field", "form"]
                },
                "label": {
                    "type": "string",
                    "description": "The label of the UI component, used for buttons or form fields"
                },
                "children": {
                    "type": "array",
                    "description": "Nested UI components",
                    "items": {
                        "$ref": "#"
                    }
                },
                "attributes": {
                    "type": "array",
                    "description": "Arbitrary attributes for the UI component, suitable for any element",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "The name of the attribute, for example onClick or className"
                            },
                            "value": {
                                "type": "string",
                                "description": "The value of the attribute"
                            }
                        },
                      "additionalProperties": false,
                      "required": ["name", "value"]
                    }
                }
            },
            "required": ["type", "label", "children", "attributes"],
            "additionalProperties": false
        }
    }
```

Sample recursive schema using explicit recursion:

json

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
	"type": "object",
	"properties": {
		"linked_list": {
			"$ref": "#/$defs/linked_list_node"
		}
	},
	"$defs": {
		"linked_list_node": {
			"type": "object",
			"properties": {
				"value": {
					"type": "number"
				},
				"next": {
					"anyOf": [\
						{\
							"$ref": "#/$defs/linked_list_node"\
						},\
						{\
							"type": "null"\
						}\
					]
				}
			},
			"additionalProperties": false,
			"required": [\
				"next",\
				"value"\
			]
		}
	},
	"additionalProperties": false,
	"required": [\
		"linked_list"\
	]
}
```

## JSON mode

JSON mode is a more basic version of the Structured Outputs feature. While JSON mode ensures that model output is valid JSON, Structured Outputs reliably matches the model's output to the schema you specify.
We recommend you use Structured Outputs if it is supported for your use case.

When JSON mode is turned on, the model's output is ensured to be valid JSON, except for in some edge cases that you should detect and handle appropriately.

To turn on JSON mode with the Chat Completions or Assistants API you can set the `response_format` to `{ "type": "json_object" }`. If you are using function calling, JSON mode is always turned on.

Important notes:

- When using JSON mode, you must always instruct the model to produce JSON via some message in the conversation, for example via your system message. If you don't include an explicit instruction to generate JSON, the model may generate an unending stream of whitespace and the request may run continually until it reaches the token limit. To help ensure you don't forget, the API will throw an error if the string "JSON" does not appear somewhere in the context.
- JSON mode will not guarantee the output matches any specific schema, only that it is valid and parses without errors. You should use Structured Outputs to ensure it matches your schema, or if that is not possible, you should use a validation library and potentially retries to ensure that the output matches your desired schema.
- Your application must detect and handle the edge cases that can result in the model output not being a complete JSON object (see below)

Handling edge cases

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
we_did_not_specify_stop_tokens = True

try:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo-0125",
        messages=[\
            {"role": "system", "content": "You are a helpful assistant designed to output JSON."},\
            {"role": "user", "content": "Who won the world series in 2020? Please respond in the format {winner: ...}"}\
        ],
        response_format={"type": "json_object"}
    )

    # Check if the conversation was too long for the context window, resulting in incomplete JSON
    if response.choices[0].message.finish_reason == "length":
        # your code should handle this error case
        pass

    # Check if the OpenAI safety system refused the request and generated a refusal instead
    if response.choices[0].message[0].get("refusal"):
        # your code should handle this error case
        # In this case, the .content field will contain the explanation (if any) that the model generated for why it is refusing
        print(response.choices[0].message[0]["refusal"])

    # Check if the model's output included restricted content, so the generation of JSON was halted and may be partial
    if response.choices[0].message.finish_reason == "content_filter":
        # your code should handle this error case
        pass

    if response.choices[0].message.finish_reason == "stop":
        # In this case the model has either successfully finished generating the JSON object according to your schema, or the model generated one of the tokens you provided as a "stop token"

        if we_did_not_specify_stop_tokens:
            # If you didn't specify any stop tokens, then the generation is complete and the content key will contain the serialized JSON object
            # This will parse successfully and should now contain  "{"winner": "Los Angeles Dodgers"}"
            print(response.choices[0].message.content)
        else:
            # Check if the response.choices[0].message.content ends with one of your stop tokens and handle appropriately
            pass
except Exception as e:
    # Your code should handle errors here, for example a network error calling the API
    print(e)
```

## Resources

To learn more about Structured Outputs, we recommend browsing the following resources:

- Check out our [introductory cookbook](https://cookbook.openai.com/examples/structured_outputs_intro) on Structured Outputs
- Learn [how to build multi-agent systems](https://cookbook.openai.com/examples/structured_outputs_multi_agent) with Structured OutputsLog in [Sign up](/signup)

# Function calling

Copy page

Connect models to external data and systems.

**Function calling** enables developers to connect language models to external data and systems.
You can define a set of functions as tools that the model has access to, and it can use them when appropriate based on the conversation history.
You can then execute those functions on the application side, and provide results back to the model.

Learn how to extend the capabilities of OpenAI models through function calling in this guide.

Experiment with function calling in the [Playground](/playground) by providing your own function definition or generate a ready-to-use definition.

Generate

## Overview

Many applications require models to call custom functions to trigger actions within the application or interact with external systems.

Here is how you can define a function as a tool for the model to use:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
from openai import OpenAI

client = OpenAI()

tools = [\
    {\
        "type": "function",\
        "function": {\
            "name": "get_weather",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "location": {"type": "string"},\
                    "unit": {"type": "string", "enum": ["c", "f"]},\
                },\
                "required": ["location", "unit"],\
                "additionalProperties": False,\
            },\
        },\
    }\
]

completion = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "What's the weather like in Paris today?"}],
    tools=tools,
)

print(completion.choices[0].message.tool_calls)
```

Functions are the only type of tools supported in the Chat Completions API, but the Assistants API also supports [built-in tools](/docs/assistants/tools).

Here are a few examples where function calling can be useful:

1. **Fetching data:** enable a conversational assistant to retrieve data from internal systems before responding to the user.
2. **Taking action:** allow an assistant to trigger actions based on the conversation, like scheduling meetings or initiating order returns.
3. **Building rich workflows:** allow assistants to execute multi-step workflows, like data extraction pipelines or content personalization.
4. **Interacting with Application UIs:** use function calls to update the user interface based on user input, like rendering a pin on a map or navigating a website.

You can find example use cases in the [examples](#examples) section below.

### The lifecycle of a function call

When you use the OpenAI API with function calling, the model never actually executes functions itself - instead, it simply generates parameters that can be used to call your function.
You are then responsible for handling how the function is executed in your code.

Read our [integration guide](#integration-guide) below for more details on how to handle function calls.

![Function Calling diagram](https://cdn.openai.com/API/docs/images/function-calling-diagram.png)

### Function calling support

Function calling is supported in the [Chat Completions API](/docs/guides/text-generation), [Assistants API](/docs/assistants/overview), [Batch API](/docs/guides/batch) and [Realtime API](/docs/guides/realtime).

This guide focuses on function calling using the Chat Completions API. We have separate guides for [function calling using the Assistants API](/docs/assistants/tools/function-calling), and for [function calling using the Realtime API](/docs/guides/realtime#tool-calling).

#### Models supporting function calling

Function calling was introduced with the release of `gpt-4-turbo` on June 13, 2023. All `gpt-*` models released after this date support function calling.

Legacy models released before this date were not trained to support function calling.

Support for parallel function calling

Parallel function calling is supported on models released on or after Nov 6, 2023. This includes: `gpt-4o`, `gpt-4o-2024-08-06`, `gpt-4o-2024-05-13`, `gpt-4o-mini`, `gpt-4o-mini-2024-07-18`, `gpt-4-turbo`, `gpt-4-turbo-2024-04-09`, `gpt-4-turbo-preview`, `gpt-4-0125-preview`, `gpt-4-1106-preview`, `gpt-3.5-turbo`, `gpt-3.5-turbo-0125`, and `gpt-3.5-turbo-1106`.

You can find a complete list of models and their release date on our [models page](/docs/models).

## Integration guide

In this integration guide, we will walk through integrating function calling into an application, taking an order delivery assistant as an example.
Rather than requiring users to interact with a form, we can let them ask the assistant for help in natural language.

We will cover how to define functions and instructions, then how to handle model responses and function execution results.

If you want to learn more about how to handle function calls in a streaming fashion, how to customize tool calling behavior or how to handle edge cases, refer to our [advanced usage](#advanced-usage) section.

### Function definition

The starting point for function calling is choosing a function in your own codebase that you'd like to enable the model to generate arguments for.

For this example, let's imagine you want to allow the model to call the `get_delivery_date` function in your codebase which accepts an `order_id` and queries your database to determine the delivery date for a given package.
Your function might look something like the following:

python

```python
1
2
3
4
5
6
# This is the function that we want the model to be able to call
def get_delivery_date(order_id: str) -> datetime:
    # Connect to the database
    conn = sqlite3.connect('ecommerce.db')
    cursor = conn.cursor()
    # ...
```

Now that we know which function we wish to allow the model to call, we will create a “function definition” that describes the function to the model. This definition describes both what the function does (and potentially when it should be called) and what parameters are required to call the function.

The `parameters` section of your function definition should be described using JSON Schema. If and when the model generates a function call, it will use this information to generate arguments according to your provided schema.

If you want to ensure the model always adheres to your supplied schema, you can enable [Structured Outputs](#structured-outputs) with function calling.

In this example it may look like this:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
    "name": "get_delivery_date",
    "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",
    "parameters": {
        "type": "object",
        "properties": {
            "order_id": {
                "type": "string",
                "description": "The customer's order ID."
            }
        },
        "required": ["order_id"],
        "additionalProperties": false
    }
}
```

Next we need to provide our function definitions within an array of available “tools” when calling the Chat Completions API.

As always, we will provide an array of “messages”, which could for example contain your prompt or a back and forth conversation between the user and an assistant.

This example shows how you may call the Chat Completions API providing relevant tools and messages for an assistant that handles customer inquiries for a store.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
tools = [\
    {\
        "type": "function",\
        "function": {\
            "name": "get_delivery_date",\
            "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "order_id": {\
                        "type": "string",\
                        "description": "The customer's order ID.",\
                    },\
                },\
                "required": ["order_id"],\
                "additionalProperties": False,\
            },\
        }\
    }\
]

messages = [\
    {\
        "role": "system",\
        "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."\
    },\
    {\
        "role": "user",\
        "content": "Hi, can you tell me the delivery date for my order?"\
    }\
]

response = openai.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    tools=tools,
)
```

### Model instructions

While you should define in the function definitions how to call them, we recommend including instructions regarding when to call functions in the system prompt.

For example, you can tell the model when to use the function by saying something like:
`"Use the 'get_delivery_date' function when the user asks about their delivery date."`

### Handling model responses

The model only suggests function calls and generates arguments for the defined functions when appropriate.
It is then up to you to decide how your application handles the execution of the functions based on these suggestions.

If the model determines that a function should be called, it will return a `tool_calls` field in the response, which you can use to determine if the model generated a function call and what the arguments were.

Unless you customize the tool calling behavior, the model will determine when to call functions based on the instructions and conversation.

Read the [Tool calling behavior](#tool-calling-behavior) section below for more details on how you can force the model to call one or several tools.

#### If the model decides that no function should be called

If the model does not generate a function call, then the response will contain a direct reply to the user as a regular chat completion response.

For example, in this case `chat_response.choices[0].message` may contain:

python

```python
1
2
3
4
5
6
chat.completionsMessage(
    content='Hi there! I can help with that. Can you please provide your order ID?',
    role='assistant',
    function_call=None,
    tool_calls=None
)
```

In an assistant use case you will typically want to show this response to the user and let them respond to it, in which case you will call the API again (with both the latest responses from the assistant and user appended to the `messages`).

Let's assume our user responded with their order id, and we sent the following request to the API.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
tools = [\
    {\
        "type": "function",\
        "function": {\
            "name": "get_delivery_date",\
            "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "order_id": {\
                        "type": "string",\
                        "description": "The customer's order ID."\
                    }\
                },\
                "required": ["order_id"],\
                "additionalProperties": False\
            }\
        }\
    }\
]

messages = []
messages.append({"role": "system", "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."})
messages.append({"role": "user", "content": "Hi, can you tell me the delivery date for my order?"})
messages.append({"role": "assistant", "content": "Hi there! I can help with that. Can you please provide your order ID?"})
messages.append({"role": "user", "content": "i think it is order_12345"})

response = client.chat.completions.create(
    model='gpt-4o',
    messages=messages,
    tools=tools
)
```

#### If the model generated a function call

If the model generated a function call, it will generate the arguments for the call (based on the `parameters` definition you provided).

Here is an example response showing this:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
Choice(
    finish_reason='tool_calls',
    index=0,
    logprobs=None,
    message=chat.completionsMessage(
        content=None,
        role='assistant',
        function_call=None,
        tool_calls=[\
            chat.completionsMessageToolCall(\
                id='call_62136354',\
                function=Function(\
                    arguments='{"order_id":"order_12345"}',\
                    name='get_delivery_date'),\
                type='function')\
        ])
)
```

#### Handling the model response indicating that a function should be called

Assuming the response indicates that a function should be called, your code will now handle this:

python

```python
1
2
3
4
5
6
7
8
9
10
# Extract the arguments for get_delivery_date
# Note this code assumes we have already determined that the model generated a function call. See below for a more production ready example that shows how to check if the model generated a function call
tool_call = response.choices[0].message.tool_calls[0]
arguments = json.loads(tool_call['function']['arguments'])

order_id = arguments.get('order_id')

# Call the get_delivery_date function with the extracted order_id

delivery_date = get_delivery_date(order_id)
```

### Submitting function output

Once the function has been executed in the code, you need to submit the result of the function call back to the model.

This will trigger another model response, taking into account the function call result.

For example, this is how you can commit the result of the function call to a conversation history:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
# Simulate the order_id and delivery_date
order_id = "order_12345"
delivery_date = datetime.now()

# Simulate the tool call response

response = {
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "tool_calls": [\
                    {\
                        "id": "call_62136354",\
                        "type": "function",\
                        "function": {\
                            "arguments": "{'order_id': 'order_12345'}",\
                            "name": "get_delivery_date"\
                        }\
                    }\
                ]\
            }\
        }\
    ]
}

# Create a message containing the result of the function call

function_call_result_message = {
    "role": "tool",
    "content": json.dumps({
        "order_id": order_id,
        "delivery_date": delivery_date.strftime('%Y-%m-%d %H:%M:%S')
    }),
    "tool_call_id": response['choices'][0]['message']['tool_calls'][0]['id']
}

# Prepare the chat completion call payload

completion_payload = {
    "model": "gpt-4o",
    "messages": [\
        {"role": "system", "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."},\
        {"role": "user", "content": "Hi, can you tell me the delivery date for my order?"},\
        {"role": "assistant", "content": "Hi there! I can help with that. Can you please provide your order ID?"},\
        {"role": "user", "content": "i think it is order_12345"},\
        response['choices'][0]['message'],\
        function_call_result_message\
    ]
}

# Call the OpenAI API's chat completions endpoint to send the tool call result back to the model

response = openai.chat.completions.create(
    model=completion_payload["model"],
    messages=completion_payload["messages"]
)

# Print the response from the API. In this case it will typically contain a message such as "The delivery date for your order #12345 is xyz. Is there anything else I can help you with?"

print(response)
```

Note that an assistant message containing tool calls should always be followed by tool response messages (one per tool call).
Making an API call with a messages array that does not follow this pattern will result in an error.

## Structured Outputs

In August 2024, we launched Structured Outputs, which ensures that a model's output exactly matches a specified JSON schema.

By default, when using function calling, the API will offer best-effort matching for your parameters, which means that occasionally the model may miss parameters or get their types wrong when using complicated schemas.

You can enable Structured Outputs for function calling by setting the parameter `strict: true` in your function definition.
When this is enabled, the function arguments generated by the model will be constrained to match the JSON Schema provided in the function definition.

As an alternative to function calling you can instead constrain the model's regular output to match a JSON Schema of your choosing. [Learn more](/docs/guides/structured-outputs#function-calling-vs-response-format) about when to use function calling vs when to control the model's normal output by using `response_format`.

### Parallel function calling and Structured Outputs

When the model outputs multiple function calls via parallel function calling, model outputs may not match strict schemas supplied in tools.

In order to ensure strict schema adherence, disable parallel function calls by supplying `parallel_tool_calls: false`. With this setting, the model will generate one function call at a time.

### Why might I not want to turn on Structured Outputs?

The main reasons to not use Structured Outputs are:

- If you need to use some feature of JSON Schema that is not yet supported ( [learn more](/docs/guides/structured-outputs#supported-schemas)), for example recursive schemas.
- If each of your API requests includes a novel schema (i.e. your schemas are not fixed, but are generated on-demand and rarely repeat). The first request with a novel JSON schema will have increased latency as the schema is pre-processed and cached for future generations to constrain the output of the model.

### What does Structured Outputs mean for Zero Data Retention?

When Structured Outputs is turned on, schemas provided are not eligible for [zero data retention](/docs/models#how-we-use-your-data).

### Supported schemas

Function calling with Structured Outputs supports a subset of the JSON Schema language.

For more information on supported schemas, see the [Structured Outputs guide](/docs/guides/structured-outputs#supported-schemas).

### Example

You can use zod in nodeJS and Pydantic in python when using the SDKs to pass your function definitions to the model.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
from enum import Enum
from typing import Union
from pydantic import BaseModel
import openai
from openai import OpenAI

client = OpenAI()

class GetDeliveryDate(BaseModel):
    order_id: str

tools = [openai.pydantic_function_tool(GetDeliveryDate)]

messages = []
messages.append({"role": "system", "content": "You are a helpful customer support assistant. Use the supplied tools to assist the user."})
messages.append({"role": "user", "content": "Hi, can you tell me the delivery date for my order #12345?"})

response = client.beta.chat.completions.create(
    model='gpt-4o-2024-08-06',
    messages=messages,
    tools=tools
)

print(response.choices[0].message.tool_calls[0].function)
```

If you are not using the SDKs, simply add the `strict: true` parameter to your function definition:

```json
1
2
3
4
5
6
7
8
9
10
11
{
    "name": "get_delivery_date",
    "description": "Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks \\"Where is my package\\"",
    "parameters": {
        "type": "object",
        "properties": {
            "order_id": { "type": "string" }
        },
        "strict": true
    }
}
```

### Limitations

When you use Structured Outputs with function calling, the model will always follow your exact schema, except in a few circumstances:

- When the model's response is cut off (either due to `max_tokens`, `stop_tokens`, or maximum context length)
- When a model [refusal](/docs/guides/structured-outputs#refusals) happens
- When there is a `content_filter` finish reason

Note that the first time you send a request with a new schema using Structured
Outputs, there will be additional latency as the schema is processed, but subsequent
requests should incur no overhead.

## Advanced usage

### Streaming tool calls

You can stream tool calls and process function arguments as they are being generated.
This is especially useful if you want to display the function arguments in your UI, or if you don't need to wait for the whole function parameters to be generated before executing the function.

To enable streaming tool calls, you can set `stream: true` in your request.
You can then process the streaming delta and check for any new tool calls delta.

You can find more information on streaming in the [API reference](/docs/api-reference/streaming).

Here is an example of how you can handle streaming tool calls with the node and python SDKs:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
from openai import OpenAI
import json

client = OpenAI()

# Define functions
tools = [\
    {\
        "type": "function",\
        "function": {\
            "name": "generate_recipe",\
            "description": "Generate a recipe based on the user's input",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "title": {\
                        "type": "string",\
                        "description": "Title of the recipe.",\
                    },\
                    "ingredients": {\
                        "type": "array",\
                        "items": {"type": "string"},\
                        "description": "List of ingredients required for the recipe.",\
                    },\
                    "instructions": {\
                        "type": "array",\
                        "items": {"type": "string"},\
                        "description": "Step-by-step instructions for the recipe.",\
                    },\
                },\
                "required": ["title", "ingredients", "instructions"],\
                "additionalProperties": False,\
            },\
        },\
    }\
]

response_stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[\
        {\
            "role": "system",\
            "content": (\
                "You are an expert cook who can help turn any user input into a delicious recipe."\
                "As soon as the user tells you what they want, use the generate_recipe tool to create a detailed recipe for them."\
            ),\
        },\
        {\
            "role": "user",\
            "content": "I want to make pancakes for 4.",\
        },\
    ],
    tools=tools,
    stream=True,
)

function_arguments = ""
function_name = ""
is_collecting_function_args = False

for part in response_stream:
    delta = part.choices[0].delta
    finish_reason = part.choices[0].finish_reason

    # Process assistant content
    if 'content' in delta:
        print("Assistant:", delta.content)

    if delta.tool_calls:
        is_collecting_function_args = True
        tool_call = delta.tool_calls[0]

        if tool_call.function.name:
            function_name = tool_call.function.name
            print(f"Function name: '{function_name}'")

        # Process function arguments delta
        if tool_call.function.arguments:
            function_arguments += tool_call.function.arguments
            print(f"Arguments: {function_arguments}")

    # Process tool call with complete arguments
    if finish_reason == "tool_calls" and is_collecting_function_args:
        print(f"Function call '{function_name}' is complete.")
        args = json.loads(function_arguments)
        print("Complete function arguments:")
        print(json.dumps(args, indent=2))

        # Reset for the next potential function call
        function_arguments = ""
        function_name = ""
        is_collecting_function_args = False
```

### Tool calling behavior

The API supports advanced features such as parallel tool calling and the ability to force tool calls.

You can disable parallel tool calling by setting `parallel_tool_calls: false`.

Parallel tool calling

Any models released on or after Nov 6, 2023 may by default generate multiple tool calls in a single response, indicating that they should be called in parallel.

This is especially useful if executing the given functions takes a long time. For example, the model may call functions to get the weather in 3 different locations at the same time, which will result in a message with 3 function calls in the tool\_calls array.

Example response:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
response = Choice(
    finish_reason='tool_calls',
    index=0,
    logprobs=None,
    message=chat.completionsMessage(
        content=None,
        role='assistant',
        function_call=None,
        tool_calls=[\
            chat.completionsMessageToolCall(\
                id='call_62136355',\
                function=Function(\
                    arguments='{"city":"New York"}',\
                    name='check_weather'),\
                type='function'),\
            chat.completionsMessageToolCall(\
                id='call_62136356',\
                function=Function(\
                    arguments='{"city":"London"}',\
                    name='check_weather'),\
                type='function'),\
            chat.completionsMessageToolCall(\
                id='call_62136357',\
                function=Function(\
                    arguments='{"city":"Tokyo"}',\
                    name='check_weather'),\
                type='function')\
        ])
)

# Iterate through tool calls to handle each weather check

for tool_call in response.message.tool_calls:
    arguments = json.loads(tool_call.function.arguments)
    city = arguments['city']
    weather_info = check_weather(city)
    print(f"Weather in {city}: {weather_info}")
```

Each function call in the array has a unique `id`.

Once you've executed these function calls in your application, you can provide the result back to the model by adding one new message to the conversation for each function call, each containing the result of one function call, with a `tool_call_id` referencing the `id` from `tool_calls`, for example:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
# Assume we have fetched the weather data from somewhere
weather_data = {
    "New York": {"temperature": "22°C", "condition": "Sunny"},
    "London": {"temperature": "15°C", "condition": "Cloudy"},
    "Tokyo": {"temperature": "25°C", "condition": "Rainy"}
}

# Prepare the chat completion call payload with inline function call result creation
completion_payload = {
    "model": "gpt-4o",
    "messages": [\
        {"role": "system", "content": "You are a helpful assistant providing weather updates."},\
        {"role": "user", "content": "Can you tell me the weather in New York, London, and Tokyo?"},\
        # Append the original function calls to the conversation\
        response['message'],\
        # Include the result of the function calls\
        {\
            "role": "tool",\
            "content": json.dumps({\
                "city": "New York",\
                "weather": weather_data["New York"]\
            }),\
            # Here we specify the tool_call_id that this result corresponds to\
            "tool_call_id": response['message']['tool_calls'][0]['id']\
        },\
        {\
            "role": "tool",\
            "content": json.dumps({\
                "city": "London",\
                "weather": weather_data["London"]\
            }),\
            "tool_call_id": response['message']['tool_calls'][1]['id']\
        },\
        {\
            "role": "tool",\
            "content": json.dumps({\
                "city": "Tokyo",\
                "weather": weather_data["Tokyo"]\
            }),\
            "tool_call_id": response['message']['tool_calls'][2]['id']\
        }\
    ]
}

# Call the OpenAI API's chat completions endpoint to send the tool call result back to the model
response = openai.chat.completions.create(
    model=completion_payload["model"],
    messages=completion_payload["messages"]
)

# Print the response from the API, which will return something like "In New York the weather is..."
print(response)
```

Forcing tool calls

By default, the model is configured to automatically select which tools to call, as determined by the `tool_choice: "auto"` setting.

We offer three ways to customize the default behavior:

1. To force the model to always call one or more tools, you can set `tool_choice: "required"`. The model will then always select one or more tool(s) to call.
This is useful for example if you want the model to pick between multiple actions to perform next
2. To force the model to call a specific function, you can set `tool_choice: {"type": "function", "function": {"name": "my_function"}}`
3. To disable function calling and force the model to only generate a user-facing message, you can either provide no tools, or set `tool_choice: "none"`

Note that if you do either 1 or 2 (i.e. force the model to call a function) then the subsequent `finish_reason` will be `"stop"` instead of being `"tool_calls"`.

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
from openai import OpenAI

client = OpenAI()

tools = [\
    {\
        "type": "function",\
        "function": {\
            "name": "get_weather",\
            "strict": True,\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "location": {"type": "string"},\
                    "unit": {"type": "string", "enum": ["c", "f"]},\
                },\
                "required": ["location", "unit"],\
                "additionalProperties": False,\
            },\
        },\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "get_stock_price",\
            "strict": True,\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "symbol": {"type": "string"},\
                },\
                "required": ["symbol"],\
                "additionalProperties": False,\
            },\
        },\
    },\
]

messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
completion = client.chat.completions.create(
    model="gpt-4o",
    messages=messages,
    tools=tools,
    tool_choice="required"
)

print(completion)
```

To see a practical example of how to force tool calls, see our cookbook:

[Customer service with tool required\\
\\
Learn how to add an element of determinism to your customer service assistant](https://cookbook.openai.com/examples/using_tool_required_for_customer_service)

### Edge cases

We recommend using the SDK to handle the edge cases described below. If for any reason
you cannot use the SDK, you should handle these cases in your code.

When you receive a response from the API, if you're not using the SDK, there are a number of edge cases that production code should handle.

In general, the API will return a valid function call, but there are some edge cases when this won't happen:

- When you have specified `max_tokens` and the model's response is cut off as a result
- When the model's output includes copyrighted material

Also, when you force the model to call a function, the `finish_reason` will be `"stop"` instead of `"tool_calls"`.

This is how you can handle these different cases in your code:

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
# Check if the conversation was too long for the context window
if response['choices'][0]['message']['finish_reason'] == "length":
    print("Error: The conversation was too long for the context window.")
    # Handle the error as needed, e.g., by truncating the conversation or asking for clarification
    handle_length_error(response)

# Check if the model's output included copyright material (or similar)
if response['choices'][0]['message']['finish_reason'] == "content_filter":
    print("Error: The content was filtered due to policy violations.")
    # Handle the error as needed, e.g., by modifying the request or notifying the user
    handle_content_filter_error(response)

# Check if the model has made a tool_call. This is the case either if the "finish_reason" is "tool_calls" or if the "finish_reason" is "stop" and our API request had forced a function call
if (response['choices'][0]['message']['finish_reason'] == "tool_calls" or
    # This handles the edge case where if we forced the model to call one of our functions, the finish_reason will actually be "stop" instead of "tool_calls"
    (our_api_request_forced_a_tool_call and response['choices'][0]['message']['finish_reason'] == "stop")):
    # Handle tool call
    print("Model made a tool call.")
    # Your code to handle tool calls
    handle_tool_call(response)

# Else finish_reason is "stop", in which case the model was just responding directly to the user
elif response['choices'][0]['message']['finish_reason'] == "stop":
    # Handle the normal stop case
    print("Model responded directly to the user.")
    # Your code to handle normal responses
    handle_normal_response(response)

# Catch any other case, this is unexpected
else:
    print("Unexpected finish_reason:", response['choices'][0]['message']['finish_reason'])
    # Handle unexpected cases as needed
    handle_unexpected_case(response)
```

### Token usage

Under the hood, functions are injected into the system message in a syntax the model has been trained on. This means functions count against the model's context limit and are billed as input tokens. If you run into token limits, we suggest limiting the number of functions or the length of the descriptions you provide for function parameters.

It is also possible to use fine-tuning to reduce the number of tokens used if you have many functions defined in your tools specification.

## Examples

The [OpenAI Cookbook](https://cookbook.openai.com/) has several end-to-end examples to help you implement function calling.

In our introductory cookbook [how to call functions with chat models](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models), we outline two examples of how the models can use function calling. This is a great resource to follow as you get started:

[Function calling\\
\\
Learn from more examples demonstrating function calling](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)

You will also find examples of function definitions for common use cases below.

Shopping Assistant

#### Scenario

A shopping assistant helps users navigate an e-commerce site.
It needs to fetch product data from a structured database, and suggest recommendations based on the user's query.
Once the user has found a product they are interested in, the assistant can add it to the shopping cart on their behalf.

#### Function definitions

To recommend products to the user, the assistant needs to query the products database.
To find more details about a product, such as reviews and additional information (e.g. materials, dimensions...), the assistant needs to fetch more information on the specific product.
It also needs a tool to add items to the shopping cart.

We will then define the following functions:

- `get_product_recommendations`: Recommends products based on filters
- `get_product_details`: Fetches more details about a product
- `add_to_cart`: Adds a product to the shopping cart

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
[\
    {\
        "type": "function",\
        "function": {\
            "name": "get_product_recommendations",\
            "description": "Searches for products matching certain criteria in the database",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "categories": {\
                        "description": "categories that could be a match",\
                        "type": "array",\
                        "items": {\
                            "type": "string",\
                            "enum": [\
                                "coats & jackets",\
                                "accessories",\
                                "tops",\
                                "jeans & trousers",\
                                "skirts & dresses",\
                                "shoes"\
                            ]\
                        }\
                    },\
                    "colors": {\
                        "description": "colors that could be a match, empty array if N/A",\
                        "type": "array",\
                        "items": {\
                            "type": "string",\
                            "enum": [\
                                "black",\
                                "white",\
                                "brown",\
                                "red",\
                                "blue",\
                                "green",\
                                "orange",\
                                "yellow",\
                                "pink",\
                                "gold",\
                                "silver"\
                            ]\
                        }\
                    },\
                    "keywords": {\
                        "description": "keywords that should be present in the item title or description",\
                        "type": "array",\
                        "items": {\
                            "type": "string"\
                        }\
                    },\
                    "price_range": {\
                        "type": "object",\
                        "properties": {\
                            "min": {\
                                "type": "number"\
                            },\
                            "max": {\
                                "type": "number"\
                            }\
                        },\
                        "required": [\
                        "min",\
                        "max"\
                        ],\
                        "additionalProperties": false\
                    },\
                    "limit": {\
                        "type": "integer",\
                        "description": "The maximum number of products to return, use 5 by default if nothing is specified by the user"\
                    }\
                },\
                "required": [\
                    "categories",\
                    "colors",\
                    "keywords",\
                    "price_range",\
                    "limit"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "get_product_details",\
            "description": "Fetches more details about a product",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "product_id": {\
                        "type": "string",\
                        "description": "The ID of the product to fetch details for"\
                    }\
                },\
                "required": [\
                    "product_id"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "add_to_cart",\
            "description": "Add items to cart when the user has confirmed their interest.",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "items": {\
                        "type": "array",\
                        "items": {\
                            "type": "object",\
                            "properties": {\
                                "product_id": {\
                                    "type": "string",\
                                    "description": "ID of the product to add to the cart"\
                                },\
                                "quantity": {\
                                    "type": "integer",\
                                    "description": "Quantity of the product to add to the cart"\
                                }\
                            },\
                            "required": [\
                                "product_id",\
                                "quantity"\
                            ],\
                            "additionalProperties": false\
                        }\
                    },\
                    "required": [\
                        "items"\
                    ],\
                    "additionalProperties": false\
                }\
            }\
        }\
    }\
]
```

Customer Service Agent

#### Scenario

A customer service assistant on an e-commerce site helps users after they have made a purchase.
It can answer questions about their orders or the company policy regarding returns and refunds.
It can also help customers process a return and give status updates.

#### Function definitions

To answer questions about orders, the assistant needs to fetch order details from the orders database.
In case the user doesn't know their order number, the assistant should also be able to fetch the last orders for a given user.
It should also be able to search the FAQ to respond to general questions.
Lastly, it should be equipped with tools to process returns and find a return status.

We will then define the following functions:

- `get_order_details`: Fetches details about a specific order
- `get_user_orders`: Fetches the last orders for a given user
- `search_faq`: Searches the FAQ for an answer to the user's question
- `process_return`: Processes a return and creates a return label
- `get_return_status`: Finds the status of a return

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
[\
    {\
        "type": "function",\
        "function": {\
            "name": "get_order_details",\
            "description": "Fetches details about a specific order",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "order_id": {\
                        "type": "string",\
                        "description": "The ID of the order to fetch details for"\
                    }\
                },\
                "required": [\
                    "order_id"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "get_user_orders",\
            "description": "Fetches the last orders for a given user",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "user_id": {\
                        "type": "string",\
                        "description": "The ID of the user to fetch orders for"\
                    },\
                    "limit": {\
                        "type": "integer",\
                        "description": "The maximum number of orders to return, use 5 by default and increase the number if the relevant order is not found."\
                    }\
                },\
                "required": [\
                    "user_id", "limit"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "search_faq",\
            "description": "Searches the FAQ for an answer to the user's question",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "query": {\
                        "type": "string",\
                        "description": "The question to search the FAQ for"\
                    }\
                },\
                "required": [\
                    "query"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "process_return",\
            "description": "Processes a return and creates a return label",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "order_id": {\
                        "type": "string",\
                        "description": "The ID of the order to process a return for"\
                    },\
                    "items": {\
                        "type": "array",\
                        "description": "The items to return",\
                        "items": {\
                            "type": "object",\
                            "properties": {\
                                "product_id": {\
                                    "type": "string",\
                                    "description": "The ID of the product to return"\
                                },\
                                "quantity": {\
                                    "type": "integer",\
                                    "description": "The quantity of the product to return"\
                                }\
                            },\
                            "required": [\
                                "product_id",\
                                "quantity"\
                            ],\
                            "additionalProperties": false\
                        }\
                    }\
                },\
                "required": [\
                    "order_id",\
                    "items"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "get_return_status",\
            "description": "Finds the status of a return",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "order_id": {\
                        "type": "string",\
                        "description": "The ID of the order to fetch the return status for"\
                    }\
                },\
                "required": [\
                    "order_id"\
                ],\
                "additionalProperties": false\
            }\
        }\
    }\
]
```

Interactive Booking Experience

#### Scenario

A user is on an interactive website to find a place to eat or stay.
After they mention their preferences, the website updates to show recommendations on a map.
Once they have found a place they are interested in, a booking is programmatically made on their behalf.

#### Function definitions

To be able to show recommendations, the app needs to first fetch recommendations based on the user's preferences,
and then pin those recommendations on the map.
To book a place, the assistant needs to fetch the availability of the place, and then create a booking on the user's behalf.

We will then define the following functions:

- `get_recommendations`: Fetche recommendations based on the user's preferences
- `show_on_map`: Place pins on the map
- `fetch_availability`: Fetch the availability for a given place
- `create_booking`: Create a booking on the user's behalf

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
[\
    {\
        "type": "function",\
        "function": {\
            "name": "get_recommendations",\
            "description": "Fetches recommendations based on the user's preferences",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "type": {\
                        "type": "string",\
                        "description": "The type of place to search recommendations for",\
                        "enum": ["restaurant", "hotel"]\
                    },\
                    "keywords": {\
                        "type": "array",\
                        "description": "Keywords that should be present in the recommendations",\
                        "items": {\
                            "type": "string"\
                        }\
                    },\
                    "location": {\
                        "type": "string",\
                        "description": "The location to search recommendations for"\
                    }\
                },\
                "required": [\
                    "type",\
                    "keywords",\
                    "location"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "show_on_map",\
            "description": "Places pins on the map for relevant locations",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "pins": {\
                        "type": "array",\
                        "description": "The pins to place on the map",\
                        "items": {\
                            "type": "object",\
                            "properties": {\
                                "name": {\
                                    "type": "string",\
                                    "description": "The name of the place"\
                                },\
                                "coordinates": {\
                                    "type": "object",\
                                    "properties": {\
                                        "latitude": { "type": "number" },\
                                        "longitude": { "type": "number" }\
                                    },\
                                    "required": [\
                                        "latitude",\
                                        "longitude"\
                                    ],\
                                    "additionalProperties": false\
                                }\
                            },\
                            "required": [\
                                "name",\
                                "coordinates"\
                            ],\
                            "additionalProperties": false\
                        }\
                    }\
                },\
                "required": [\
                    "pins"\
                ],\
                "additionalProperties": false\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "fetch_availability",\
            "description": "Fetches the availability for a given place",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "place_id": {\
                        "type": "string",\
                        "description": "The ID of the place to fetch availability for"\
                    }\
                }\
            }\
        }\
    },\
    {\
        "type": "function",\
        "function": {\
            "name": "create_booking",\
            "description": "Creates a booking on the user's behalf",\
            "parameters": {\
                "type": "object",\
                "properties": {\
                    "place_id": {\
                        "type": "string",\
                        "description": "The ID of the place to create a booking for"\
                    },\
                    "booking_details": {\
                        "anyOf": [\
                            {\
                                "type": "object",\
                                "description": "Restaurant booking with specific date and time",\
                                "properties": {\
                                    "date": {\
                                        "type": "string",\
                                        "description": "The date of the booking, in format YYYY-MM-DD"\
                                    },\
                                    "time": {\
                                        "type": "string",\
                                        "description": "The time of the booking, in format HH:MM"\
                                    }\
                                },\
                                "required": [\
                                    "date",\
                                    "time"\
                                ]\
                            },\
                            {\
                                "type": "object",\
                                "description": "Hotel booking with specific check-in and check-out dates",\
                                "properties": {\
                                    "check_in": {\
                                        "type": "string",\
                                        "description": "The check-in date of the booking, in format YYYY-MM-DD"\
                                    },\
                                    "check_out": {\
                                        "type": "string",\
                                        "description": "The check-out date of the booking, in format YYYY-MM-DD"\
                                    }\
                                },\
                                "required": [\
                                    "check_in",\
                                    "check_out"\
                                ]\
                            }\
                        ]\
                    }\
                },\
                "required": [\
                    "place_id",\
                    "booking_details"\
                ],\
                "additionalProperties": false\
            }\
        }\
    }\
]
```

## Best practices

### Turn on Structured Outputs by setting `strict: "true"`

When Structured Outputs is turned on, the arguments generated by the model for function calls will reliably match the JSON Schema that you provide.

If you are not using Structured Outputs, then the structure of arguments is not guaranteed to be correct, so we recommend the use of a validation library like Pydantic to first verify the arguments prior to using them.

### Name functions intuitively, with detailed descriptions

If you find the model does not generate calls to the correct functions, you may need to update your function names and descriptions so the model more clearly understands when it should select each function. Avoid using abbreviations or acronyms to shorten function and argument names.

You can also include detailed descriptions for when a function should be called. For complex functions, you should include descriptions for each of the arguments to help the model know what it needs to ask the user to collect that argument.

### Name function parameters intuitively, with detailed descriptions

Use clear and descriptive names for function parameters. If applicable, specify the expected format for a parameter in the description (e.g., YYYY-mm-dd or dd/mm/yy for a date).

### Consider providing additional information about how and when to call functions in your system message

Providing clear instructions in your system message can significantly improve the model's function calling accuracy. For example, guide the model with instructions like the following:

`"Use check_order_status when the user inquires about the status of their order, such as 'Where is my order?' or 'Has my order shipped yet?'".`

Provide context for complex scenarios. For example:

`"Before scheduling a meeting with schedule_meeting, check the user's calendar for availability using check_availability to avoid conflicts."`

### Use enums for function arguments when possible

If your use case allows, you can use enums to constrain the possible values for arguments. This can help reduce hallucinations.

For example, if you have an AI assistant that helps with ordering a T-shirt, you likely have a fixed set of sizes for the T-shirt that you might want to constrain the model to choose from. If you want the model to output “s”, “m”, “l”, for small, medium, and large, you could provide those values in an enum, like this:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "name": "pick_tshirt_size",
    "description": "Call this if the user specifies which size t-shirt they want",
    "parameters": {
        "type": "object",
        "properties": {
            "size": {
                "type": "string",
                "enum": ["s", "m", "l"],
                "description": "The size of the t-shirt that the user would like to order"
            }
        },
        "required": ["size"],
        "additionalProperties": false
    }
}
```

If you don't constrain the output, a user may say “large” or “L”, and the model may use these values as a parameter.
As your code may expect a specific structure, it's helpful to limit the possible values the model can choose from.

### Keep the number of functions low for higher accuracy

We recommend that you use no more than 20 tools in a single API call.

Developers typically see a reduction in the model's ability to select the correct tool once they have between 10-20 tools defined.

If your use case requires the model to be able to pick between a large number of custom functions, you may want to explore fine-tuning ( [learn more](https://cookbook.openai.com/examples/fine_tuning_for_function_calling)) or break out the tools and group them logically to create a multi-agent system.

### Set up evals to act as an aid in prompt engineering your function definitions and system messages

We recommend for non-trivial uses of function calling setting up an evaluation system that allow you to measure how frequently the correct function is called or correct arguments are generated for a wide variety of possible user messages. Learn more about setting up evals on the [OpenAI Cookbook](https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals).

You can then use these to measure whether adjustments to your function definitions and system messages will improve or hurt your integration.

### Fine-tuning may help improve accuracy for function calling

Fine-tuning a model can improve performance at function calling for your use case, especially if you have a large number of functions, or complex, nuanced or similar functions.

See our fine-tuning for function calling [cookbook](https://cookbook.openai.com/examples/fine_tuning_for_function_calling) for more information.

[Fine-tuning for function calling\\
\\
Learn how to fine-tune a model for function calling](https://cookbook.openai.com/examples/fine_tuning_for_function_calling)Log in [Sign up](/signup)

# Tokenizer

### Learn about language model tokenization

OpenAI's large language models process text using **tokens**, which are common sequences of characters found in a set of text. The models learn to understand the statistical relationships between these tokens, and excel at producing the next token in a sequence of tokens. [Learn more](/docs/concepts/tokens).

You can use the tool below to understand how a piece of text might be tokenized by a language model, and the total count of tokens in that piece of text.

GPT-4o & GPT-4o miniGPT-3.5 & GPT-4GPT-3 (Legacy)

ClearShow example

Tokens

0

Characters

0

TextToken IDs

A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).

If you need a programmatic interface for tokenizing text, check out our [tiktoken](https://github.com/openai/tiktoken) package for Python. For JavaScript, the community-supported [@dbdq/tiktoken](https://www.npmjs.com/package/tiktoken) package works with most GPT models.Log in [Sign up](/signup)

# Prompt examples

Explore what's possible with some example prompts

All categories

Grammar correction

Convert ungrammatical statements into standard English.

Summarize for a 2nd grader

Simplify text to a level appropriate for a second-grade student.

Parse unstructured data

Create tables from unstructured text.

Emoji Translation

Translate regular text into emoji text.

Calculate time complexity

Find the time complexity of a function.

Explain code

Explain a complicated piece of code.

Keywords

Extract keywords from a block of text.

Product name generator

Generate product names from a description and seed words.

Python bug fixer

Find and fix bugs in source code.

Spreadsheet creator

Create spreadsheets of various kinds of data.

Tweet classifier

Detect sentiment in a tweet.

Airport code extractor

Extract airport codes from text.

Mood to color

Turn a text description into a color.

VR fitness idea generator

Generate ideas for fitness promoting virtual reality games.

Marv the sarcastic chat bot

Marv is a factual chatbot that is also sarcastic.

Turn by turn directions

Convert natural language to turn-by-turn directions.

Interview questions

Create interview questions.

Function from specification

Create a Python function from a specification.

Improve code efficiency

Provide ideas for efficiency improvements to Python code.

Single page website creator

Create a single page website.

Rap battle writer

Generate a rap battle between two characters.

Memo writer

Generate a company memo based on provided points.

Emoji chatbot

Generate conversational replies using emojis only.

Translation

Translate natural language text.

Socratic tutor

Generate responses as a Socratic tutor.

Natural language to SQL

Convert natural language into SQL queries.

Meeting notes summarizer

Summarize meeting notes including overall discussion, action items, and future topics.

Review classifier

Classify user reviews based on a set of tags.

Pro and con discusser

Analyze the pros and cons of a given topic.

Lesson plan writer

Generate a lesson plan for a specific topic.

Summarize for a 2nd grader

Extract

Natural Language

Simplify text to a level appropriate for a second-grade student.

Prompt

SYSTEM

Summarize content you are provided with for a second-grade student.

USER

Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.\[19\] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,\[20\] and is on average the third-brightest natural object in the night sky after the Moon and Venus.

Sample response

Jupiter is a really big planet in our Solar System. It is the fifth planet from the Sun and it is the largest planet. It is called a gas giant because it is made mostly of gas. Jupiter is much smaller than the Sun, but it is bigger than all the other planets combined. It is very bright and can be seen in the night sky without a telescope. People have known about Jupiter for a very long time, even before they started writing things down. It is named after a god from ancient Rome. Sometimes, Jupiter is so bright that it can make shadows on Earth. It is usually the third-brightest thing we can see in the night sky, after the Moon and Venus.

API request

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[\
    {\
      "role": "system",\
      "content": "Summarize content you are provided with for a second-grade student."\
    },\
    {\
      "role": "user",\
      "content": "Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus."\
    }\
  ],
  temperature=1,
  max_tokens=1024,
  top_p=1
)
```Log in [Sign up](/signup)

Page not found

We couldn't find the page you were looking for.

Was this expected?Log in [Sign up](/signup)

# Prompt examples

Explore what's possible with some example prompts

All categories

Grammar correction

Convert ungrammatical statements into standard English.

Summarize for a 2nd grader

Simplify text to a level appropriate for a second-grade student.

Parse unstructured data

Create tables from unstructured text.

Emoji Translation

Translate regular text into emoji text.

Calculate time complexity

Find the time complexity of a function.

Explain code

Explain a complicated piece of code.

Keywords

Extract keywords from a block of text.

Product name generator

Generate product names from a description and seed words.

Python bug fixer

Find and fix bugs in source code.

Spreadsheet creator

Create spreadsheets of various kinds of data.

Tweet classifier

Detect sentiment in a tweet.

Airport code extractor

Extract airport codes from text.

Mood to color

Turn a text description into a color.

VR fitness idea generator

Generate ideas for fitness promoting virtual reality games.

Marv the sarcastic chat bot

Marv is a factual chatbot that is also sarcastic.

Turn by turn directions

Convert natural language to turn-by-turn directions.

Interview questions

Create interview questions.

Function from specification

Create a Python function from a specification.

Improve code efficiency

Provide ideas for efficiency improvements to Python code.

Single page website creator

Create a single page website.

Rap battle writer

Generate a rap battle between two characters.

Memo writer

Generate a company memo based on provided points.

Emoji chatbot

Generate conversational replies using emojis only.

Translation

Translate natural language text.

Socratic tutor

Generate responses as a Socratic tutor.

Natural language to SQL

Convert natural language into SQL queries.

Meeting notes summarizer

Summarize meeting notes including overall discussion, action items, and future topics.

Review classifier

Classify user reviews based on a set of tags.

Pro and con discusser

Analyze the pros and cons of a given topic.

Lesson plan writer

Generate a lesson plan for a specific topic.

Explain code

Extract

Code

Explain a complicated piece of code.

Prompt

SYSTEM

You will be provided with a piece of code, and your task is to explain it in a concise way.

USER

class Log:
def \_\_init\_\_(self, path):
dirname = os.path.dirname(path)
os.makedirs(dirname, exist\_ok=True)
f = open(path, "a+")

# Check that the file is newline-terminated
size = os.path.getsize(path)
if size > 0:
f.seek(size - 1)
end = f.read(1)
if end != "\\n":
f.write("\\n")
self.f = f
self.path = path

def log(self, event):
event\["\_event\_id"\] = str(uuid.uuid4())
json.dump(event, self.f)
self.f.write("\\n")

def state(self):
state = {"complete": set(), "last": None}
for line in open(self.path):
event = json.loads(line)
if event\["type"\] == "submit" and event\["success"\]:
state\["complete"\].add(event\["id"\])
state\["last"\] = event
return state

Sample response

This code defines a class \`Log\` that is used to log events to a file and retrieve the state of the log.

The \`\_\_init\_\_\` method initializes the log file. It takes a file path as an argument, creates the directory if it doesn't exist, and opens the file in append mode. If the file is not empty and doesn't end with a newline, it appends a newline.

The \`log\` method logs an event to the file. It takes a dictionary as an argument, adds a unique identifier to it, converts it to JSON, and writes it to the file followed by a newline.

The \`state\` method retrieves the state of the log. It initializes a dictionary with two keys: "complete" (a set of completed events) and "last" (the last event). It then reads the log file line by line, parses each line as JSON, and if the event type is "submit" and it was successful, it adds the event id to the "complete" set and updates the "last" event. Finally, it returns the state dictionary.

API request

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[\
    {\
      "role": "system",\
      "content": "You will be provided with a piece of code, and your task is to explain it in a concise way."\
    },\
    {\
      "role": "user",\
      "content": "class Log:\n        def __init__(self, path):\n            dirname = os.path.dirname(path)\n            os.makedirs(dirname, exist_ok=True)\n            f = open(path, \"a+\")\n    \n            # Check that the file is newline-terminated\n            size = os.path.getsize(path)\n            if size > 0:\n                f.seek(size - 1)\n                end = f.read(1)\n                if end != \"\\n\":\n                    f.write(\"\\n\")\n            self.f = f\n            self.path = path\n    \n        def log(self, event):\n            event[\"_event_id\"] = str(uuid.uuid4())\n            json.dump(event, self.f)\n            self.f.write(\"\\n\")\n    \n        def state(self):\n            state = {\"complete\": set(), \"last\": None}\n            for line in open(self.path):\n                event = json.loads(line)\n                if event[\"type\"] == \"submit\" and event[\"success\"]:\n                    state[\"complete\"].add(event[\"id\"])\n                    state[\"last\"] = event\n            return state"\
    }\
  ],
  temperature=1,
  max_tokens=1024,
  top_p=1
)
```Log in [Sign up](/signup)

# Prompt examples

Explore what's possible with some example prompts

All categories

Grammar correction

Convert ungrammatical statements into standard English.

Summarize for a 2nd grader

Simplify text to a level appropriate for a second-grade student.

Parse unstructured data

Create tables from unstructured text.

Emoji Translation

Translate regular text into emoji text.

Calculate time complexity

Find the time complexity of a function.

Explain code

Explain a complicated piece of code.

Keywords

Extract keywords from a block of text.

Product name generator

Generate product names from a description and seed words.

Python bug fixer

Find and fix bugs in source code.

Spreadsheet creator

Create spreadsheets of various kinds of data.

Tweet classifier

Detect sentiment in a tweet.

Airport code extractor

Extract airport codes from text.

Mood to color

Turn a text description into a color.

VR fitness idea generator

Generate ideas for fitness promoting virtual reality games.

Marv the sarcastic chat bot

Marv is a factual chatbot that is also sarcastic.

Turn by turn directions

Convert natural language to turn-by-turn directions.

Interview questions

Create interview questions.

Function from specification

Create a Python function from a specification.

Improve code efficiency

Provide ideas for efficiency improvements to Python code.

Single page website creator

Create a single page website.

Rap battle writer

Generate a rap battle between two characters.

Memo writer

Generate a company memo based on provided points.

Emoji chatbot

Generate conversational replies using emojis only.

Translation

Translate natural language text.

Socratic tutor

Generate responses as a Socratic tutor.

Natural language to SQL

Convert natural language into SQL queries.

Meeting notes summarizer

Summarize meeting notes including overall discussion, action items, and future topics.

Review classifier

Classify user reviews based on a set of tags.

Pro and con discusser

Analyze the pros and cons of a given topic.

Lesson plan writer

Generate a lesson plan for a specific topic.

Parse unstructured data

Extract

Natural Language

Create tables from unstructured text.

Prompt

SYSTEM

You will be provided with unstructured data, and your task is to parse it into CSV format.

USER

There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.

Sample response

Fruit,Color,Taste
neoskizzles,purple,candy
loheckles,grayish blue,tart
pounits,bright green,savory
loopnovas,neon pink,cotton candy
glowls,pale orange,sour and bitter

API request

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[\
    {\
      "role": "system",\
      "content": "You will be provided with unstructured data, and your task is to parse it into CSV format."\
    },\
    {\
      "role": "user",\
      "content": "There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them."\
    }\
  ],
  temperature=1,
  max_tokens=256,
  top_p=1
)
```Log in [Sign up](/signup)

# Prompt examples

Explore what's possible with some example prompts

All categories

Grammar correction

Convert ungrammatical statements into standard English.

Summarize for a 2nd grader

Simplify text to a level appropriate for a second-grade student.

Parse unstructured data

Create tables from unstructured text.

Emoji Translation

Translate regular text into emoji text.

Calculate time complexity

Find the time complexity of a function.

Explain code

Explain a complicated piece of code.

Keywords

Extract keywords from a block of text.

Product name generator

Generate product names from a description and seed words.

Python bug fixer

Find and fix bugs in source code.

Spreadsheet creator

Create spreadsheets of various kinds of data.

Tweet classifier

Detect sentiment in a tweet.

Airport code extractor

Extract airport codes from text.

Mood to color

Turn a text description into a color.

VR fitness idea generator

Generate ideas for fitness promoting virtual reality games.

Marv the sarcastic chat bot

Marv is a factual chatbot that is also sarcastic.

Turn by turn directions

Convert natural language to turn-by-turn directions.

Interview questions

Create interview questions.

Function from specification

Create a Python function from a specification.

Improve code efficiency

Provide ideas for efficiency improvements to Python code.

Single page website creator

Create a single page website.

Rap battle writer

Generate a rap battle between two characters.

Memo writer

Generate a company memo based on provided points.

Emoji chatbot

Generate conversational replies using emojis only.

Translation

Translate natural language text.

Socratic tutor

Generate responses as a Socratic tutor.

Natural language to SQL

Convert natural language into SQL queries.

Meeting notes summarizer

Summarize meeting notes including overall discussion, action items, and future topics.

Review classifier

Classify user reviews based on a set of tags.

Pro and con discusser

Analyze the pros and cons of a given topic.

Lesson plan writer

Generate a lesson plan for a specific topic.

Emoji chatbot

Generate

Natural Language

Generate conversational replies using emojis only.

Prompt

SYSTEM

You will be provided with a message, and your task is to respond using emojis only.

USER

How are you?

Sample response

😊👍

API request

python

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[\
    {\
      "role": "system",\
      "content": "You will be provided with a message, and your task is to respond using emojis only."\
    },\
    {\
      "role": "user",\
      "content": "How are you?"\
    }\
  ],
  temperature=0.8,
  max_tokens=256,
  top_p=1
)
```Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.[iframe](https://auth0.openai.com/authorize?issuer=auth0.openai.com&client_id=DRivsnm2Mu42T3KOpqdtwB3NYviHYzwD&audience=https%3A%2F%2Fapi.openai.com%2Fv1&redirect_uri=https%3A%2F%2Fplatform.openai.com%2Fauth%2Fcallback&device_id=2cb05218-caca-4de7-b795-82e66f572089&scope=openid%20profile%20email%20offline_access&response_type=code&response_mode=web_message&state=MlY3cDg4Y1FFQUJ6WkN3OTBDN3k5aExkZUJEMHR2OE5Mc25CLkxWODhNcw%3D%3D&nonce=Y35rajhlVlNWU1ltdm1lfmFMbEw2amZfOXdGQWJic05CLjNoUFRyUWVXWA%3D%3D&code_challenge=ZvLWsU_gJ0YRXHHRnIoFIerL3gThAboFOxB06Rvi8Ow&code_challenge_method=S256&prompt=none&auth0Client=eyJuYW1lIjoiYXV0aDAtc3BhLWpzIiwidmVyc2lvbiI6IjEuMjEuMCJ9)

# auth0.openai.com is blocked

**auth0.openai.com** refused to connect.

ERR\_BLOCKED\_BY\_RESPONSE

null

**auth0.openai.com** refused to connect.

![](<Base64-Image-Removed>)![](<Base64-Image-Removed>)Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.Log in [Sign up](/signup)

## Introduction

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries#community-libraries).

To install the official Python bindings, run the following command:

```bash
pip install openai
```

To install the official Node.js library, run the following command in your Node.js project directory:

```bash
npm install openai
```

## Authentication

### API keys

The OpenAI API uses API keys for authentication. You can create API keys at a user or service account level. Service accounts are tied to a "bot" individual and should be used to provision access for production systems. Each API key can be scoped to one of the following,

1. **Project keys** \- Provides access to a single project ( **preferred option**); access [Project API keys](/settings/organization/general) by selecting the specific project you wish to generate keys against.
2. **User keys** \- Our legacy keys. Provides access to all organizations and all projects that user has been added to; access [API Keys](/settings/organization/api-keys) to view your available keys. We highly advise transitioning to project keys for best security practices, although access via this method is currently still supported.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

```bash
Authorization: Bearer OPENAI_API_KEY
```

### Organizations and projects (optional)

For users who belong to multiple organizations or are accessing their projects through their legacy user API key, you can pass a header to specify which organization and project is used for an API request. Usage from these API requests will count as usage for the specified organization and project.

To access the `Default project` in an organization, leave out the `OpenAI-Project` header

Example curl command:

```bash
1
2
3
4
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Organization: YOUR_ORG_ID" \
  -H "OpenAI-Project: $PROJECT_ID"
```

Example with the `openai` Python package:

```python
1
2
3
4
5
6
from openai import OpenAI

client = OpenAI(
  organization='YOUR_ORG_ID',
  project='$PROJECT_ID',
)
```

Example with the `openai` Node.js package:

```javascript
1
2
3
4
5
6
import OpenAI from "openai";

const openai = new OpenAI({
    organization: "YOUR_ORG_ID",
    project: "$PROJECT_ID",
});
```

Organization IDs can be found on your [Organization settings](/settings/organization/general) page.
Project IDs can be found on your [General settings](/settings) page by selecting the specific project.

## Making requests

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key. If you are using a legacy user key and you have multiple projects, you will also need to [specify the Project Id](/docs/api-reference/authentication). For improved security, we recommend transitioning to project based keys instead.

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
     "model": "gpt-4o-mini",
     "messages": [{"role": "user", "content": "Say this is a test!"}],
     "temperature": 0.7
   }'
```

This request queries the `gpt-4o-mini` model (which under the hood points to a [`gpt-4o-mini` model variant](/docs/models#gpt-4o-mini)) to complete the text starting with a prompt of " _Say this is a test_". You should get a response back that resembles the following:

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
{
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677858242,
    "model": "gpt-4o-mini",
    "usage": {
        "prompt_tokens": 13,
        "completion_tokens": 7,
        "total_tokens": 20,
        "completion_tokens_details": {
            "reasoning_tokens": 0,
            "accepted_prediction_tokens": 0,
            "rejected_prediction_tokens": 0
        }
    },
    "choices": [\
        {\
            "message": {\
                "role": "assistant",\
                "content": "\n\nThis is a test!"\
            },\
            "logprobs": null,\
            "finish_reason": "stop",\
            "index": 0\
        }\
    ]
}
```

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

## Streaming

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard. Our official [Node](https://github.com/openai/openai-node?tab=readme-ov-file#streaming-responses) and [Python](https://github.com/openai/openai-python?tab=readme-ov-file#streaming-responses) libraries include helpers to make parsing these events simpler.

Streaming is supported for both the [Chat Completions API](/docs/api-reference/chat/streaming) and the [Assistants API](/docs/api-reference/runs/createRun). This section focuses on how streaming works for Chat Completions. Learn more about how streaming works in the Assistants API [here](/docs/assistants/overview).

In Python, a streaming request looks like:

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI

client = OpenAI()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

In Node / Typescript, a streaming request looks like:

```javascript
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import OpenAI from "openai";

const openai = new OpenAI();

async function main() {
    const stream = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: "Say this is a test" }],
        stream: true,
    });
    for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || "");
    }
}

main();
```

#### Parsing Server-sent events

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

## Debugging requests

In addition to [error codes](/docs/guides/error-codes) returned from API responses, it may sometimes be necessary to inspect HTTP response headers as well. Of particular interest will be the headers which contain the unique ID of a particular API request, and information about rate limiting applied to your requests. Below is an incomplete list of HTTP headers returned with API responses:

**API meta information**

- `openai-organization`: The [organization](/docs/guides/production-best-practices#setting-up-your-organization) associated with the request
- `openai-processing-ms`: Time taken processing your API request
- `openai-version`: REST API version used for this request (currently `2020-10-01`)
- `x-request-id`: Unique identifier for this API request (used in troubleshooting)

**[Rate limiting information](/docs/guides/rate-limits)**

- `x-ratelimit-limit-requests`
- `x-ratelimit-limit-tokens`
- `x-ratelimit-remaining-requests`
- `x-ratelimit-remaining-tokens`
- `x-ratelimit-reset-requests`
- `x-ratelimit-reset-tokens`

**OpenAI recommends logging request IDs in production deployments**, which will allow more efficient troubleshooting with our [support team](https://help.openai.com/en/) should the need arise. Our official SDKs provide a property on top level response objects containing the value of the `x-request-id` header.

**Request ID in Python**

```python
1
2
3
4
5
6
7
8
9
10
11
12
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)

print(response._request_id)
```

**Request ID in JavaScript**

```javascript
1
2
3
4
5
6
7
8
9
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
});

console.log(response._request_id);
```

### Access raw response objects in SDKs

If you are using a lower-level HTTP client (like [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or [`HttpClient` in C#](https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/http/httpclient)), you should already have access to response headers as a part of the HTTP interface.

If you are using one of OpenAI's [official SDKs](/docs/libraries) (which largely abstract the HTTP request/response cycle), you will need to access raw HTTP responses in a slightly different way.

Below is an example of accessing the raw response object (and the `x-ratelimit-limit-tokens` header) using our [Python SDK](https://github.com/openai/openai-python?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```python
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.with_raw_response.create(
    messages=[{\
        "role": "user",\
        "content": "Say this is a test",\
    }],
    model="gpt-4o-mini",
)
print(response.headers.get('x-ratelimit-limit-tokens'))

# get the object that `chat.completions.create()` would have returned
completion = response.parse()
print(completion)
```

Here is how you'd access a raw response (and the `x-ratelimit-limit-tokens` header) using our [JavaScript SDK](https://github.com/openai/openai-node?tab=readme-ov-file#accessing-raw-response-data-eg-headers).

```javascript
1
2
3
4
5
6
7
8
9
10
import OpenAI from 'openai';
const client = new OpenAI();

const response = await client.chat.completions.create({
    messages: [{ role: 'user', content: 'Say this is a test' }],
    model: 'gpt-4o-mini'
}).asResponse();

// access the underlying Response object
console.log(response.headers.get('x-ratelimit-limit-tokens'));
```

## Backward compatibility

OpenAI is committed to providing stability to API users by avoiding breaking changes in major API versions whenever reasonably possible. This includes:

- The REST API (currently `v1`)
- Our first-party [SDKs](/docs/libraries) (released SDKs will adhere to [semantic versioning](https://semver.org/))
- [Model](/docs/models) families (like `gpt-4o` or `o1-mini`)

Backwards-compatible changes and upgrades will be continuously delivered over time. These and any rare breaking changes will be communicated in the [changelog](/docs/changelog). Here are some examples of changes which we consider to be backwards-compatible (non-breaking) changes.

**Changes in model prompting behavior between snapshots**

Model outputs are by their nature variable, so changes in prompting and model behavior between snapshots should be expected. For example, if you moved from `gpt-4o-2024-05-13` to `gpt-4o-2024-08-06`, the same `system` or `user` messages could function differently between versions. The best way to ensure consistent prompting behavior and model output is to use pinned model versions, and to implement [evals](/docs/guides/evals) for your applications.

**Backwards-compatible API changes**

- Adding new resources (URLs) to the REST API and SDKs
- Adding new optional API parameters
- Adding new properties to JSON response objects or event data
- Changing the order of properties in a JSON response object
- Changing the length or format of opaque strings, like resource identifiers and UUIDs
- Adding new event types (in either streaming or the Realtime API)

## Audio

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

## Create speech

posthttps://api.openai.com/v1/audio/speech

Generates audio from the input text.

### Request body

model

string

Required

One of the available [TTS models](/docs/models#tts): `tts-1` or `tts-1-hd`

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech#voice-options).

response\_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/audio/speech \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "The quick brown fox jumped over the lazy dog.",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

## Create transcription

posthttps://api.openai.com/v1/audio/transcriptions

Transcribes audio into the input language.

### Request body

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should match the audio language.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

timestamp\_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

DefaultDefaultWord timestampsWord timestampsSegment timestampsSegment timestamps

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/transcriptions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/audio.mp3" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## Create translation

posthttps://api.openai.com/v1/audio/translations

Translates audio into English.

### Request body

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text#prompting) should be in English.

response\_format

string

Optional

Defaults to json

The format of the output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/audio/translations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F file="@/path/to/file/german.m4a" \
  -F model="whisper-1"
```

Response

```json
1
2
3
{
  "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
}
```

## The transcription object (JSON)

Represents a transcription response returned by model, based on the provided input.

text

string

The transcribed text.

OBJECT The transcription object (JSON)

```JSON
1
2
3
{
  "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
}
```

## The transcription object (Verbose JSON)

Represents a verbose json transcription response returned by model, based on the provided input.

language

string

The language of the input audio.

duration

string

The duration of the input audio.

text

string

The transcribed text.

words

array

Extracted words and their corresponding timestamps.

Show properties

segments

array

Segments of the transcribed text and their corresponding details.

Show properties

OBJECT The transcription object (Verbose JSON)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "task": "transcribe",
  "language": "english",
  "duration": 8.470000267028809,
  "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
  "segments": [\
    {\
      "id": 0,\
      "seek": 0,\
      "start": 0.0,\
      "end": 3.319999933242798,\
      "text": " The beach was a popular spot on a hot summer day.",\
      "tokens": [\
        50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\
      ],\
      "temperature": 0.0,\
      "avg_logprob": -0.2860786020755768,\
      "compression_ratio": 1.2363636493682861,\
      "no_speech_prob": 0.00985979475080967\
    },\
    ...\
  ]
}
```

## Chat

Given a list of messages comprising a conversation, the model will return a response.
Related guide: [Chat Completions](/docs/guides/text-generation)

## Create chat completion

posthttps://api.openai.com/v1/chat/completions

Creates a model response for the given chat conversation. Learn more in the
[text generation](/docs/guides/text-generation), [vision](/docs/guides/vision),
and [audio](/docs/guides/audio) guides.

### Request body

messages

array

Required

A list of messages comprising the conversation so far. Depending on the
[model](/docs/models) you use, different message types (modalities) are
supported, like [text](/docs/guides/text-generation),
[images](/docs/guides/vision), and [audio](/docs/guides/audio).

Show possible types

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.

store

boolean or null

Optional

Defaults to false

Whether or not to store the output of this chat completion request
for use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products.

metadata

object or null

Optional

Developer-defined tags and values used for filtering completions
in the [dashboard](https://platform.openai.com/chat-completions).

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.

top\_logprobs

integer or null

Optional

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

max\_tokens

Deprecated

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.

This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning).

max\_completion\_tokens

integer or null

Optional

An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning).

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

modalities

array or null

Optional

Output types that you would like the model to generate for this request.
Most models are capable of generating text, which is the default:

`["text"]`

The `gpt-4o-audio-preview` model can also be used to [generate audio](/docs/guides/audio). To
request that this model generate both text and audio responses, you can
use:

`["text", "audio"]`

prediction

object

Optional

Configuration for a [Predicted Output](/docs/guides/predicted-outputs),
which can greatly improve response times when large parts of the model
response are known ahead of time. This is most common when you are
regenerating a file with only minor changes to most of the content.

Show possible types

audio

object or null

Optional

Parameters for audio output. Required when audio output is requested with
`modalities: ["audio"]`. [Learn more](/docs/guides/audio).

Show properties

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

response\_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4o mini](/docs/models#gpt-4o-mini), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

seed

integer or null

Optional

This feature is in Beta.
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

service\_tier

string or null

Optional

Defaults to auto

Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:

- If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
- If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
- When not set, the default behavior is 'auto'.

When this parameter is set, the response body will include the `service_tier` utilized.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tool and instead generates a message.
`auto` means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools.
Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

`none` is the default when no tools are present. `auto` is the default if tools are present.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

function\_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model.
`none` means the model will not call a function and instead generates a message.
`auto` means the model can pick between generating a message or calling a function.
Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

DefaultDefaultImage inputImage inputStreamingStreamingFunctionsFunctionsLogprobsLogprobs

Example request

gpt-4o

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [\
      {\
        "role": "system",\
        "content": "You are a helpful assistant."\
      },\
      {\
        "role": "user",\
        "content": "Hello!"\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4o-mini",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [{\
    "index": 0,\
    "message": {\
      "role": "assistant",\
      "content": "\n\nHello there, how may I assist you today?",\
    },\
    "logprobs": null,\
    "finish_reason": "stop"\
  }],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 12,
    "total_tokens": 21,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

## The chat completion object

Represents a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion.

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

model

string

The model used for the chat completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion`.

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The chat completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "id": "chatcmpl-123456",
  "object": "chat.completion",
  "created": 1728933352,
  "model": "gpt-4o-2024-08-06",
  "choices": [\
    {\
      "index": 0,\
      "message": {\
        "role": "assistant",\
        "content": "Hi there! How can I assist you today?",\
        "refusal": null\
      },\
      "logprobs": null,\
      "finish_reason": "stop"\
    }\
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": "fp_6b68a8204b"
}
```

## The chat completion chunk object

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

choices

array

A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
last chunk if you set `stream_options: {"include_usage": true}`.

Show properties

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

model

string

The model to generate the completion.

service\_tier

string or null

The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.
Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always `chat.completion.chunk`.

usage

object or null

An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.

Show properties

OBJECT The chat completion chunk object

```JSON
1
2
3
4
5
6
7
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

....

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

## Embeddings

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.
Related guide: [Embeddings](/docs/guides/embeddings)

## Create embeddings

posthttps://api.openai.com/v1/embeddings

Creates an embedding vector representing the input text.

### Request body

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Show possible types

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

encoding\_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/embeddings \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "The food was delicious and the waiter...",
    "model": "text-embedding-ada-002",
    "encoding_format": "float"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "object": "embedding",\
      "embedding": [\
        0.0023064255,\
        -0.009327292,\
        .... (1536 floats total for ada-002)\
        -0.0028842222,\
      ],\
      "index": 0\
    }\
  ],
  "model": "text-embedding-ada-002",
  "usage": {
    "prompt_tokens": 8,
    "total_tokens": 8
  }
}
```

## The embedding object

Represents an embedding vector returned by embedding endpoint.

index

integer

The index of the embedding in the list of embeddings.

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

object

string

The object type, which is always "embedding".

OBJECT The embedding object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "embedding",
  "embedding": [\
    0.0023064255,\
    -0.009327292,\
    .... (1536 floats total for ada-002)\
    -0.0028842222,\
  ],
  "index": 0
}
```

## Fine-tuning

Manage fine-tuning jobs to tailor a model to your specific training data.
Related guide: [Fine-tune models](/docs/guides/fine-tuning)

## Create fine-tuning job

posthttps://api.openai.com/v1/fine\_tuning/jobs

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

model

string

Required

The name of the model to fine-tune. You can select one of the
[supported models](/docs/guides/fine-tuning#which-models-can-be-fine-tuned).

training\_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Show properties

suffix

string or null

Optional

Defaults to null

A string of up to 64 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.

validation\_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation
metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file.
The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

integrations

array or null

Optional

A list of integrations to enable for your fine-tuning job.

Show properties

seed

integer or null

Optional

The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
If a seed is not specified, one will be generated for you.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

DefaultDefaultEpochsEpochsValidation fileValidation fileW&B IntegrationW&B Integration

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
    "model": "gpt-4o-mini"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "status": "queued",
  "validation_file": null,
  "training_file": "file-abc123",
}
```

## List fine-tuning jobs

gethttps://api.openai.com/v1/fine\_tuning/jobs

List your organization's fine-tuning jobs

### Query parameters

after

string

Optional

Identifier for the last job from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",\
      "created_at": 1689813489,\
      "level": "warn",\
      "message": "Fine tuning process stopping due to job cancellation",\
      "data": null,\
      "type": "message"\
    },\
    { ... },\
    { ... }\
  ], "has_more": true
}
```

## List fine-tuning events

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events

Get status updates for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

after

string

Optional

Identifier for the last event from the previous pagination request.

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "Fine tuning job successfully completed",\
      "data": null,\
      "type": "message"\
    },\
    {\
      "object": "fine_tuning.job.event",\
      "id": "ft-event-tyiGuB72evQncpH87xe505Sv",\
      "created_at": 1721764800,\
      "level": "info",\
      "message": "New fine-tuned model created: ft:gpt-4o-mini:openai::7p4lURel",\
      "data": null,\
      "type": "message"\
    }\
  ],
  "has_more": true
}
```

## List fine-tuning checkpoints

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/checkpoints

List checkpoints for a fine-tuning job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to get checkpoints for.

### Query parameters

after

string

Optional

Identifier for the last checkpoint ID from the previous pagination request.

limit

integer

Optional

Defaults to 10

Number of checkpoints to retrieve.

### Returns

A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object) for a fine-tuning job.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
{
  "object": "list"
  "data": [\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",\
      "created_at": 1721764867,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:96olL566:ckpt-step-2000",\
      "metrics": {\
        "full_valid_loss": 0.134,\
        "full_valid_mean_token_accuracy": 0.874\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 2000,\
    },\
    {\
      "object": "fine_tuning.job.checkpoint",\
      "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",\
      "created_at": 1721764800,\
      "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",\
      "metrics": {\
        "full_valid_loss": 0.167,\
        "full_valid_mean_token_accuracy": 0.781\
      },\
      "fine_tuning_job_id": "ftjob-abc123",\
      "step_number": 1000,\
    },\
  ],
  "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
  "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
  "has_more": true
}
```

## Retrieve fine-tuning job

gethttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## Cancel fine-tuning

posthttps://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel

Immediately cancel a fine-tune job.

### Path parameters

fine\_tuning\_job\_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

curl

```bash
1
2
curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "gpt-4o-mini-2024-07-18",
  "created_at": 1721764800,
  "fine_tuned_model": null,
  "organization_id": "org-123",
  "result_files": [],
  "hyperparameters": {
    "n_epochs":  "auto"
  },
  "status": "cancelled",
  "validation_file": "file-abc123",
  "training_file": "file-abc123"
}
```

## Training format for chat models

The per-line training example of a fine-tuning input file for chat models

messages

array

Show possible types

tools

array

A list of tools the model may generate JSON inputs for.

Show properties

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

functions

Deprecated

array

A list of functions the model may generate JSON inputs for.

Show properties

OBJECT Training format for chat models

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "messages": [\
    { "role": "user", "content": "What is the weather in San Francisco?" },\
    {\
      "role": "assistant",\
      "tool_calls": [\
        {\
          "id": "call_id",\
          "type": "function",\
          "function": {\
            "name": "get_current_weather",\
            "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"\
          }\
        }\
      ]\
    }\
  ],
  "parallel_tool_calls": false,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
                "type": "string",\
                "description": "The city and country, eg. San Francisco, USA"\
            },\
            "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }\
          },\
          "required": ["location", "format"]\
        }\
      }\
    }\
  ]
}
```

## Training format for completions models

The per-line training example of a fine-tuning input file for completions models

prompt

string

The input prompt for this training example.

completion

string

The desired completion for this training example.

OBJECT Training format for completions models

```JSON
1
2
3
4
{
  "prompt": "What is the answer to 2+2",
  "completion": "4"
}
```

## The fine-tuning job object

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

id

string

The object identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Show properties

fine\_tuned\_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

finished\_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Show properties

model

string

The base model that is being fine-tuned.

object

string

The object type, which is always "fine\_tuning.job".

organization\_id

string

The organization that owns the fine-tuning job.

result\_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

trained\_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

training\_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

validation\_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

integrations

array or null

A list of integrations to enable for this fine-tuning job.

Show possible types

seed

integer

The seed used for the fine-tuning job.

estimated\_finish

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.

OBJECT The fine-tuning job object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "fine_tuning.job",
  "id": "ftjob-abc123",
  "model": "davinci-002",
  "created_at": 1692661014,
  "finished_at": 1692661190,
  "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
  "organization_id": "org-123",
  "result_files": [\
      "file-abc123"\
  ],
  "status": "succeeded",
  "validation_file": null,
  "training_file": "file-abc123",
  "hyperparameters": {
      "n_epochs": 4,
      "batch_size": 1,
      "learning_rate_multiplier": 1.0
  },
  "trained_tokens": 5768,
  "integrations": [],
  "seed": 0,
  "estimated_finish": 0
}
```

## The fine-tuning job event object

Fine-tuning job event object

id

string

created\_at

integer

level

string

message

string

object

string

OBJECT The fine-tuning job event object

```JSON
1
2
3
4
5
6
7
{
  "object": "fine_tuning.job.event",
  "id": "ftevent-abc123"
  "created_at": 1677610602,
  "level": "info",
  "message": "Created fine-tuning job"
}
```

## The fine-tuning job checkpoint object

The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.

id

string

The checkpoint identifier, which can be referenced in the API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the checkpoint was created.

fine\_tuned\_model\_checkpoint

string

The name of the fine-tuned checkpoint model that is created.

step\_number

integer

The step number that the checkpoint was created at.

metrics

object

Metrics at the step number during the fine-tuning job.

Show properties

fine\_tuning\_job\_id

string

The name of the fine-tuning job that this checkpoint was created from.

object

string

The object type, which is always "fine\_tuning.job.checkpoint".

OBJECT The fine-tuning job checkpoint object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "object": "fine_tuning.job.checkpoint",
  "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
  "created_at": 1712211699,
  "fine_tuned_model_checkpoint": "ft:gpt-4o-mini-2024-07-18:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
  "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
  "metrics": {
    "step": 88,
    "train_loss": 0.478,
    "train_mean_token_accuracy": 0.924,
    "valid_loss": 10.112,
    "valid_mean_token_accuracy": 0.145,
    "full_valid_loss": 0.567,
    "full_valid_mean_token_accuracy": 0.944
  },
  "step_number": 88
}
```

## Batch

Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.
Related guide: [Batch](/docs/guides/batch)

## Create batch

posthttps://api.openai.com/v1/batches

Creates and executes a batch from an uploaded file of requests

### Request body

input\_file\_id

string

Required

The ID of an uploaded file that contains requests for the new batch.

See [upload file](/docs/api-reference/files/create) for how to upload a file.

Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.

endpoint

string

Required

The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.

completion\_window

string

Required

The time frame within which the batch should be processed. Currently only `24h` is supported.

metadata

object or null

Optional

Optional custom metadata for the batch.

### Returns

The created [Batch](/docs/api-reference/batch/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/batches \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "input_file_id": "file-abc123",
    "endpoint": "/v1/chat/completions",
    "completion_window": "24h"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "validating",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": null,
  "expires_at": null,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 0,
    "completed": 0,
    "failed": 0
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Retrieve batch

gethttps://api.openai.com/v1/batches/{batch\_id}

Retrieves a batch.

### Path parameters

batch\_id

string

Required

The ID of the batch to retrieve.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches/batch_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## Cancel batch

posthttps://api.openai.com/v1/batches/{batch\_id}/cancel

Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.

### Path parameters

batch\_id

string

Required

The ID of the batch to cancel.

### Returns

The [Batch](/docs/api-reference/batch/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/batches/batch_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/chat/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "cancelling",
  "output_file_id": null,
  "error_file_id": null,
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": null,
  "completed_at": null,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": 1711475133,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 23,
    "failed": 1
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## List batch

gethttps://api.openai.com/v1/batches

List your organization's batches.

### Query parameters

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

### Returns

A list of paginated [Batch](/docs/api-reference/batch/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/batches?limit=2 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "object": "list",
  "data": [\
    {\
      "id": "batch_abc123",\
      "object": "batch",\
      "endpoint": "/v1/chat/completions",\
      "errors": null,\
      "input_file_id": "file-abc123",\
      "completion_window": "24h",\
      "status": "completed",\
      "output_file_id": "file-cvaTdG",\
      "error_file_id": "file-HOWS94",\
      "created_at": 1711471533,\
      "in_progress_at": 1711471538,\
      "expires_at": 1711557933,\
      "finalizing_at": 1711493133,\
      "completed_at": 1711493163,\
      "failed_at": null,\
      "expired_at": null,\
      "cancelling_at": null,\
      "cancelled_at": null,\
      "request_counts": {\
        "total": 100,\
        "completed": 95,\
        "failed": 5\
      },\
      "metadata": {\
        "customer_id": "user_123456789",\
        "batch_description": "Nightly job",\
      }\
    },\
    { ... },\
  ],
  "first_id": "batch_abc123",
  "last_id": "batch_abc456",
  "has_more": true
}
```

## The batch object

id

string

object

string

The object type, which is always `batch`.

endpoint

string

The OpenAI API endpoint used by the batch.

errors

object

Show properties

input\_file\_id

string

The ID of the input file for the batch.

completion\_window

string

The time frame within which the batch should be processed.

status

string

The current status of the batch.

output\_file\_id

string

The ID of the file containing the outputs of successfully executed requests.

error\_file\_id

string

The ID of the file containing the outputs of requests with errors.

created\_at

integer

The Unix timestamp (in seconds) for when the batch was created.

in\_progress\_at

integer

The Unix timestamp (in seconds) for when the batch started processing.

expires\_at

integer

The Unix timestamp (in seconds) for when the batch will expire.

finalizing\_at

integer

The Unix timestamp (in seconds) for when the batch started finalizing.

completed\_at

integer

The Unix timestamp (in seconds) for when the batch was completed.

failed\_at

integer

The Unix timestamp (in seconds) for when the batch failed.

expired\_at

integer

The Unix timestamp (in seconds) for when the batch expired.

cancelling\_at

integer

The Unix timestamp (in seconds) for when the batch started cancelling.

cancelled\_at

integer

The Unix timestamp (in seconds) for when the batch was cancelled.

request\_counts

object

The request counts for different statuses within the batch.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
{
  "id": "batch_abc123",
  "object": "batch",
  "endpoint": "/v1/completions",
  "errors": null,
  "input_file_id": "file-abc123",
  "completion_window": "24h",
  "status": "completed",
  "output_file_id": "file-cvaTdG",
  "error_file_id": "file-HOWS94",
  "created_at": 1711471533,
  "in_progress_at": 1711471538,
  "expires_at": 1711557933,
  "finalizing_at": 1711493133,
  "completed_at": 1711493163,
  "failed_at": null,
  "expired_at": null,
  "cancelling_at": null,
  "cancelled_at": null,
  "request_counts": {
    "total": 100,
    "completed": 95,
    "failed": 5
  },
  "metadata": {
    "customer_id": "user_123456789",
    "batch_description": "Nightly eval job",
  }
}
```

## The request input object

The per-line object of the batch input file

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs. Must be unique for each request in a batch.

method

string

The HTTP method to be used for the request. Currently only `POST` is supported.

url

string

The OpenAI API relative URL to be used for the request. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.

OBJECT The request input object

```JSON
{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
```

## The request output object

The per-line object of the batch output and error files

id

string

custom\_id

string

A developer-provided per-request id that will be used to match outputs to inputs.

response

object or null

Show properties

error

object or null

For requests that failed with a non-HTTP error, this will contain more information on the cause of the failure.

Show properties

OBJECT The request output object

```JSON
{"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-4o-mini", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
```

## Files

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).

## Upload file

posthttps://api.openai.com/v1/files

Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

The Batch API only supports `.jsonl` files up to 200 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

file

file

Required

The File object (not file name) to be uploaded.

purpose

string

Required

The intended purpose of the uploaded file.

Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@mydata.jsonl"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## List files

gethttps://api.openai.com/v1/files

Returns a list of files.

### Query parameters

purpose

string

Optional

Only return files with the given purpose.

limit

integer

Optional

Defaults to 10000

A limit on the number of objects to be returned. Limit can range between 1 and 10,000, and the default is 10,000.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 175,\
      "created_at": 1613677385,\
      "filename": "salesOverview.pdf",\
      "purpose": "assistants",\
    },\
    {\
      "id": "file-abc123",\
      "object": "file",\
      "bytes": 140,\
      "created_at": 1613779121,\
      "filename": "puppy.jsonl",\
      "purpose": "fine-tune",\
    }\
  ],
  "object": "list"
}
```

## Retrieve file

gethttps://api.openai.com/v1/files/{file\_id}

Returns information about a specific file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "mydata.jsonl",
  "purpose": "fine-tune",
}
```

## Delete file

deletehttps://api.openai.com/v1/files/{file\_id}

Delete a file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/files/file-abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "file-abc123",
  "object": "file",
  "deleted": true
}
```

## Retrieve file content

gethttps://api.openai.com/v1/files/{file\_id}/content

Returns the contents of the specified file.

### Path parameters

file\_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/files/file-abc123/content \
  -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
```

## The file object

The `File` object represents a document that has been uploaded to OpenAI.

id

string

The file identifier, which can be referenced in the API endpoints.

bytes

integer

The size of the file, in bytes.

created\_at

integer

The Unix timestamp (in seconds) for when the file was created.

filename

string

The name of the file.

object

string

The object type, which is always `file`.

purpose

string

The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

status\_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

OBJECT The file object

```JSON
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "file",
  "bytes": 120000,
  "created_at": 1677610602,
  "filename": "salesOverview.pdf",
  "purpose": "assistants",
}
```

## Uploads

Allows you to upload large files in multiple parts.

## Create upload

posthttps://api.openai.com/v1/uploads

Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

For certain `purpose` s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:

- [Assistants](/docs/assistants/tools/file-search#supported-files)

For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).

### Request body

filename

string

Required

The name of the file to upload.

purpose

string

Required

The intended purpose of the uploaded file.

See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose).

bytes

integer

Required

The number of bytes in the file you are uploading.

mime\_type

string

Required

The MIME type of the file.

This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `pending`.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/uploads \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "purpose": "fine-tune",
    "filename": "training_examples.jsonl",
    "bytes": 2147483648,
    "mime_type": "text/jsonl"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "pending",
  "expires_at": 1719127296
}
```

## Add upload part

posthttps://api.openai.com/v1/uploads/{upload\_id}/parts

Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object) object. A Part represents a chunk of bytes from the file you are trying to upload.

Each Part can be at most 64 MB, and you can add Parts until you hit the Upload maximum of 8 GB.

It is possible to add multiple Parts in parallel. You can decide the intended order of the Parts when you [complete the Upload](/docs/api-reference/uploads/complete).

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

data

file

Required

The chunk of bytes for this Part.

### Returns

The upload [Part](/docs/api-reference/uploads/part-object) object.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/uploads/upload_abc123/parts
  -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
```

Response

```json
1
2
3
4
5
6
{
  "id": "part_def456",
  "object": "upload.part",
  "created_at": 1719185911,
  "upload_id": "upload_abc123"
}
```

## Complete upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/complete

Completes the [Upload](/docs/api-reference/uploads/object).

Within the returned Upload object, there is a nested [File](/docs/api-reference/files/object) object that is ready to use in the rest of the platform.

You can specify the order of the Parts by passing in an ordered list of the Part IDs.

The number of bytes uploaded upon completion must match the number of bytes initially specified when creating the Upload object. No Parts may be added after an Upload is completed.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Request body

part\_ids

array

Required

The ordered list of Part IDs.

md5

string

Optional

The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `completed` with an additional `file` property containing the created usable File object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/uploads/upload_abc123/complete
  -d '{
    "part_ids": ["part_def456", "part_ghi789"]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## Cancel upload

posthttps://api.openai.com/v1/uploads/{upload\_id}/cancel

Cancels the Upload. No Parts may be added after an Upload is cancelled.

### Path parameters

upload\_id

string

Required

The ID of the Upload.

### Returns

The [Upload](/docs/api-reference/uploads/object) object with status `cancelled`.

Example request

curl

```bash
curl https://api.openai.com/v1/uploads/upload_abc123/cancel
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "cancelled",
  "expires_at": 1719127296
}
```

## The upload object

The Upload object can accept byte chunks in the form of Parts.

id

string

The Upload unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

filename

string

The name of the file to be uploaded.

bytes

integer

The intended number of bytes to be uploaded.

purpose

string

The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values.

status

string

The status of the Upload.

expires\_at

integer

The Unix timestamp (in seconds) for when the Upload was created.

object

string

The object type, which is always "upload".

file

The `File` object represents a document that has been uploaded to OpenAI.

OBJECT The upload object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "upload_abc123",
  "object": "upload",
  "bytes": 2147483648,
  "created_at": 1719184911,
  "filename": "training_examples.jsonl",
  "purpose": "fine-tune",
  "status": "completed",
  "expires_at": 1719127296,
  "file": {
    "id": "file-xyz321",
    "object": "file",
    "bytes": 2147483648,
    "created_at": 1719186911,
    "filename": "training_examples.jsonl",
    "purpose": "fine-tune",
  }
}
```

## The upload part object

The upload Part represents a chunk of bytes we can add to an Upload object.

id

string

The upload Part unique identifier, which can be referenced in API endpoints.

created\_at

integer

The Unix timestamp (in seconds) for when the Part was created.

upload\_id

string

The ID of the Upload object that this Part was added to.

object

string

The object type, which is always `upload.part`.

OBJECT The upload part object

```JSON
1
2
3
4
5
6
{
    "id": "part_def456",
    "object": "upload.part",
    "created_at": 1719186911,
    "upload_id": "upload_abc123"
}
```

## Images

Given a prompt and/or an input image, the model will generate a new image.
Related guide: [Image generation](/docs/guides/images)

## Create image

posthttps://api.openai.com/v1/images/generations

Creates an image given a prompt.

### Request body

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/images/generations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "dall-e-3",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image edit

posthttps://api.openai.com/v1/images/edits

Creates an edited or extended image given an original image and a prompt.

### Request body

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/images/edits \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F mask="@mask.png" \
  -F prompt="A cute baby sea otter wearing a beret" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## Create image variation

posthttps://api.openai.com/v1/images/variations

Creates a variation of a given image.

### Request body

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

response\_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/images/variations \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F image="@otter.png" \
  -F n=2 \
  -F size="1024x1024"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "created": 1589478378,
  "data": [\
    {\
      "url": "https://..."\
    },\
    {\
      "url": "https://..."\
    }\
  ]
}
```

## The image object

Represents the url or the content of an image generated by the OpenAI API.

b64\_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

url

string

The URL of the generated image, if `response_format` is `url` (default).

revised\_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

OBJECT The image object

```JSON
1
2
3
4
{
  "url": "...",
  "revised_prompt": "..."
}
```

## Models

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

## List models

gethttps://api.openai.com/v1/models

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

curl

```bash
1
2
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
{
  "object": "list",
  "data": [\
    {\
      "id": "model-id-0",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner"\
    },\
    {\
      "id": "model-id-1",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "organization-owner",\
    },\
    {\
      "id": "model-id-2",\
      "object": "model",\
      "created": 1686935002,\
      "owned_by": "openai"\
    },\
  ],
  "object": "list"
}
```

## Retrieve model

gethttps://api.openai.com/v1/models/{model}

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-4o

curl

```bash
1
2
curl https://api.openai.com/v1/models/gpt-4o \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Delete a fine-tuned model

deletehttps://api.openai.com/v1/models/{model}

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/models/ft:gpt-4o-mini:acemeco:suffix:abc123 \
  -X DELETE \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Response

```json
1
2
3
4
5
{
  "id": "ft:gpt-4o-mini:acemeco:suffix:abc123",
  "object": "model",
  "deleted": true
}
```

## The model object

Describes an OpenAI model offering that can be used with the API.

id

string

The model identifier, which can be referenced in the API endpoints.

created

integer

The Unix timestamp (in seconds) when the model was created.

object

string

The object type, which is always "model".

owned\_by

string

The organization that owns the model.

OBJECT The model object

```JSON
1
2
3
4
5
6
{
  "id": "gpt-4o",
  "object": "model",
  "created": 1686935002,
  "owned_by": "openai"
}
```

## Moderations

Given text and/or image inputs, classifies if those inputs are potentially harmful across several categories.
Related guide: [Moderations](/docs/guides/moderation)

## Create moderation

posthttps://api.openai.com/v1/moderations

Classifies if text and/or image inputs are potentially harmful. Learn
more in the [moderation guide](/docs/guides/moderation).

### Request body

input

string or array

Required

Input (or inputs) to classify. Can be a single string, an array of strings, or
an array of multi-modal input objects similar to other models.

Show possible types

model

string

Optional

Defaults to omni-moderation-latest

The content moderation model you would like to use. Learn more in
[the moderation guide](/docs/guides/moderation), and learn about
available models [here](/docs/models#moderation).

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Single stringSingle stringImage and textImage and text

Example request

curl

```bash
1
2
3
4
5
6
curl https://api.openai.com/v1/moderations \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "input": "I want to kill them."
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "modr-AB8CjOTu2jiq12hp1AQPfeqFWaORR",
  "model": "text-moderation-007",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "sexual": false,\
        "hate": false,\
        "harassment": true,\
        "self-harm": false,\
        "sexual/minors": false,\
        "hate/threatening": false,\
        "violence/graphic": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "harassment/threatening": true,\
        "violence": true\
      },\
      "category_scores": {\
        "sexual": 0.000011726012417057063,\
        "hate": 0.22706663608551025,\
        "harassment": 0.5215635299682617,\
        "self-harm": 2.227119921371923e-6,\
        "sexual/minors": 7.107352217872176e-8,\
        "hate/threatening": 0.023547329008579254,\
        "violence/graphic": 0.00003391829886822961,\
        "self-harm/intent": 1.646940972932498e-6,\
        "self-harm/instructions": 1.1198755256458526e-9,\
        "harassment/threatening": 0.5694745779037476,\
        "violence": 0.9971134662628174\
      }\
    }\
  ]
}
```

## The moderation object

Represents if a given text input is potentially harmful.

id

string

The unique identifier for the moderation request.

model

string

The model used to generate the moderation results.

results

array

A list of moderation objects.

Show properties

OBJECT The moderation object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
{
  "id": "modr-0d9740456c391e43c445bf0f010940c7",
  "model": "omni-moderation-latest",
  "results": [\
    {\
      "flagged": true,\
      "categories": {\
        "harassment": true,\
        "harassment/threatening": true,\
        "sexual": false,\
        "hate": false,\
        "hate/threatening": false,\
        "illicit": false,\
        "illicit/violent": false,\
        "self-harm/intent": false,\
        "self-harm/instructions": false,\
        "self-harm": false,\
        "sexual/minors": false,\
        "violence": true,\
        "violence/graphic": true\
      },\
      "category_scores": {\
        "harassment": 0.8189693396524255,\
        "harassment/threatening": 0.804985420696006,\
        "sexual": 1.573112165348997e-6,\
        "hate": 0.007562942636942845,\
        "hate/threatening": 0.004208854591835476,\
        "illicit": 0.030535955153511665,\
        "illicit/violent": 0.008925306722380033,\
        "self-harm/intent": 0.00023023930975076432,\
        "self-harm/instructions": 0.0002293869201073356,\
        "self-harm": 0.012598046106750154,\
        "sexual/minors": 2.212566909570261e-8,\
        "violence": 0.9999992735124786,\
        "violence/graphic": 0.843064871157054\
      },\
      "category_applied_input_types": {\
        "harassment": [\
          "text"\
        ],\
        "harassment/threatening": [\
          "text"\
        ],\
        "sexual": [\
          "text",\
          "image"\
        ],\
        "hate": [\
          "text"\
        ],\
        "hate/threatening": [\
          "text"\
        ],\
        "illicit": [\
          "text"\
        ],\
        "illicit/violent": [\
          "text"\
        ],\
        "self-harm/intent": [\
          "text",\
          "image"\
        ],\
        "self-harm/instructions": [\
          "text",\
          "image"\
        ],\
        "self-harm": [\
          "text",\
          "image"\
        ],\
        "sexual/minors": [\
          "text"\
        ],\
        "violence": [\
          "text",\
          "image"\
        ],\
        "violence/graphic": [\
          "text",\
          "image"\
        ]\
      }\
    }\
  ]
}
```

## Assistants  Beta

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant  Beta

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4o"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## List assistants  Beta

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "tools": [],\
      "tool_resources": {},\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## Retrieve assistant  Beta

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Modify assistant  Beta

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "file_search"}],
      "model": "gpt-4o"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "asst_123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": []
    }
  },
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant  Beta

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## The assistant object  Beta

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

Show possible types

tool\_resources

object or null

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4o",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Threads  Beta

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread  Beta

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Show properties

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d ''
```

Response

```json
1
2
3
4
5
6
7
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {},
  "tool_resources": {}
}
```

## Retrieve thread  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {},
  "tool_resources": {
    "code_interpreter": {
      "file_ids": []
    }
  }
}
```

## Modify thread  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

tool\_resources

object or null

Optional

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  },
  "tool_resources": {}
}
```

## Delete thread  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object  Beta

Represents a thread that contains [messages](/docs/api-reference/messages).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

tool\_resources

object or null

A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The thread object

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages  Beta

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string or array

Required

Show possible types

attachments

array or null

Optional

A list of files attached to the message, and the tools they should be added to.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1713226573,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## List messages  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "assistant_id": null,\
      "thread_id": "thread_abc123",\
      "run_id": null,\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "attachments": [],\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## Retrieve message  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "attachments": [],
  "metadata": {}
}
```

## Modify message  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [message](/docs/api-reference/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "assistant_id": null,
  "thread_id": "thread_abc123",
  "run_id": null,
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete message  Beta

deletehttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Deletes a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "msg_abc123",
  "object": "thread.message.deleted",
  "deleted": true
}
```

## The message object  Beta

Represents a message within a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

attachments

array or null

A list of files attached to the message, and the tools they were added to.

Show properties

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The message object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "attachments": [],
  "metadata": {}
}
```

## Runs  Beta

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Create thread and run  Beta

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

tool\_resources

object or null

Optional

A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Optional

Defaults to true

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "required_action": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "tool_resources": {},
  "metadata": {},
  "temperature": 1.0,
  "top_p": 1.0,
  "max_completion_tokens": null,
  "max_prompt_tokens": null,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "incomplete_details": null,
  "usage": null,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## List runs  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4o",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "tool_resources": {\
        "code_interpreter": {\
          "file_ids": [\
            "file-abc123",\
            "file-abc456"\
          ]\
        }\
      },\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto",\
      "parallel_tool_calls": true\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## Retrieve run  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Modify run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "tool_resources": {
    "code_interpreter": {
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ]
    }
  },
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Submit tool outputs to run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Cancel a run  Beta

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "file_search"\
    }\
  ],
  "tool_resources": {
    "file_search": {
      "vector_store_ids": ["vs_123"]
    }
  },
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## The run object  Beta

Represents an execution run on a [thread](/docs/api-reference/threads).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Show possible types

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Show properties

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run.

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling one or more tools.
`required` means the model must call one or more tools before responding to the user.
Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

parallel\_tool\_calls

boolean

Whether to enable [parallel function calling](/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.

response\_format

"auto" or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4o",
  "instructions": null,
  "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto",
  "parallel_tool_calls": true
}
```

## Run steps  Beta

Represents the steps (model and tool calls) taken during the run.

Related guide: [Assistants](/docs/assistants/overview)

## List run steps  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

A list of [run step](/docs/api-reference/run-steps/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run step  Beta

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Query parameters

include\[\]

array

Optional

A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.

See the [file search tool documentation](/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Returns

The [run step](/docs/api-reference/run-steps/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## The run step object  Beta

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Show properties

OBJECT The run step object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Vector stores  Beta

Vector stores are used to store files for use by the `file_search` tool.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store  Beta

posthttps://api.openai.com/v1/vector\_stores

Create a vector store.

### Request body

file\_ids

array

Optional

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

name

string

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

A [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## List vector stores  Beta

gethttps://api.openai.com/v1/vector\_stores

Returns a list of vector stores.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [vector store](/docs/api-reference/vector-stores/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
{
  "object": "list",
  "data": [\
    {\
      "id": "vs_abc123",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    },\
    {\
      "id": "vs_abc456",\
      "object": "vector_store",\
      "created_at": 1699061776,\
      "name": "Support FAQ v2",\
      "bytes": 139920,\
      "file_counts": {\
        "in_progress": 0,\
        "completed": 3,\
        "failed": 0,\
        "cancelled": 0,\
        "total": 3\
      }\
    }\
  ],
  "first_id": "vs_abc123",
  "last_id": "vs_abc456",
  "has_more": false
}
```

## Retrieve vector store  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Retrieves a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to retrieve.

### Returns

The [vector store](/docs/api-reference/vector-stores/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776
}
```

## Modify vector store  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Modifies a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to modify.

### Request body

name

string or null

Optional

The name of the vector store.

expires\_after

object

Optional

The expiration policy for a vector store.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

### Returns

The modified [vector store](/docs/api-reference/vector-stores/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
  -d '{
    "name": "Support FAQ"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vs_abc123",
  "object": "vector_store",
  "created_at": 1699061776,
  "name": "Support FAQ",
  "bytes": 139920,
  "file_counts": {
    "in_progress": 0,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 3
  }
}
```

## Delete vector store  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}

Delete a vector store.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "vs_abc123",
  object: "vector_store.deleted",
  deleted: true
}
```

## The vector store object  Beta

A vector store is a collection of processed files can be used by the `file_search` tool.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store was created.

name

string

The name of the vector store.

usage\_bytes

integer

The total number of bytes used by the files in the vector store.

file\_counts

object

Show properties

status

string

The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use.

expires\_after

object

The expiration policy for a vector store.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the vector store will expire.

last\_active\_at

integer or null

The Unix timestamp (in seconds) for when the vector store was last active.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.

OBJECT The vector store object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "vs_123",
  "object": "vector_store",
  "created_at": 1698107661,
  "usage_bytes": 123456,
  "last_active_at": 1698107661,
  "name": "my_vector_store",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "cancelled": 0,
    "failed": 0,
    "total": 100
  },
  "metadata": {},
  "last_used_at": 1698107661
}
```

## Vector store files  Beta

Vector store files represent files inside a vector store.

Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Create a vector store file by attaching a [File](/docs/api-reference/files) to a [vector store](/docs/api-reference/vector-stores/object).

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json" \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "usage_bytes": 1234,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## List vector store files  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files

Returns a list of vector store files.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve vector store file  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Retrieves a vector store file.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [vector store file](/docs/api-reference/vector-stores-files/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "created_at": 1699061776,
  "vector_store_id": "vs_abcd",
  "status": "completed",
  "last_error": null
}
```

## Delete vector store file  Beta

deletehttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/files/{file\_id}

Delete a vector store file. This will remove the file from the vector store but the file itself will not be deleted. To delete the file, use the [delete file](/docs/api-reference/files/delete) endpoint.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "vector_store.file.deleted",
  deleted: true
}
```

## The vector store file object  Beta

A list of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file`.

usage\_bytes

integer

The total vector store usage in bytes. Note that this may be different from the original file size.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store file was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use.

last\_error

object or null

The last error associated with this vector store file. Will be `null` if there are no errors.

Show properties

chunking\_strategy

object

The strategy used to chunk the file.

Show possible types

OBJECT The vector store file object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
  "id": "file-abc123",
  "object": "vector_store.file",
  "usage_bytes": 1234,
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "last_error": null,
  "chunking_strategy": {
    "type": "static",
    "static": {
      "max_chunk_size_tokens": 800,
      "chunk_overlap_tokens": 400
    }
  }
}
```

## Vector store file batches  Beta

Vector store file batches represent operations to add multiple files to a vector store.
Related guide: [File Search](/docs/assistants/tools/file-search)

## Create vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches

Create a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store for which to create a File Batch.

### Request body

file\_ids

array

Required

A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files.

chunking\_strategy

object

Optional

The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy.

Show possible types

### Returns

A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -H "Content-Type: application/json \
    -H "OpenAI-Beta: assistants=v2" \
    -d '{
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Retrieve vector store file batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}

Retrieves a vector store file batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch being retrieved.

### Returns

The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "in_progress",
  "file_counts": {
    "in_progress": 1,
    "completed": 1,
    "failed": 0,
    "cancelled": 0,
    "total": 0,
  }
}
```

## Cancel vector store file batch  Beta

posthttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/cancel

Cancel a vector store file batch. This attempts to cancel the processing of files in this batch as soon as possible.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the file batch belongs to.

batch\_id

string

Required

The ID of the file batch to cancel.

### Returns

The modified vector store file batch object.

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_abc123",
  "object": "vector_store.file_batch",
  "created_at": 1699061776,
  "vector_store_id": "vs_abc123",
  "status": "cancelling",
  "file_counts": {
    "in_progress": 12,
    "completed": 3,
    "failed": 0,
    "cancelled": 0,
    "total": 15,
  }
}
```

## List vector store files in a batch  Beta

gethttps://api.openai.com/v1/vector\_stores/{vector\_store\_id}/file\_batches/{batch\_id}/files

Returns a list of vector store files in a batch.

### Path parameters

vector\_store\_id

string

Required

The ID of the vector store that the files belong to.

batch\_id

string

Required

The ID of the file batch that the files belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

filter

string

Optional

Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.

### Returns

A list of [vector store file](/docs/api-reference/vector-stores-files/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v2"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "vector_store.file",\
      "created_at": 1699061776,\
      "vector_store_id": "vs_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## The vector store files batch object  Beta

A batch of files attached to a vector store.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `vector_store.file_batch`.

created\_at

integer

The Unix timestamp (in seconds) for when the vector store files batch was created.

vector\_store\_id

string

The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to.

status

string

The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`.

file\_counts

object

Show properties

OBJECT The vector store files batch object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
  "id": "vsfb_123",
  "object": "vector_store.files_batch",
  "created_at": 1698107661,
  "vector_store_id": "vs_abc123",
  "status": "completed",
  "file_counts": {
    "in_progress": 0,
    "completed": 100,
    "failed": 0,
    "cancelled": 0,
    "total": 100
  }
}
```

## Streaming  Beta

Stream the result of executing a Run or resuming a Run after submitting tool outputs.
You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
[Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.
Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object  Beta

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object  Beta

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events  Beta

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads/object)

Occurs when a new [thread](/docs/api-reference/threads/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a new [run](/docs/api-reference/runs/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is completed.

thread.run.incomplete

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) ends with status `incomplete`.

thread.run.failed

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs/object)

Occurs when a [run](/docs/api-reference/runs/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/run-steps/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/run-steps/step-object)

Occurs when a [run step](/docs/api-reference/run-steps/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages/object)

Occurs when a [message](/docs/api-reference/messages/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.

## Administration

Programmatically manage your organization.
The Audit Logs endpoint provides a log of all actions taken in the organization for security and monitoring purposes.
To access these endpoints please generate an Admin API Key through the [API Platform Organization overview](/organization/admin-keys). Admin API keys cannot be used for non-administration endpoints.
For best practices on setting up your organization, please refer to this [guide](/docs/guides/production-best-practices#setting-up-your-organization)

## Invites

Invite and manage invitations for an organization. Invited users are automatically added to the Default project.

## List invites

gethttps://api.openai.com/v1/organization/invites

Returns a list of invites in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [Invite](/docs/api-reference/invite/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites?after=invite-abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create invite

posthttps://api.openai.com/v1/organization/invites

Create an invite for a user to the organization. The invite must be accepted by the user before they have access to the organization.

### Request body

email

string

Required

Send an email to this address

role

string

Required

`owner` or `reader`

### Returns

The created [Invite](/docs/api-reference/invite/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/invites \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "email": "user@example.com",
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve invite

gethttps://api.openai.com/v1/organization/invites/{invite\_id}

Retrieves an invite.

### Path parameters

invite\_id

string

Required

The ID of the invite to retrieve.

### Returns

The [Invite](/docs/api-reference/invite/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete invite

deletehttps://api.openai.com/v1/organization/invites/{invite\_id}

Delete an invite. If the invite has already been accepted, it cannot be deleted.

### Path parameters

invite\_id

string

Required

The ID of the invite to delete.

### Returns

Confirmation that the invite has been deleted

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/invites/invite-abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The invite object

Represents an individual `invite` to the organization.

object

string

The object type, which is always `organization.invite`

id

string

The identifier, which can be referenced in API endpoints

email

string

The email address of the individual to whom the invite was sent

role

string

`owner` or `reader`

status

string

`accepted`, `expired`, or `pending`

invited\_at

integer

The Unix timestamp (in seconds) of when the invite was sent.

expires\_at

integer

The Unix timestamp (in seconds) of when the invite expires.

accepted\_at

integer

The Unix timestamp (in seconds) of when the invite was accepted.

OBJECT The invite object

```JSON
1
2
3
4
5
6
7
8
9
10
{
  "object": "organization.invite",
  "id": "invite-abc",
  "email": "user@example.com",
  "role": "owner",
  "status": "accepted",
  "invited_at": 1711471533,
  "expires_at": 1711471533,
  "accepted_at": 1711471533
}
```

## Users

Manage users and their role in an organization. Users will be automatically added to the Default project.

## List users

gethttps://api.openai.com/v1/organization/users

Lists all of the users in the organization.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [User](/docs/api-reference/users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify user

posthttps://api.openai.com/v1/organization/users/{user\_id}

Modifies a user's role in the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `reader`

### Returns

The updated [User](/docs/api-reference/users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Retrieve user

gethttps://api.openai.com/v1/organization/users/{user\_id}

Retrieves a user by their identifier.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

The [User](/docs/api-reference/users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete user

deletehttps://api.openai.com/v1/organization/users/{user\_id}

Deletes a user from the organization.

### Path parameters

user\_id

string

Required

The ID of the user.

### Returns

Confirmation of the deleted user

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The user object

Represents an individual `user` within an organization.

object

string

The object type, which is always `organization.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `reader`

added\_at

integer

The Unix timestamp (in seconds) of when the user was added.

OBJECT The user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Projects

Manage the projects within an orgnanization includes creation, updating, and archiving or projects.
The Default project cannot be modified or archived.

## List projects

gethttps://api.openai.com/v1/organization/projects

Returns a list of projects.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

include\_archived

boolean

Optional

Defaults to false

If `true` returns all projects including those that have been `archived`. Archived projects are not included by default.

### Returns

A list of [Project](/docs/api-reference/projects/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects?after=proj_abc&limit=20&include_archived=false \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project

posthttps://api.openai.com/v1/organization/projects

Create a new project in the organization. Projects can be created and archived, but cannot be deleted.

### Request body

name

string

Required

The friendly name of the project, this name appears in reports.

### Returns

The created [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project ABC"
  }'
```

Response

Select...

```json

```

## Retrieve project

gethttps://api.openai.com/v1/organization/projects/{project\_id}

Retrieves a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The [Project](/docs/api-reference/projects/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project

posthttps://api.openai.com/v1/organization/projects/{project\_id}

Modifies a project in the organization.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The updated name of the project, this name appears in reports.

### Returns

The updated [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Project DEF"
  }'
```

## Archive project

posthttps://api.openai.com/v1/organization/projects/{project\_id}/archive

Archives a project in the organization. Archived projects cannot be used or updated.

### Path parameters

project\_id

string

Required

The ID of the project.

### Returns

The archived [Project](/docs/api-reference/projects/object) object.

Example request

curl

```bash
1
2
3
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/archive \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project object

Represents an individual project.

id

string

The identifier, which can be referenced in API endpoints

object

string

The object type, which is always `organization.project`

name

string

The name of the project. This appears in reporting.

created\_at

integer

The Unix timestamp (in seconds) of when the project was created.

archived\_at

integer or null

The Unix timestamp (in seconds) of when the project was archived or `null`.

status

string

`active` or `archived`

OBJECT The project object

```JSON
1
2
3
4
5
6
7
8
{
    "id": "proj_abc",
    "object": "organization.project",
    "name": "Project example",
    "created_at": 1711471533,
    "archived_at": null,
    "status": "active"
}
```

## Project users

Manage users within a project, including adding, updating roles, and removing users.
Users cannot be removed from the Default project, unless they are being removed from the organization.

## List project users

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users

Returns a list of users in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectUser](/docs/api-reference/project-users/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users?after=user_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users

Adds a user to the project. Users must already be members of the organization to be added to a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

user\_id

string

Required

The ID of the user.

role

string

Required

`owner` or `member`

### Returns

The created [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "user_id": "user_abc",
      "role": "member"
  }'
```

Response

Select...

```json

```

## Retrieve project user

gethttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Retrieves a user in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

The [ProjectUser](/docs/api-reference/project-users/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Modify project user

posthttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Modifies a user's role in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Request body

role

string

Required

`owner` or `member`

### Returns

The updated [ProjectUser](/docs/api-reference/project-users/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "role": "owner"
  }'
```

Response

Select...

```json

```

## Delete project user

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/users/{user\_id}

Deletes a user from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

user\_id

string

Required

The ID of the user.

### Returns

Confirmation that project has been deleted or an error in case of an archived project, which has no users

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/users/user_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project user object

Represents an individual user in a project.

object

string

The object type, which is always `organization.project.user`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the user

email

string

The email address of the user

role

string

`owner` or `member`

added\_at

integer

The Unix timestamp (in seconds) of when the project was added.

OBJECT The project user object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "organization.project.user",
    "id": "user_abc",
    "name": "First Last",
    "email": "user@example.com",
    "role": "owner",
    "added_at": 1711471533
}
```

## Project service accounts

Manage service accounts within a project. A service account is a bot user that is not associated with a user.
If a user leaves an organization, their keys and membership in projects will no longer work. Service accounts
do not have this limitation. However, service accounts can also be deleted from a project.

## List project service accounts

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Returns a list of service accounts in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts?after=custom_id&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Create project service account

posthttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts

Creates a new service account in the project. This also returns an unredacted API key for the service account.

### Path parameters

project\_id

string

Required

The ID of the project.

### Request body

name

string

Required

The name of the service account being created.

### Returns

The created [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/service_accounts \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "name": "Production App"
  }'
```

Response

Select...

```json

```

## Retrieve project service account

gethttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Retrieves a service account in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

The [ProjectServiceAccount](/docs/api-reference/project-service-accounts/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project service account

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/service\_accounts/{service\_account\_id}

Deletes a service account from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

service\_account\_id

string

Required

The ID of the service account.

### Returns

Confirmation of service account being deleted, or an error in case of an archived project, which has no service accounts

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/service_accounts/svc_acct_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project service account object

Represents an individual service account in a project.

object

string

The object type, which is always `organization.project.service_account`

id

string

The identifier, which can be referenced in API endpoints

name

string

The name of the service account

role

string

`owner` or `member`

created\_at

integer

The Unix timestamp (in seconds) of when the service account was created

OBJECT The project service account object

```JSON
1
2
3
4
5
6
7
{
    "object": "organization.project.service_account",
    "id": "svc_acct_abc",
    "name": "Service Account",
    "role": "owner",
    "created_at": 1711471533
}
```

## Project API keys

Manage API keys for a given project. Supports listing and deleting keys for users.
This API does not allow issuing keys for users, as users need to authorize themselves to generate keys.

## List project API keys

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys

Returns a list of API keys in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

### Returns

A list of [ProjectApiKey](/docs/api-reference/project-api-keys/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys?after=key_abc&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Retrieve project API key

gethttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Retrieves an API key in the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

The [ProjectApiKey](/docs/api-reference/project-api-keys/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## Delete project API key

deletehttps://api.openai.com/v1/organization/projects/{project\_id}/api\_keys/{key\_id}

Deletes an API key from the project.

### Path parameters

project\_id

string

Required

The ID of the project.

key\_id

string

Required

The ID of the API key.

### Returns

Confirmation of the key's deletion or an error if the key belonged to a service account

Example request

curl

```bash
1
2
3
curl -X DELETE https://api.openai.com/v1/organization/projects/proj_abc/api_keys/key_abc \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

Select...

```json

```

## The project API key object

Represents an individual API key in a project.

object

string

The object type, which is always `organization.project.api_key`

redacted\_value

string

The redacted value of the API key

name

string

The name of the API key

created\_at

integer

The Unix timestamp (in seconds) of when the API key was created

id

string

The identifier, which can be referenced in API endpoints

owner

object

Show properties

OBJECT The project API key object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "object": "organization.project.api_key",
    "redacted_value": "sk-abc...def",
    "name": "My API Key",
    "created_at": 1711471533,
    "id": "key_abc",
    "owner": {
        "type": "user",
        "user": {
            "object": "organization.project.user",
            "id": "user_abc",
            "name": "First Last",
            "email": "user@example.com",
            "role": "owner",
            "created_at": 1711471533
        }
    }
}
```

## Project rate limits

Manage rate limits per model for projects. Rate limits may be configured to be equal to or lower than the organization's rate limits.

## List project rate limits

gethttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits

Returns the rate limits per model for a project.

### Path parameters

project\_id

string

Required

The ID of the project.

### Query parameters

limit

integer

Optional

Defaults to 100

A limit on the number of objects to be returned. The default is 100.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, beginning with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/projects/proj_abc/rate_limits?after=rl_xxx&limit=20 \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "object": "list",
    "data": [\
        {\
          "object": "project.rate_limit",\
          "id": "rl-ada",\
          "model": "ada",\
          "max_requests_per_1_minute": 600,\
          "max_tokens_per_1_minute": 150000,\
          "max_images_per_1_minute": 10\
        }\
    ],
    "first_id": "rl-ada",
    "last_id": "rl-ada",
    "has_more": false
}
```

## Modify project rate limit

posthttps://api.openai.com/v1/organization/projects/{project\_id}/rate\_limits/{rate\_limit\_id}

Updates a project rate limit.

### Path parameters

project\_id

string

Required

The ID of the project.

rate\_limit\_id

string

Required

The ID of the rate limit.

### Request body

max\_requests\_per\_1\_minute

integer

Optional

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

Optional

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

Optional

The maximum images per minute. Only relevant for certain models.

max\_audio\_megabytes\_per\_1\_minute

integer

Optional

The maximum audio megabytes per minute. Only relevant for certain models.

max\_requests\_per\_1\_day

integer

Optional

The maximum requests per day. Only relevant for certain models.

batch\_1\_day\_max\_input\_tokens

integer

Optional

The maximum batch input tokens per day. Only relevant for certain models.

### Returns

The updated [ProjectRateLimit](/docs/api-reference/project-rate-limits/object) object.

Example request

curl

```bash
1
2
3
4
5
6
curl -X POST https://api.openai.com/v1/organization/projects/proj_abc/rate_limits/rl_xxx \
  -H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "max_requests_per_1_minute": 500
  }'
```

Response

```json
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl-ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
  }
```

## The project rate limit object

Represents a project rate limit config.

object

string

The object type, which is always `project.rate_limit`

id

string

The identifier, which can be referenced in API endpoints.

model

string

The model this rate limit applies to.

max\_requests\_per\_1\_minute

integer

The maximum requests per minute.

max\_tokens\_per\_1\_minute

integer

The maximum tokens per minute.

max\_images\_per\_1\_minute

integer

The maximum images per minute. Only present for relevant models.

max\_audio\_megabytes\_per\_1\_minute

integer

The maximum audio megabytes per minute. Only present for relevant models.

max\_requests\_per\_1\_day

integer

The maximum requests per day. Only present for relevant models.

batch\_1\_day\_max\_input\_tokens

integer

The maximum batch input tokens per day. Only present for relevant models.

OBJECT The project rate limit object

```JSON
1
2
3
4
5
6
7
8
{
    "object": "project.rate_limit",
    "id": "rl_ada",
    "model": "ada",
    "max_requests_per_1_minute": 600,
    "max_tokens_per_1_minute": 150000,
    "max_images_per_1_minute": 10
}
```

## Audit logs

Logs of user actions and configuration changes within this organization.
To log events, you must activate logging in the [Organization Settings](/settings/organization/general).
Once activated, for security reasons, logging cannot be deactivated.

## List audit logs

gethttps://api.openai.com/v1/organization/audit\_logs

List user actions and configuration changes within this organization.

### Query parameters

effective\_at

object

Optional

Return only events whose `effective_at` (Unix seconds) is in this range.

Show properties

project\_ids\[\]

array

Optional

Return only events for these projects.

event\_types\[\]

array

Optional

Return only events with a `type` in one of these values. For example, `project.created`. For all options, see the documentation for the [audit log object](/docs/api-reference/audit-logs/object).

actor\_ids\[\]

array

Optional

Return only events performed by these actors. Can be a user ID, a service account ID, or an api key tracking ID.

actor\_emails\[\]

array

Optional

Return only events performed by users with these emails.

resource\_ids\[\]

array

Optional

Return only events performed on these targets. For example, a project ID updated.

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of paginated [Audit Log](/docs/api-reference/audit-logs/object) objects.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/organization/audit_logs \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
{
    "object": "list",
    "data": [\
        {\
            "id": "audit_log-xxx_yyyymmdd",\
            "type": "project.archived",\
            "effective_at": 1722461446,\
            "actor": {\
                "type": "api_key",\
                "api_key": {\
                    "type": "user",\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    }\
                }\
            },\
            "project.archived": {\
                "id": "proj_abc"\
            },\
        },\
        {\
            "id": "audit_log-yyy__20240101",\
            "type": "api_key.updated",\
            "effective_at": 1720804190,\
            "actor": {\
                "type": "session",\
                "session": {\
                    "user": {\
                        "id": "user-xxx",\
                        "email": "user@example.com"\
                    },\
                    "ip_address": "127.0.0.1",\
                    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"\
                }\
            },\
            "api_key.updated": {\
                "id": "key_xxxx",\
                "data": {\
                    "scopes": ["resource_2.operation_2"]\
                }\
            },\
        }\
    ],
    "first_id": "audit_log-xxx__20240101",
    "last_id": "audit_log_yyy__20240101",
    "has_more": true
}
```

## The audit log object

A log of a user action or configuration change within this organization.

id

string

The ID of this log.

type

string

The event type.

effective\_at

integer

The Unix timestamp (in seconds) of the event.

project

object

The project that the action was scoped to. Absent for actions not scoped to projects.

Show properties

actor

object

The actor who performed the audit logged action.

Show properties

api\_key.created

object

The details for events with this `type`.

Show properties

api\_key.updated

object

The details for events with this `type`.

Show properties

api\_key.deleted

object

The details for events with this `type`.

Show properties

invite.sent

object

The details for events with this `type`.

Show properties

invite.accepted

object

The details for events with this `type`.

Show properties

invite.deleted

object

The details for events with this `type`.

Show properties

login.failed

object

The details for events with this `type`.

Show properties

logout.failed

object

The details for events with this `type`.

Show properties

organization.updated

object

The details for events with this `type`.

Show properties

project.created

object

The details for events with this `type`.

Show properties

project.updated

object

The details for events with this `type`.

Show properties

project.archived

object

The details for events with this `type`.

Show properties

rate\_limit.updated

object

The details for events with this `type`.

Show properties

rate\_limit.deleted

object

The details for events with this `type`.

Show properties

service\_account.created

object

The details for events with this `type`.

Show properties

service\_account.updated

object

The details for events with this `type`.

Show properties

service\_account.deleted

object

The details for events with this `type`.

Show properties

user.added

object

The details for events with this `type`.

Show properties

user.updated

object

The details for events with this `type`.

Show properties

user.deleted

object

The details for events with this `type`.

Show properties

OBJECT The audit log object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "id": "req_xxx_20240101",
    "type": "api_key.created",
    "effective_at": 1720804090,
    "actor": {
        "type": "session",
        "session": {
            "user": {
                "id": "user-xxx",
                "email": "user@example.com"
            },
            "ip_address": "127.0.0.1",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
    },
    "api_key.created": {
        "id": "key_xxxx",
        "data": {
            "scopes": ["resource.operation"]
        }
    }
}
```

## Usage

The **Usage API** provides detailed insights into your activity across the OpenAI API. It also includes a separate [Costs endpoint](/docs/api-reference/usage/costs), which offers visibility into your spend, breaking down consumption by invoice line items and project IDs.

While the Usage API delivers granular usage data, it may not always reconcile perfectly with the Costs due to minor differences in how usage and spend are recorded. For financial purposes, we recommend using the [Costs endpoint](/docs/api-reference/usage/costs) or the [Costs tab](/settings/organization/usage) in the Usage Dashboard, which will reconcile back to your billing invoice.

## Completions

gethttps://api.openai.com/v1/organization/usage/completions

Get completions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

batch

boolean

Optional

If `true`, return batch jobs only. If `false`, return non-batch jobs only. By default, return both.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `batch` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Completions usage](/docs/api-reference/usage/completions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/completions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.completions.result",\
                    "input_tokens": 1000,\
                    "output_tokens": 500,\
                    "input_cached_tokens": 800,\
                    "num_model_requests": 5,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null,\
                    "batch": null\
                }\
            ]\
        }\
    ],
    "has_more": true,
    "next_page": "AAAAAGdGxdEiJdKOAAAAAGcqsYA="
}
```

## Completions usage object

The aggregated completions usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

input\_cached\_tokens

integer

The number of input tokens that has been cached from previous requests.

output\_tokens

integer

The number of output tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

batch

boolean

When `group_by=batch`, this field tells whether the grouped usage result is batch or not.

OBJECT Completions usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "object": "orgainzation.usage.completions.result",
    "input_tokens": 5000,
    "output_tokens": 1000,
    "input_cached_tokens": 4000,
    "num_model_requests": 5,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "gpt-4o-mini-2024-07-18",
    "batch": false
}
```

## Embeddings

gethttps://api.openai.com/v1/organization/usage/embeddings

Get embeddings usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Embeddings usage](/docs/api-reference/usage/embeddings_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/embeddings?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.embeddings.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Embeddings usage object

The aggregated embeddings usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Embeddings usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.embeddings.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-embedding-ada-002-v2"
}
```

## Moderations

gethttps://api.openai.com/v1/organization/usage/moderations

Get moderations usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Moderations usage](/docs/api-reference/usage/moderations_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/moderations?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.moderations.result",\
                    "input_tokens": 16,\
                    "num_model_requests": 2,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Moderations usage object

The aggregated moderations usage details of the specific time bucket.

object

string

input\_tokens

integer

The number of input tokens used.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Moderations usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.moderations.result",
    "input_tokens": 20,
    "num_model_requests": 2,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "text-moderation"
}
```

## Images

gethttps://api.openai.com/v1/organization/usage/images

Get images usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

sources

array

Optional

Return only usages for these sources. Possible values are `image.generation`, `image.edit`, `image.variation` or any combination of them.

sizes

array

Optional

Return only usages for these image sizes. Possible values are `256x256`, `512x512`, `1024x1024`, `1792x1792`, `1024x1792` or any combination of them.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model`, `size`, `source` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Images usage](/docs/api-reference/usage/images_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/images?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.images.result",\
                    "images": 2,\
                    "num_model_requests": 2,\
                    "size": null,\
                    "source": null,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Images usage object

The aggregated images usage details of the specific time bucket.

object

string

images

integer

The number of images processed.

num\_model\_requests

integer

The count of requests made to the model.

source

string

When `group_by=source`, this field provides the source of the grouped usage result, possible values are `image.generation`, `image.edit`, `image.variation`.

size

string

When `group_by=size`, this field provides the image size of the grouped usage result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Images usage object

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "object": "orgainzation.usage.images.result",
    "images": 2,
    "num_model_requests": 2,
    "size": "1024x1024",
    "source": "image.generation",
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "dall-e-3"
}
```

## Audio speeches

gethttps://api.openai.com/v1/organization/usage/audio\_speeches

Get audio speeches usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio speeches usage](/docs/api-reference/usage/audio_speeches_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_speeches?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_speeches.result",\
                    "characters": 45,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio speeches usage object

The aggregated audio speeches usage details of the specific time bucket.

object

string

characters

integer

The number of characters processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio speeches usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_speeches.result",
    "characters": 45,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Audio transcriptions

gethttps://api.openai.com/v1/organization/usage/audio\_transcriptions

Get audio transcriptions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

user\_ids

array

Optional

Return only usage for these users.

api\_key\_ids

array

Optional

Return only usage for these API keys.

models

array

Optional

Return only usage for these models.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`, `user_id`, `api_key_id`, `model` or any combination of them.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Audio transcriptions usage](/docs/api-reference/usage/audio_transcriptions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/audio_transcriptions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.audio_transcriptions.result",\
                    "seconds": 20,\
                    "num_model_requests": 1,\
                    "project_id": null,\
                    "user_id": null,\
                    "api_key_id": null,\
                    "model": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Audio transcriptions usage object

The aggregated audio transcriptions usage details of the specific time bucket.

object

string

seconds

integer

The number of seconds processed.

num\_model\_requests

integer

The count of requests made to the model.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

user\_id

string

When `group_by=user_id`, this field provides the user ID of the grouped usage result.

api\_key\_id

string

When `group_by=api_key_id`, this field provides the API key ID of the grouped usage result.

model

string

When `group_by=model`, this field provides the model name of the grouped usage result.

OBJECT Audio transcriptions usage object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.usage.audio_transcriptions.result",
    "seconds": 10,
    "num_model_requests": 1,
    "project_id": "proj_abc",
    "user_id": "user-abc",
    "api_key_id": "key_abc",
    "model": "tts-1"
}
```

## Vector stores

gethttps://api.openai.com/v1/organization/usage/vector\_stores

Get vector stores usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Vector stores usage](/docs/api-reference/usage/vector_stores_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/vector_stores?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.vector_stores.result",\
                    "usage_bytes": 1024,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Vector stores usage object

The aggregated vector stores usage details of the specific time bucket.

object

string

usage\_bytes

integer

The vector stores usage in bytes.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Vector stores usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.vector_stores.result",
    "usage_bytes": 1024,
    "project_id": "proj_abc"
}
```

## Code interpreter sessions

gethttps://api.openai.com/v1/organization/usage/code\_interpreter\_sessions

Get code interpreter sessions usage details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently `1m`, `1h` and `1d` are supported, default to `1d`.

project\_ids

array

Optional

Return only usage for these projects.

group\_by

array

Optional

Group the usage data by the specified fields. Support fields include `project_id`.

limit

integer

Optional

Specifies the number of buckets to return.

- `bucket_width=1d`: default: 7, max: 31
- `bucket_width=1h`: default: 24, max: 168
- `bucket_width=1m`: default: 60, max: 1440

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Code interpreter sessions usage](/docs/api-reference/usage/code_interpreter_sessions_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/usage/code_interpreter_sessions?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.usage.code_interpreter_sessions.result",\
                    "sessions": 1,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Code interpreter sessions usage object

The aggregated code interpreter sessions usage details of the specific time bucket.

object

string

sessions

integer

The number of code interpreter sessions.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped usage result.

OBJECT Code interpreter sessions usage object

```JSON
1
2
3
4
5
{
    "object": "orgainzation.usage.code_interpreter_sessions.result",
    "sessions": 1,
    "project_id": "proj_abc"
}
```

## Costs

gethttps://api.openai.com/v1/organization/costs

Get costs details for the organization.

### Query parameters

start\_time

integer

Required

Start time (Unix seconds) of the query time range, inclusive.

end\_time

integer

Optional

End time (Unix seconds) of the query time range, exclusive.

bucket\_width

string

Optional

Defaults to 1d

Width of each time bucket in response. Currently only `1d` is supported, default to `1d`.

project\_ids

array

Optional

Return only costs for these projects.

group\_by

array

Optional

Group the costs by the specified fields. Support fields include `project_id`, `line_item` and any combination of them.

limit

integer

Optional

Defaults to 7

A limit on the number of buckets to be returned. Limit can range between 1 and 180, and the default is 7.

page

string

Optional

A cursor for use in pagination. Corresponding to the `next_page` field from the previous response.

### Returns

A list of paginated, time bucketed [Costs](/docs/api-reference/usage/costs_object) objects.

Example request

curl

```bash
1
2
3
curl "https://api.openai.com/v1/organization/costs?start_time=1730419200&limit=1" \
-H "Authorization: Bearer $OPENAI_ADMIN_KEY" \
-H "Content-Type: application/json"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
    "object": "page",
    "data": [\
        {\
            "object": "bucket",\
            "start_time": 1730419200,\
            "end_time": 1730505600,\
            "results": [\
                {\
                    "object": "orgainzation.costs.result",\
                    "amount": {\
                        "value": 0.06,\
                        "currency": "usd"\
                    },\
                    "line_item": null,\
                    "project_id": null\
                }\
            ]\
        }\
    ],
    "has_more": false,
    "next_page": null
}
```

## Costs object

The aggregated costs details of the specific time bucket.

object

string

amount

object

Show properties

line\_item

string

When `group_by=line_item`, this field provides the line item of the grouped costs result.

project\_id

string

When `group_by=project_id`, this field provides the project ID of the grouped costs result.

OBJECT Costs object

```JSON
1
2
3
4
5
6
7
8
9
{
    "object": "orgainzation.costs.result",
    "amount": {
      "value": 0.06,
      "currency": "usd"
    },
    "line_item": "Image models",
    "project_id": "proj_abc"
}
```

## Realtime  Beta

Communicate with a GPT-4o class model live, in real time, over WebSocket.
Produces both audio and text transcriptions.
[Learn more about the Realtime API](/docs/guides/realtime).

## Client events

These are events that the OpenAI Realtime WebSocket server will accept from the client.

## session.update

Send this event to update the session’s default configuration. The client may
send this event at any time to update the session configuration, and any
field may be updated at any time, except for "voice". The server will respond
with a `session.updated` event that shows the full effective configuration.
Only fields that are present are updated, thus the correct way to clear a
field like "instructions" is to pass an empty string.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `session.update`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.update

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
{
    "event_id": "event_123",
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a helpful assistant.",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "tools": [\
            {\
                "type": "function",\
                "name": "get_weather",\
                "description": "Get the current weather...",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "location": { "type": "string" }\
                    },\
                    "required": ["location"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## input\_audio\_buffer.append

Send this event to append audio bytes to the input audio buffer. The audio
buffer is temporary storage you can write to and later commit. In Server VAD
mode, the audio buffer is used to detect speech and the server will decide
when to commit. When Server VAD is disabled, you must commit the audio buffer
manually.

The client may choose how much audio to place in each event up to a maximum
of 15 MiB, for example streaming smaller chunks from the client may allow the
VAD to be more responsive. Unlike made other client events, the server will
not send a confirmation response to this event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.append`.

audio

string

Base64-encoded audio bytes. This must be in the format specified by the
`input_audio_format` field in the session configuration.

OBJECT input\_audio\_buffer.append

```JSON
1
2
3
4
5
{
    "event_id": "event_456",
    "type": "input_audio_buffer.append",
    "audio": "Base64EncodedAudioData"
}
```

## input\_audio\_buffer.commit

Send this event to commit the user input audio buffer, which will create a
new user message item in the conversation. This event will produce an error
if the input audio buffer is empty. When in Server VAD mode, the client does
not need to send this event, the server will commit the audio buffer
automatically.

Committing the input audio buffer will trigger input audio transcription
(if enabled in session configuration), but it will not create a response
from the model. The server will respond with an `input_audio_buffer.committed`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.commit`.

OBJECT input\_audio\_buffer.commit

```JSON
1
2
3
4
{
    "event_id": "event_789",
    "type": "input_audio_buffer.commit"
}
```

## input\_audio\_buffer.clear

Send this event to clear the audio bytes in the buffer. The server will
respond with an `input_audio_buffer.cleared` event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `input_audio_buffer.clear`.

OBJECT input\_audio\_buffer.clear

```JSON
1
2
3
4
{
    "event_id": "event_012",
    "type": "input_audio_buffer.clear"
}
```

## conversation.item.create

Add a new Item to the Conversation's context, including messages, function
calls, and function call responses. This event can be used both to populate a
"history" of the conversation and to add new items mid-stream, but has the
current limitation that it cannot populate assistant audio messages.

If successful, the server will respond with a `conversation.item.created`
event, otherwise an `error` event will be sent.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.create`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.
If not set, the new item will be appended to the end of the conversation.
If set, it allows an item to be inserted mid-conversation. If the ID
cannot be found, an error will be returned and the item will not be added.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
{
    "event_id": "event_345",
    "type": "conversation.item.create",
    "previous_item_id": null,
    "item": {
        "id": "msg_001",
        "type": "message",
        "role": "user",
        "content": [\
            {\
                "type": "input_text",\
                "text": "Hello, how are you?"\
            }\
        ]
    }
}
```

## conversation.item.truncate

Send this event to truncate a previous assistant message’s audio. The server
will produce audio faster than realtime, so this event is useful when the user
interrupts to truncate audio that has already been sent to the client but not
yet played. This will synchronize the server's understanding of the audio with
the client's playback.

Truncating audio will delete the server-side text transcript to ensure there
is not text in the context that hasn't been heard by the user.

If successful, the server will respond with a `conversation.item.truncated`
event.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.truncate`.

item\_id

string

The ID of the assistant message item to truncate. Only assistant message
items can be truncated.

content\_index

integer

The index of the content part to truncate. Set this to 0.

audio\_end\_ms

integer

Inclusive duration up to which audio is truncated, in milliseconds. If
the audio\_end\_ms is greater than the actual audio duration, the server
will respond with an error.

OBJECT conversation.item.truncate

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_678",
    "type": "conversation.item.truncate",
    "item_id": "msg_002",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.delete

Send this event when you want to remove any item from the conversation
history. The server will respond with a `conversation.item.deleted` event,
unless the item does not exist in the conversation history, in which case the
server will respond with an error.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `conversation.item.delete`.

item\_id

string

The ID of the item to delete.

OBJECT conversation.item.delete

```JSON
1
2
3
4
5
{
    "event_id": "event_901",
    "type": "conversation.item.delete",
    "item_id": "msg_003"
}
```

## response.create

This event instructs the server to create a Response, which means triggering
model inference. When in Server VAD mode, the server will create Responses
automatically.

A Response will include at least one Item, and may have two, in which case
the second will be a function call. These Items will be appended to the
conversation history.

The server will respond with a `response.created` event, events for Items
and content created, and finally a `response.done` event to indicate the
Response is complete.

The `response.create` event includes inference configuration like
`instructions`, and `temperature`. These fields will override the Session's
configuration for this Response only.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.create`.

response

object

Realtime session object configuration.

Show properties

OBJECT response.create

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
{
    "event_id": "event_234",
    "type": "response.create",
    "response": {
        "modalities": ["text", "audio"],
        "instructions": "Please assist the user.",
        "voice": "sage",
        "output_audio_format": "pcm16",
        "tools": [\
            {\
                "type": "function",\
                "name": "calculate_sum",\
                "description": "Calculates the sum of two numbers.",\
                "parameters": {\
                    "type": "object",\
                    "properties": {\
                        "a": { "type": "number" },\
                        "b": { "type": "number" }\
                    },\
                    "required": ["a", "b"]\
                }\
            }\
        ],
        "tool_choice": "auto",
        "temperature": 0.7,
        "max_output_tokens": 150
    }
}
```

## response.cancel

Send this event to cancel an in-progress response. The server will respond
with a `response.cancelled` event or an error if there is no response to
cancel.

event\_id

string

Optional client-generated ID used to identify this event.

type

string

The event type, must be `response.cancel`.

OBJECT response.cancel

```JSON
1
2
3
4
{
    "event_id": "event_567",
    "type": "response.cancel"
}
```

## Server events

These are events emitted from the OpenAI Realtime WebSocket server to the client.

## error

Returned when an error occurs, which could be a client problem or a server
problem. Most errors are recoverable and the session will stay open, we
recommend to implementors to monitor and log error messages by default.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `error`.

error

object

Details of the error.

Show properties

OBJECT error

```JSON
1
2
3
4
5
6
7
8
9
10
11
{
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
        "param": null,
        "event_id": "event_567"
    }
}
```

## session.created

Returned when a Session is created. Emitted automatically when a new
connection is established as the first server event. This event will contain
the default Session configuration.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.created`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
{
    "event_id": "event_1234",
    "type": "session.created",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text", "audio"],
        "instructions": "...model instructions here...",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": null,
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 200
        },
        "tools": [],
        "tool_choice": "auto",
        "temperature": 0.8,
        "max_response_output_tokens": "inf"
    }
}
```

## session.updated

Returned when a session is updated with a `session.update` event, unless
there is an error.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `session.updated`.

session

object

Realtime session object configuration.

Show properties

OBJECT session.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
    "event_id": "event_5678",
    "type": "session.updated",
    "session": {
        "id": "sess_001",
        "object": "realtime.session",
        "model": "gpt-4o-realtime-preview-2024-10-01",
        "modalities": ["text"],
        "instructions": "New instructions",
        "voice": "sage",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": null,
        "tools": [],
        "tool_choice": "none",
        "temperature": 0.7,
        "max_response_output_tokens": 200
    }
}
```

## conversation.created

Returned when a conversation is created. Emitted right after session creation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.created`.

conversation

object

The conversation resource.

Show properties

OBJECT conversation.created

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_9101",
    "type": "conversation.created",
    "conversation": {
        "id": "conv_001",
        "object": "realtime.conversation"
    }
}
```

## conversation.item.created

Returned when a conversation item is created. There are several scenarios that
produce this event:

- The server is generating a Response, which if successful will produce
either one or two Items, which will be of type `message`
(role `assistant`) or type `function_call`.
- The input audio buffer has been committed, either by the client or the
server (in `server_vad` mode). The server will take the content of the
input audio buffer and add it to a new user message Item.
- The client has sent a `conversation.item.create` event to add a new Item
to the Conversation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.created`.

previous\_item\_id

string

The ID of the preceding item in the Conversation context, allows the
client to understand the order of the conversation.

item

object

The item to add to the conversation.

Show properties

OBJECT conversation.item.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_1920",
    "type": "conversation.item.created",
    "previous_item_id": "msg_002",
    "item": {
        "id": "msg_003",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "user",
        "content": [\
            {\
                "type": "input_audio",\
                "transcript": "hello how are you",\
                "audio": "base64encodedaudio=="\
            }\
        ]
    }
}
```

## conversation.item.input\_audio\_transcription.completed

This event is the output of audio transcription for user audio written to the
user audio buffer. Transcription begins when the input audio buffer is
committed by the client or server (in `server_vad` mode). Transcription runs
asynchronously with Response creation, so this event may come before or after
the Response events.

Realtime API models accept audio natively, and thus input transcription is a
separate process run on a separate ASR (Automatic Speech Recognition) model,
currently always `whisper-1`. Thus the transcript may diverge somewhat from
the model's interpretation, and should be treated as a rough guide.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.completed`.

item\_id

string

The ID of the user message item containing the audio.

content\_index

integer

The index of the content part containing the audio.

transcript

string

The transcribed text.

OBJECT conversation.item.input\_audio\_transcription.completed

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2122",
    "type": "conversation.item.input_audio_transcription.completed",
    "item_id": "msg_003",
    "content_index": 0,
    "transcript": "Hello, how are you?"
}
```

## conversation.item.input\_audio\_transcription.failed

Returned when input audio transcription is configured, and a transcription
request for a user message failed. These events are separate from other
`error` events so that the client can identify the related Item.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be
`conversation.item.input_audio_transcription.failed`.

item\_id

string

The ID of the user message item.

content\_index

integer

The index of the content part containing the audio.

error

object

Details of the transcription error.

Show properties

OBJECT conversation.item.input\_audio\_transcription.failed

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2324",
    "type": "conversation.item.input_audio_transcription.failed",
    "item_id": "msg_003",
    "content_index": 0,
    "error": {
        "type": "transcription_error",
        "code": "audio_unintelligible",
        "message": "The audio could not be transcribed.",
        "param": null
    }
}
```

## conversation.item.truncated

Returned when an earlier assistant audio message item is truncated by the
client with a `conversation.item.truncate` event. This event is used to
synchronize the server's understanding of the audio with the client's playback.

This action will truncate the audio and remove the server-side text transcript
to ensure there is no text in the context that hasn't been heard by the user.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.truncated`.

item\_id

string

The ID of the assistant message item that was truncated.

content\_index

integer

The index of the content part that was truncated.

audio\_end\_ms

integer

The duration up to which the audio was truncated, in milliseconds.

OBJECT conversation.item.truncated

```JSON
1
2
3
4
5
6
7
{
    "event_id": "event_2526",
    "type": "conversation.item.truncated",
    "item_id": "msg_004",
    "content_index": 0,
    "audio_end_ms": 1500
}
```

## conversation.item.deleted

Returned when an item in the conversation is deleted by the client with a
`conversation.item.delete` event. This event is used to synchronize the
server's understanding of the conversation history with the client's view.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `conversation.item.deleted`.

item\_id

string

The ID of the item that was deleted.

OBJECT conversation.item.deleted

```JSON
1
2
3
4
5
{
    "event_id": "event_2728",
    "type": "conversation.item.deleted",
    "item_id": "msg_005"
}
```

## input\_audio\_buffer.committed

Returned when an input audio buffer is committed, either by the client or
automatically in server VAD mode. The `item_id` property is the ID of the user
message item that will be created, thus a `conversation.item.created` event
will also be sent to the client.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.committed`.

previous\_item\_id

string

The ID of the preceding item after which the new item will be inserted.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.committed

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1121",
    "type": "input_audio_buffer.committed",
    "previous_item_id": "msg_001",
    "item_id": "msg_002"
}
```

## input\_audio\_buffer.cleared

Returned when the input audio buffer is cleared by the client with a
`input_audio_buffer.clear` event.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.cleared`.

OBJECT input\_audio\_buffer.cleared

```JSON
1
2
3
4
{
    "event_id": "event_1314",
    "type": "input_audio_buffer.cleared"
}
```

## input\_audio\_buffer.speech\_started

Sent by the server when in `server_vad` mode to indicate that speech has been
detected in the audio buffer. This can happen any time audio is added to the
buffer (unless speech is already detected). The client may want to use this
event to interrupt audio playback or provide visual feedback to the user.

The client should expect to receive a `input_audio_buffer.speech_stopped` event
when speech stops. The `item_id` property is the ID of the user message item
that will be created when speech stops and will also be included in the
`input_audio_buffer.speech_stopped` event (unless the client manually commits
the audio buffer during VAD activation).

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_started`.

audio\_start\_ms

integer

Milliseconds from the start of all audio written to the buffer during the
session when speech was first detected. This will correspond to the
beginning of audio sent to the model, and thus includes the
`prefix_padding_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created when speech stops.

OBJECT input\_audio\_buffer.speech\_started

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1516",
    "type": "input_audio_buffer.speech_started",
    "audio_start_ms": 1000,
    "item_id": "msg_003"
}
```

## input\_audio\_buffer.speech\_stopped

Returned in `server_vad` mode when the server detects the end of speech in
the audio buffer. The server will also send an `conversation.item.created`
event with the user message item that is created from the audio buffer.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `input_audio_buffer.speech_stopped`.

audio\_end\_ms

integer

Milliseconds since the session started when speech stopped. This will
correspond to the end of audio sent to the model, and thus includes the
`min_silence_duration_ms` configured in the Session.

item\_id

string

The ID of the user message item that will be created.

OBJECT input\_audio\_buffer.speech\_stopped

```JSON
1
2
3
4
5
6
{
    "event_id": "event_1718",
    "type": "input_audio_buffer.speech_stopped",
    "audio_end_ms": 2000,
    "item_id": "msg_003"
}
```

## response.created

Returned when a new Response is created. The first event of response creation,
where the response is in an initial state of `in_progress`.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.created`.

response

object

The response resource.

Show properties

OBJECT response.created

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_2930",
    "type": "response.created",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "in_progress",
        "status_details": null,
        "output": [],
        "usage": null
    }
}
```

## response.done

Returned when a Response is done streaming. Always emitted, no matter the
final state. The Response object included in the `response.done` event will
include all output Items in the Response but will omit the raw audio data.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.done`.

response

object

The response resource.

Show properties

OBJECT response.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
{
    "event_id": "event_3132",
    "type": "response.done",
    "response": {
        "id": "resp_001",
        "object": "realtime.response",
        "status": "completed",
        "status_details": null,
        "output": [\
            {\
                "id": "msg_006",\
                "object": "realtime.item",\
                "type": "message",\
                "status": "completed",\
                "role": "assistant",\
                "content": [\
                    {\
                        "type": "text",\
                        "text": "Sure, how can I assist you today?"\
                    }\
                ]\
            }\
        ],
        "usage": {
            "total_tokens":275,
            "input_tokens":127,
            "output_tokens":148,
            "input_token_details": {
                "cached_tokens":384,
                "text_tokens":119,
                "audio_tokens":8,
                "cached_tokens_details": {
                    "text_tokens": 128,
                    "audio_tokens": 256
                }
            },
            "output_token_details": {
              "text_tokens":36,
              "audio_tokens":112
            }
        }
    }
}
```

## response.output\_item.added

Returned when a new Item is created during Response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.added`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

## response.output\_item.done

Returned when an Item is done streaming. Also emitted when a Response is
interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.output_item.done`.

response\_id

string

The ID of the Response to which the item belongs.

output\_index

integer

The index of the output item in the Response.

item

object

The item to add to the conversation.

Show properties

OBJECT response.output\_item.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [\
            {\
                "type": "text",\
                "text": "Sure, I can help with that."\
            }\
        ]
    }
}
```

## response.content\_part.added

Returned when a new content part is added to an assistant message item during
response generation.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.added`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item to which the content part was added.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that was added.

Show properties

OBJECT response.content\_part.added

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

## response.content\_part.done

Returned when a content part is done streaming in an assistant message item.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.content_part.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

part

object

The content part that is done.

Show properties

OBJECT response.content\_part.done

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
{
    "event_id": "event_3940",
    "type": "response.content_part.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": "Sure, I can help with that."
    }
}
```

## response.text.delta

Returned when the text value of a "text" content part is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The text delta.

OBJECT response.text.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4142",
    "type": "response.text.delta",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "delta": "Sure, I can h"
}
```

## response.text.done

Returned when the text value of a "text" content part is done streaming. Also
emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.text.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

text

string

The final text content.

OBJECT response.text.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4344",
    "type": "response.text.done",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "text": "Sure, I can help with that."
}
```

## response.audio\_transcript.delta

Returned when the model-generated transcription of audio output is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

The transcript delta.

OBJECT response.audio\_transcript.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4546",
    "type": "response.audio_transcript.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Hello, how can I a"
}
```

## response.audio\_transcript.done

Returned when the model-generated transcription of audio output is done
streaming. Also emitted when a Response is interrupted, incomplete, or
cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio_transcript.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

transcript

string

The final transcript of the audio.

OBJECT response.audio\_transcript.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4748",
    "type": "response.audio_transcript.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "transcript": "Hello, how can I assist you today?"
}
```

## response.audio.delta

Returned when the model-generated audio is updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

delta

string

Base64-encoded audio data delta.

OBJECT response.audio.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_4950",
    "type": "response.audio.delta",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0,
    "delta": "Base64EncodedAudioDelta"
}
```

## response.audio.done

Returned when the model-generated audio is done. Also emitted when a Response
is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.audio.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the item.

output\_index

integer

The index of the output item in the response.

content\_index

integer

The index of the content part in the item's content array.

OBJECT response.audio.done

```JSON
1
2
3
4
5
6
7
8
{
    "event_id": "event_5152",
    "type": "response.audio.done",
    "response_id": "resp_001",
    "item_id": "msg_008",
    "output_index": 0,
    "content_index": 0
}
```

## response.function\_call\_arguments.delta

Returned when the model-generated function call arguments are updated.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.delta`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

delta

string

The arguments delta as a JSON string.

OBJECT response.function\_call\_arguments.delta

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5354",
    "type": "response.function_call_arguments.delta",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "delta": "{\"location\": \"San\""
}
```

## response.function\_call\_arguments.done

Returned when the model-generated function call arguments are done streaming.
Also emitted when a Response is interrupted, incomplete, or cancelled.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `response.function_call_arguments.done`.

response\_id

string

The ID of the response.

item\_id

string

The ID of the function call item.

output\_index

integer

The index of the output item in the response.

call\_id

string

The ID of the function call.

arguments

string

The final arguments as a JSON string.

OBJECT response.function\_call\_arguments.done

```JSON
1
2
3
4
5
6
7
8
9
{
    "event_id": "event_5556",
    "type": "response.function_call_arguments.done",
    "response_id": "resp_002",
    "item_id": "fc_001",
    "output_index": 0,
    "call_id": "call_001",
    "arguments": "{\"location\": \"San Francisco\"}"
}
```

## rate\_limits.updated

Emitted at the beginning of a Response to indicate the updated rate limits.
When a Response is created some tokens will be "reserved" for the output
tokens, the rate limits shown here reflect that reservation, which is then
adjusted accordingly once the Response is completed.

event\_id

string

The unique ID of the server event.

type

string

The event type, must be `rate_limits.updated`.

rate\_limits

array

List of rate limit information.

Show properties

OBJECT rate\_limits.updated

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
    "event_id": "event_5758",
    "type": "rate_limits.updated",
    "rate_limits": [\
        {\
            "name": "requests",\
            "limit": 1000,\
            "remaining": 999,\
            "reset_seconds": 60\
        },\
        {\
            "name": "tokens",\
            "limit": 50000,\
            "remaining": 49950,\
            "reset_seconds": 60\
        }\
    ]
}
```

## Completions  Legacy

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation#text-generation-models) to leverage our best and newest models.

## Create completion  Legacy

posthttps://api.openai.com/v1/completions

Creates a completion for the provided prompt and parameters.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <\|endoftext\|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

best\_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

frequency\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

logit\_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <\|endoftext\|> token from being generated.

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

max\_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

presence\_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

stream\_options

object or null

Optional

Defaults to null

Options for streaming response. Only set this when you set `stream: true`.

Show properties

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

This parameter is only supported for `gpt-3.5-turbo-instruct`.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streamingNo streamingStreamingStreaming

Example request

gpt-3.5-turbo-instruct

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo-instruct",
    "prompt": "Say this is a test",
    "max_tokens": 7,
    "temperature": 0
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-3.5-turbo-instruct",
  "system_fingerprint": "fp_44709d6fcb",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## The completion object  Legacy

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

id

string

A unique identifier for the completion.

choices

array

The list of completion choices the model generated for the input prompt.

Show properties

created

integer

The Unix timestamp (in seconds) of when the completion was created.

model

string

The model used for completion.

system\_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

object

string

The object type, which is always "text\_completion"

usage

object

Usage statistics for the completion request.

Show properties

OBJECT The completion object

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
  "object": "text_completion",
  "created": 1589478378,
  "model": "gpt-4-turbo",
  "choices": [\
    {\
      "text": "\n\nThis is indeed a test",\
      "index": 0,\
      "logprobs": null,\
      "finish_reason": "length"\
    }\
  ],
  "usage": {
    "prompt_tokens": 5,
    "completion_tokens": 7,
    "total_tokens": 12
  }
}
```

## Assistants (v1)  Legacy

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

## Create assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants

Create an assistant with a model and instructions.

### Request body

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

An [assistant](/docs/api-reference/assistants-v1/object) object.

Code InterpreterCode InterpreterFilesFiles

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl "https://api.openai.com/v1/assistants" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
    "name": "Math Tutor",
    "tools": [{"type": "code_interpreter"}],
    "model": "gpt-4-turbo"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Create assistant file (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}/files

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants-v1).

### Path parameters

assistant\_id

string

Required

The ID of the assistant for which to create a File.

### Request body

file\_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/assistants/asst_abc123/files \
    -H 'Authorization: Bearer $OPENAI_API_KEY"' \
    -H 'Content-Type: application/json' \
    -H 'OpenAI-Beta: assistants=v1' \
    -d '{
      "file_id": "file-abc123"
    }'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## List assistants (v1)  Legacy

gethttps://api.openai.com/v1/assistants

Returns a list of assistants.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "object": "list",
  "data": [\
    {\
      "id": "asst_abc123",\
      "object": "assistant",\
      "created_at": 1698982736,\
      "name": "Coding Tutor",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc456",\
      "object": "assistant",\
      "created_at": 1698982718,\
      "name": "My Assistant",\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": "You are a helpful assistant designed to make me better at coding!",\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    },\
    {\
      "id": "asst_abc789",\
      "object": "assistant",\
      "created_at": 1698982643,\
      "name": null,\
      "description": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "tools": [],\
      "file_ids": [],\
      "metadata": {},\
      "top_p": 1.0,\
      "temperature": 1.0,\
      "response_format": "auto"\
    }\
  ],
  "first_id": "asst_abc123",
  "last_id": "asst_abc789",
  "has_more": false
}
```

## List assistant files (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files

Returns a list of assistant files.

### Path parameters

assistant\_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    },\
    {\
      "id": "file-abc456",\
      "object": "assistant.file",\
      "created_at": 1699060412,\
      "assistant_id": "asst_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc456",
  "has_more": false
}
```

## Retrieve assistant (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}

Retrieves an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123"\
  ],
  "metadata": {}
}
```

## Retrieve assistant file (v1)  Legacy

gethttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Retrieves an AssistantFile.

### Path parameters

assistant\_id

string

Required

The ID of the assistant who the file belongs to.

file\_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants-v1/file-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H 'Authorization: Bearer $OPENAI_API_KEY"' \
  -H 'Content-Type: application/json' \
  -H 'OpenAI-Beta: assistants=v1'
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Modify assistant (v1)  Legacy

posthttps://api.openai.com/v1/assistants/{assistant\_id}

Modifies an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to modify.

### Request body

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

The modified [assistant](/docs/api-reference/assistants-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [{"type": "retrieval"}],
      "model": "gpt-4-turbo",
      "file_ids": ["file-abc123", "file-abc456"]
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1699009709,
  "name": "HR Helper",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## Delete assistant (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}

Delete an assistant.

### Path parameters

assistant\_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "asst_abc123",
  "object": "assistant.deleted",
  "deleted": true
}
```

## Delete assistant file (v1)  Legacy

deletehttps://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}

Delete an assistant file.

### Path parameters

assistant\_id

string

Required

The ID of the assistant that the file belongs to.

file\_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/assistants/asst_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  id: "file-abc123",
  object: "assistant.file.deleted",
  deleted: true
}
```

## The assistant object (v1)  Legacy

Represents an `assistant` that can call the model and use tools.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

name

string or null

The name of the assistant. The maximum length is 256 characters.

description

string or null

The description of the assistant. The maximum length is 512 characters.

model

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models#overview) for descriptions of them. type: string

instructions

string or null

The system instructions that the assistant uses. The maximum length is 256,000 characters.

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Show possible types

file\_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The assistant object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
{
  "id": "asst_abc123",
  "object": "assistant",
  "created_at": 1698984975,
  "name": "Math Tutor",
  "description": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "top_p": 1.0,
  "temperature": 1.0,
  "response_format": "auto"
}
```

## The assistant file object (v1)  Legacy

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `assistant.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

assistant\_id

string

The assistant ID that the file is attached to.

OBJECT The assistant file object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "assistant.file",
  "created_at": 1699055364,
  "assistant_id": "asst_abc123"
}
```

## Threads (v1)  Legacy

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

## Create thread (v1)  Legacy

posthttps://api.openai.com/v1/threads

Create a thread.

### Request body

messages

array

Optional

A list of [messages](/docs/api-reference/messages-v1) to start the thread with.

Show properties

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads-v1) object.

EmptyEmptyMessagesMessages

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d ''
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699012949,
  "metadata": {}
}
```

## Retrieve thread (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}

Retrieves a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {}
}
```

## Modify thread (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}

Modifies a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1699014083,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## Delete thread (v1)  Legacy

deletehttps://api.openai.com/v1/threads/{thread\_id}

Delete a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

curl

```bash
1
2
3
4
5
curl https://api.openai.com/v1/threads/thread_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X DELETE
```

Response

```json
1
2
3
4
5
{
  "id": "thread_abc123",
  "object": "thread.deleted",
  "deleted": true
}
```

## The thread object (v1)  Legacy

Represents a thread that contains [messages](/docs/api-reference/messages-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread`.

created\_at

integer

The Unix timestamp (in seconds) for when the thread was created.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The thread object (v1)

```JSON
1
2
3
4
5
6
{
  "id": "thread_abc123",
  "object": "thread",
  "created_at": 1698107661,
  "metadata": {}
}
```

## Messages (v1)  Legacy

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

## Create message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages

Create a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to create a message for.

### Request body

role

string

Required

The role of the entity that is creating the message. Allowed values include:

- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.

content

string

Required

The content of the message.

file\_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages-v1/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "role": "user",
      "content": "How does AI work? Explain it in simple terms."
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## List messages (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages

Returns a list of messages for a given thread.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) the messages belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

run\_id

string

Optional

Filter messages by the run ID that generated them.

### Returns

A list of [message](/docs/api-reference/messages-v1) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
{
  "object": "list",
  "data": [\
    {\
      "id": "msg_abc123",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "How does AI work? Explain it in simple terms.",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    },\
    {\
      "id": "msg_abc456",\
      "object": "thread.message",\
      "created_at": 1699016383,\
      "thread_id": "thread_abc123",\
      "role": "user",\
      "content": [\
        {\
          "type": "text",\
          "text": {\
            "value": "Hello, what is AI?",\
            "annotations": []\
          }\
        }\
      ],\
      "file_ids": [\
        "file-abc123"\
      ],\
      "assistant_id": null,\
      "run_id": null,\
      "metadata": {}\
    }\
  ],
  "first_id": "msg_abc123",
  "last_id": "msg_abc456",
  "has_more": false
}
```

## List message files (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files

Returns a list of message files.

### Path parameters

thread\_id

string

Required

The ID of the thread that the message and files belong to.

message\_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages-v1/file-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "object": "list",
  "data": [\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    },\
    {\
      "id": "file-abc123",\
      "object": "thread.message.file",\
      "created_at": 1699061776,\
      "message_id": "msg_abc123"\
    }\
  ],
  "first_id": "file-abc123",
  "last_id": "file-abc123",
  "has_more": false
}
```

## Retrieve message (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Retrieve a message.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this message belongs.

message\_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads-v1/messages/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {}
}
```

## Retrieve message file (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}

Retrieves a message file.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the message and File belong.

message\_id

string

Required

The ID of the message the file belongs to.

file\_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages-v1/file-object) object.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123/files/file-abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1699061776,
  "message_id": "msg_abc123"
}
```

## Modify message (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}

Modifies a message.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this message belongs.

message\_id

string

Required

The ID of the message to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads-v1/messages/object) object.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1699017614,
  "thread_id": "thread_abc123",
  "role": "user",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "How does AI work? Explain it in simple terms.",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": null,
  "run_id": null,
  "metadata": {
    "modified": "true",
    "user": "abc123"
  }
}
```

## The message object (v1)  Legacy

Represents a message within a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message`.

created\_at

integer

The Unix timestamp (in seconds) for when the message was created.

thread\_id

string

The [thread](/docs/api-reference/threads-v1) ID that this message belongs to.

status

string

The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.

incomplete\_details

object or null

On an incomplete message, details about why the message is incomplete.

Show properties

completed\_at

integer or null

The Unix timestamp (in seconds) for when the message was completed.

incomplete\_at

integer or null

The Unix timestamp (in seconds) for when the message was marked as incomplete.

role

string

The entity that produced the message. One of `user` or `assistant`.

content

array

The content of the message in array of text and/or images.

Show possible types

assistant\_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants-v1) that authored this message.

run\_id

string or null

The ID of the [run](/docs/api-reference/runs-v1) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.

file\_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code\_interpreter that can access files. A maximum of 10 files can be attached to a message.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

OBJECT The message object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
{
  "id": "msg_abc123",
  "object": "thread.message",
  "created_at": 1698983503,
  "thread_id": "thread_abc123",
  "role": "assistant",
  "content": [\
    {\
      "type": "text",\
      "text": {\
        "value": "Hi! How can I help you today?",\
        "annotations": []\
      }\
    }\
  ],
  "file_ids": [],
  "assistant_id": "asst_abc123",
  "run_id": "run_abc123",
  "metadata": {}
}
```

## The message file object (v1)  Legacy

A list of files attached to a `message`.

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.file`.

created\_at

integer

The Unix timestamp (in seconds) for when the message file was created.

message\_id

string

The ID of the [message](/docs/api-reference/messages-v1) that the [File](/docs/api-reference/files) is attached to.

OBJECT The message file object (v1)

```JSON
1
2
3
4
5
6
7
{
  "id": "file-abc123",
  "object": "thread.message.file",
  "created_at": 1698107661,
  "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
  "file_id": "file-abc123"
}
```

## Runs (v1)  Legacy

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

## Create run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs

Create a run.

### Path parameters

thread\_id

string

Required

The ID of the thread to run.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants-v1/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

additional\_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

additional\_messages

array or null

Optional

Adds additional messages to the thread before creating the run.

Show properties

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Show possible types

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "assistant_id": "asst_abc123"
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699063290,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": 1699063290,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699063291,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Create thread and run (v1)  Legacy

posthttps://api.openai.com/v1/threads/runs

Create a thread and run it in one request.

### Request body

assistant\_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants-v1) to use to execute this run.

thread

object

Optional

Show properties

model

string

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

top\_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top\_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

max\_prompt\_tokens

integer or null

Optional

The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

max\_completion\_tokens

integer or null

Optional

The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `complete`. See `incomplete_details` for more info.

truncation\_strategy

object

Optional

Show properties

tool\_choice

string or object

Optional

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Optional

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

### Returns

A [run](/docs/api-reference/runs-v1/object) object.

DefaultDefaultStreamingStreamingStreaming with FunctionsStreaming with Functions

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
      "assistant_id": "asst_abc123",
      "thread": {
        "messages": [\
          {"role": "user", "content": "Explain deep learning to a 5 year old."}\
        ]
      }
    }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076792,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "queued",
  "started_at": null,
  "expires_at": 1699077392,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You are a helpful assistant.",
  "tools": [],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1
}
```

## List runs (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs

Returns a list of runs belonging to a thread.

### Path parameters

thread\_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs-v1/object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
{
  "object": "list",
  "data": [\
    {\
      "id": "run_abc123",\
      "object": "thread.run",\
      "created_at": 1699075072,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699075072,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699075073,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    },\
    {\
      "id": "run_abc456",\
      "object": "thread.run",\
      "created_at": 1699063290,\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "status": "completed",\
      "started_at": 1699063290,\
      "expires_at": null,\
      "cancelled_at": null,\
      "failed_at": null,\
      "completed_at": 1699063291,\
      "last_error": null,\
      "model": "gpt-4-turbo",\
      "instructions": null,\
      "incomplete_details": null,\
      "tools": [\
        {\
          "type": "code_interpreter"\
        }\
      ],\
      "file_ids": [\
        "file-abc123",\
        "file-abc456"\
      ],\
      "metadata": {},\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      },\
      "temperature": 1.0,\
      "top_p": 1.0,\
      "max_prompt_tokens": 1000,\
      "max_completion_tokens": 1000,\
      "truncation_strategy": {\
        "type": "auto",\
        "last_messages": null\
      },\
      "response_format": "auto",\
      "tool_choice": "auto"\
    }\
  ],
  "first_id": "run_abc123",
  "last_id": "run_abc456",
  "has_more": false
}
```

## List run steps (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps

Returns a list of run steps belonging to a run.

### Path parameters

thread\_id

string

Required

The ID of the thread the run and run steps belong to.

run\_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include after=obj\_foo in order to fetch the next page of the list.

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj\_foo, your subsequent call can include before=obj\_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs-v1/step-object) objects.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
{
  "object": "list",
  "data": [\
    {\
      "id": "step_abc123",\
      "object": "thread.run.step",\
      "created_at": 1699063291,\
      "run_id": "run_abc123",\
      "assistant_id": "asst_abc123",\
      "thread_id": "thread_abc123",\
      "type": "message_creation",\
      "status": "completed",\
      "cancelled_at": null,\
      "completed_at": 1699063291,\
      "expired_at": null,\
      "failed_at": null,\
      "last_error": null,\
      "step_details": {\
        "type": "message_creation",\
        "message_creation": {\
          "message_id": "msg_abc123"\
        }\
      },\
      "usage": {\
        "prompt_tokens": 123,\
        "completion_tokens": 456,\
        "total_tokens": 579\
      }\
    }\
  ],
  "first_id": "step_abc123",
  "last_id": "step_abc456",
  "has_more": false
}
```

## Retrieve run (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Retrieves a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {},
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Retrieve run step (v1)  Legacy

gethttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}

Retrieves a run step.

### Path parameters

thread\_id

string

Required

The ID of the thread to which the run and run step belongs.

run\_id

string

Required

The ID of the run to which the run step belongs.

step\_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs-v1/step-object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1"
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Modify run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}

Modifies a run.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

Required

The ID of the run to modify.

### Request body

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "metadata": {
      "user_id": "user_abc123"
    }
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699075072,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699075072,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699075073,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "code_interpreter"\
    }\
  ],
  "file_ids": [\
    "file-abc123",\
    "file-abc456"\
  ],
  "metadata": {
    "user_id": "user_abc123"
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Submit tool outputs to run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

thread\_id

string

Required

The ID of the [thread](/docs/api-reference/threads-v1) to which this run belongs.

run\_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

tool\_outputs

array

Required

A list of tools for which the outputs are being submitted.

Show properties

stream

boolean or null

Optional

If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

DefaultDefaultStreamingStreaming

Example request

curl

```bash
1
2
3
4
5
6
7
8
9
10
11
12
curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -H "OpenAI-Beta: assistants=v1" \
  -d '{
    "tool_outputs": [\
      {\
        "tool_call_id": "call_001",\
        "output": "70 degrees and sunny."\
      }\
    ]
  }'
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
{
  "id": "run_123",
  "object": "thread.run",
  "created_at": 1699075592,
  "assistant_id": "asst_123",
  "thread_id": "thread_123",
  "status": "queued",
  "started_at": 1699075592,
  "expires_at": 1699076192,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "incomplete_details": null,
  "tools": [\
    {\
      "type": "function",\
      "function": {\
        "name": "get_current_weather",\
        "description": "Get the current weather in a given location",\
        "parameters": {\
          "type": "object",\
          "properties": {\
            "location": {\
              "type": "string",\
              "description": "The city and state, e.g. San Francisco, CA"\
            },\
            "unit": {\
              "type": "string",\
              "enum": ["celsius", "fahrenheit"]\
            }\
          },\
          "required": ["location"]\
        }\
      }\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## Cancel a run (v1)  Legacy

posthttps://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel

Cancels a run that is `in_progress`.

### Path parameters

thread\_id

string

Required

The ID of the thread to which this run belongs.

run\_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs-v1/object) object matching the specified ID.

Example request

curl

```bash
1
2
3
4
curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "OpenAI-Beta: assistants=v1" \
  -X POST
```

Response

```json
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1699076126,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "cancelling",
  "started_at": 1699076126,
  "expires_at": 1699076726,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": null,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": "You summarize books.",
  "tools": [\
    {\
      "type": "retrieval"\
    }\
  ],
  "file_ids": [],
  "metadata": {},
  "usage": null,
  "temperature": 1.0,
  "top_p": 1.0,
}
```

## The run object (v1)  Legacy

Represents an execution run on a [thread](/docs/api-reference/threads-v1).

id

string

The identifier, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run`.

created\_at

integer

The Unix timestamp (in seconds) for when the run was created.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was executed on as a part of this run.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) used for execution of this run.

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

required\_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Show properties

last\_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Show properties

expires\_at

integer or null

The Unix timestamp (in seconds) for when the run will expire.

started\_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

incomplete\_details

object or null

Details on why the run is incomplete. Will be `null` if the run is not incomplete.

Show properties

model

string

The model that the [assistant](/docs/api-reference/assistants-v1) used for this run.

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants-v1) used for this run.

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants-v1) used for this run.

Show possible types

file\_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants-v1) used for this run.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

temperature

number or null

The sampling temperature used for this run. If not set, defaults to 1.

top\_p

number or null

The nucleus sampling value used for this run. If not set, defaults to 1.

max\_prompt\_tokens

integer or null

The maximum number of prompt tokens specified to have been used over the course of the run.

max\_completion\_tokens

integer or null

The maximum number of completion tokens specified to have been used over the course of the run.

truncation\_strategy

object

Show properties

tool\_choice

string or object

Controls which (if any) tool is called by the model.
`none` means the model will not call any tools and instead generates a message.
`auto` is the default value and means the model can pick between generating a message or calling a tool.
Specifying a particular tool like `{"type": "TOOL_TYPE"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

Show possible types

response\_format

string or object

Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models#gpt-4o), [GPT-4 Turbo](/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show possible types

OBJECT The run object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
{
  "id": "run_abc123",
  "object": "thread.run",
  "created_at": 1698107661,
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "status": "completed",
  "started_at": 1699073476,
  "expires_at": null,
  "cancelled_at": null,
  "failed_at": null,
  "completed_at": 1699073498,
  "last_error": null,
  "model": "gpt-4-turbo",
  "instructions": null,
  "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
  "file_ids": [],
  "metadata": {},
  "incomplete_details": null,
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  },
  "temperature": 1.0,
  "top_p": 1.0,
  "max_prompt_tokens": 1000,
  "max_completion_tokens": 1000,
  "truncation_strategy": {
    "type": "auto",
    "last_messages": null
  },
  "response_format": "auto",
  "tool_choice": "auto"
}
```

## The run step object (v1)  Legacy

Represents a step in execution of a run.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step`.

created\_at

integer

The Unix timestamp (in seconds) for when the run step was created.

assistant\_id

string

The ID of the [assistant](/docs/api-reference/assistants-v1) associated with the run step.

thread\_id

string

The ID of the [thread](/docs/api-reference/threads-v1) that was run.

run\_id

string

The ID of the [run](/docs/api-reference/runs-v1) that this run step is a part of.

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

step\_details

object

The details of the run step.

Show possible types

last\_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Show properties

expired\_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

cancelled\_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

failed\_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

completed\_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

usage

OBJECT The run step object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
{
  "id": "step_abc123",
  "object": "thread.run.step",
  "created_at": 1699063291,
  "run_id": "run_abc123",
  "assistant_id": "asst_abc123",
  "thread_id": "thread_abc123",
  "type": "message_creation",
  "status": "completed",
  "cancelled_at": null,
  "completed_at": 1699063291,
  "expired_at": null,
  "failed_at": null,
  "last_error": null,
  "step_details": {
    "type": "message_creation",
    "message_creation": {
      "message_id": "msg_abc123"
    }
  },
  "usage": {
    "prompt_tokens": 123,
    "completion_tokens": 456,
    "total_tokens": 579
  }
}
```

## Streaming (v1)  Legacy

Stream the result of executing a Run or resuming a Run after submitting tool outputs.

You can stream events from the [Create Thread and Run](/docs/api-reference/runs-v1/createThreadAndRun),
[Create Run](/docs/api-reference/runs-v1/createRun), and [Submit Tool Outputs](/docs/api-reference/runs-v1/submitToolOutputs)
endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
[Assistants API quickstart](/docs/assistants/overview) to learn more.

## The message delta object (v1)  Legacy

Represents a message delta i.e. any changed fields on a message during streaming.

id

string

The identifier of the message, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.message.delta`.

delta

object

The delta containing the fields that have changed on the Message.

Show properties

OBJECT The message delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
{
  "id": "msg_123",
  "object": "thread.message.delta",
  "delta": {
    "content": [\
      {\
        "index": 0,\
        "type": "text",\
        "text": { "value": "Hello", "annotations": [] }\
      }\
    ]
  }
}
```

## The run step delta object (v1)  Legacy

Represents a run step delta i.e. any changed fields on a run step during streaming.

id

string

The identifier of the run step, which can be referenced in API endpoints.

object

string

The object type, which is always `thread.run.step.delta`.

delta

object

The delta containing the fields that have changed on the run step.

Show properties

OBJECT The run step delta object (v1)

```JSON
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{
  "id": "step_123",
  "object": "thread.run.step.delta",
  "delta": {
    "step_details": {
      "type": "tool_calls",
      "tool_calls": [\
        {\
          "index": 0,\
          "id": "call_123",\
          "type": "code_interpreter",\
          "code_interpreter": { "input": "", "outputs": [] }\
        }\
      ]
    }
  }
}
```

## Assistant stream events (v1)  Legacy

Represents an event emitted when streaming a Run.

Each event in a server-sent events stream has an `event` and `data` property:

```text
event: thread.created
data: {"id": "thread_123", "object": "thread", ...}
```

We emit events whenever a new object is created, transitions to a new state, or is being
streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
to create a message during a run, we emit a `thread.message.created event`, a
`thread.message.in_progress` event, many `thread.message.delta` events, and finally a
`thread.message.completed` event.

We may add additional events over time, so we recommend handling unknown events gracefully
in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
integrate the Assistants API with streaming.

thread.created

`data` is a [thread](/docs/api-reference/threads-v1/object)

Occurs when a new [thread](/docs/api-reference/threads-v1/object) is created.

thread.run.created

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a new [run](/docs/api-reference/runs-v1/object) is created.

thread.run.queued

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `queued` status.

thread.run.in\_progress

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to an `in_progress` status.

thread.run.requires\_action

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `requires_action` status.

thread.run.completed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is completed.

thread.run.failed

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) fails.

thread.run.cancelling

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) moves to a `cancelling` status.

thread.run.cancelled

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) is cancelled.

thread.run.expired

`data` is a [run](/docs/api-reference/runs-v1/object)

Occurs when a [run](/docs/api-reference/runs-v1/object) expires.

thread.run.step.created

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is created.

thread.run.step.in\_progress

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) moves to an `in_progress` state.

thread.run.step.delta

`data` is a [run step delta](/docs/api-reference/assistants-streaming-v1/run-step-delta-object)

Occurs when parts of a [run step](/docs/api-reference/runs-v1/step-object) are being streamed.

thread.run.step.completed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is completed.

thread.run.step.failed

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) fails.

thread.run.step.cancelled

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) is cancelled.

thread.run.step.expired

`data` is a [run step](/docs/api-reference/runs-v1/step-object)

Occurs when a [run step](/docs/api-reference/runs-v1/step-object) expires.

thread.message.created

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is created.

thread.message.in\_progress

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) moves to an `in_progress` state.

thread.message.delta

`data` is a [message delta](/docs/api-reference/assistants-streaming-v1/message-delta-object)

Occurs when parts of a [Message](/docs/api-reference/messages-v1/object) are being streamed.

thread.message.completed

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) is completed.

thread.message.incomplete

`data` is a [message](/docs/api-reference/messages-v1/object)

Occurs when a [message](/docs/api-reference/messages-v1/object) ends before it is completed.

error

`data` is an [error](/docs/guides/error-codes#api-errors)

Occurs when an [error](/docs/guides/error-codes#api-errors) occurs. This can happen due to an internal server error or a timeout.

done

`data` is `[DONE]`

Occurs when a stream ends.Log in [Sign up](/signup)

Authentication required

Please log in to access this page

Log inSign up

We use cookies and similar technologies to deliver, maintain, improve our services and for security purposes. Check our [Cookie Policy](https://openai.com/policies/cookie-policy) for details. Click 'Accept all' to let OpenAI and partners use cookies for these purposes. Click 'Reject all' to say no to cookies, except those that are strictly necessary. Choose 'Manage Cookies' to pick specific cookies you're okay with or to change your preferences.

Reject allAccept all[Skip to main content](#main)

Terms & policies \| OpenAI

# Terms & policies

## Legal

- [Terms of use](/policies/terms-of-use/): Terms that govern use of ChatGPT, DALL·E and OpenAI's other services for individuals

- [Privacy policy](/policies/privacy-policy/): Practices with respect to personal information we collect from or about you.

- [Service terms](/policies/service-terms/): Additional terms that govern your use of specific services.

- [Data processing addendum](/policies/data-processing-addendum/): Ensuring that personal data is handled appropriately and securely.

- [Our approach to patents](/approach-to-patents/): Information on our use of patents.

- [Plugin terms](/policies/plugin-terms/): These terms govern the creation and use of your Plugin in connection with OpenAI Services.

- [Service credit terms](/policies/service-credit-terms/): These terms govern any credits redeemable for our services

- [Business terms](/policies/business-terms/): Terms that govern use of OpenAI's services for businesses, enterprises, or developers


## Policies

- [Usage policies](/policies/usage-policies/): Ensuring our technology is used for good.

- [Enterprise privacy](/enterprise-privacy/): Usage and retention of data submitted for enterprise users.

- [Sharing & publication policy](/policies/sharing-publication-policy/): On permitted sharing, publication, and research access.

- [Coordinated vulnerability disclosure policy](/policies/coordinated-vulnerability-disclosure-policy/): Definition of good faith in the context of finding and reporting vulnerabilities.


We use cookies and similar technologies to deliver, maintain, improve our services and for security purposes.

Check our [Cookie Policy](/policies/cookie-policy/) for details. Click 'Accept all' to let OpenAI and partners use cookies for these purposes. Click 'Reject non-essential' to say no to cookies, except those that are strictly necessary.

Accept allReject non-essential